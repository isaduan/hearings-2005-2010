S.  1372,  THE  FAIR  RATINGS  ACT 

S.  HRG.  109–1127 

HEARING 

BEFORE THE 

COMMITTEE ON COMMERCE, 

SCIENCE, AND TRANSPORTATION 

UNITED STATES SENATE 
ONE  HUNDRED  NINTH  CONGRESS 

FIRST  SESSION 

JULY  27,  2005 

Printed  for  the  use  of  the  Committee  on  Commerce,  Science,  and  Transportation 

( 

65–216 PDF 

WASHINGTON  : 

2011 

U.S.  GOVERNMENT  PRINTING  OFFICE

For sale by the Superintendent of Documents, U.S. Government Printing Office

Internet: bookstore.gpo.gov Phone: toll free (866) 512–1800; DC area (202) 512–1800

Fax: (202) 512–2104 Mail: Stop IDCC, Washington, DC 20402–0001

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00001 Fmt 5011 Sfmt 5011 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

SENATE  COMMITTEE  ON  COMMERCE,  SCIENCE,  AND  TRANSPORTATION 

ONE  HUNDRED  NINTH  CONGRESS 

FIRST  SESSION 

TED  STEVENS,  Alaska,  Chairman 

JOHN  MCCAIN,  Arizona 
CONRAD  BURNS,  Montana 
TRENT  LOTT,  Mississippi 
KAY  BAILEY  HUTCHISON,  Texas 
OLYMPIA  J.  SNOWE,  Maine 
GORDON  H.  SMITH,  Oregon 
JOHN  ENSIGN,  Nevada 
GEORGE  ALLEN,  Virginia 
JOHN  E.  SUNUNU,  New  Hampshire 
JIM  DEMINT,  South  Carolina 
DAVID  VITTER,  Louisiana 

DANIEL  K.  INOUYE,  Hawaii,  Co-Chairman 
JOHN  D.  ROCKEFELLER  IV,  West  Virginia 
JOHN  F.  KERRY,  Massachusetts 
BYRON  L.  DORGAN,  North  Dakota 
BARBARA  BOXER,  California 
BILL  NELSON,  Florida 
MARIA  CANTWELL,  Washington 
FRANK  R.  LAUTENBERG,  New  Jersey 
E.  BENJAMIN  NELSON,  Nebraska 
MARK  PRYOR,  Arkansas 

LISA J.  SUTHERLAND,  Republican  Staff  Director 

CHRISTINE DRAGER KURTH,  Republican  Deputy  Staff  Director 

DAVID RUSSELL,  Republican  Chief  Counsel 

MARGARET L.  CUMMISKY,  Democratic  Staff  Director  and  Chief  Counsel 

SAMUEL E.  WHITEHORN,  Democratic  Deputy  Staff  Director  and  General  Counsel 

LILA HARPER HELMS,  Democratic  Policy  Director 

(II) 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00002 Fmt 5904 Sfmt 5904 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

C O N T E N T S 

Hearing held on July 27, 2005 
...............................................................................
Statement of Senator Burns  ...................................................................................

WITNESSES 

Crawford, Kathy, President, Local Broadcast, MindShare  ..................................
Prepared statement  ..........................................................................................
Ivie, George, Executive Director/CEO, The Media Rating Council, Inc.  .............
Prepared statement  ..........................................................................................
Metzger, Gale, Former President, Statistical Research Inc.  ................................
Prepared statement  ..........................................................................................
Mullen, Patrick J., President, Tribune Broadcasting Company  ..........................
Prepared statement  ..........................................................................................
Shagrin, Ceril, Executive Vice President for Research, Univision  ......................
Prepared statement  ..........................................................................................
.............................
Prepared statement  ..........................................................................................

Whiting, Susan D., President/CEO, Nielsen Media Research 

APPENDIX 

ment 

Inouye, Hon. Daniel K., U.S. Senator from Hawaii, prepared statement  ...........
Lautenberg,  Hon.  Frank  R.,  U.S.  Senator  from  New  Jersey,  prepared  state-
......................................................................................................................
Letter, dated September 29, 2005, from Kathy Crawford, MindShare, to Hon. 
..........................................................................................................
Metzger, Gale, supplementary information  ...........................................................

Ted Stevens 

Page 
1 
1 

21 
23 
3 
5 
32 
35 
27 
29 
18 
20 
13 
15 

63 

63 

64 
68 

(III) 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00003 Fmt 5904 Sfmt 5904 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00004 Fmt 5904 Sfmt 5904 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

S.  1372,  THE  FAIR  RATINGS  ACT 

WEDNESDAY,  JULY  27,  2005 

COMMITTEE ON COMMERCE, SCIENCE, AND TRANSPORTATION, 

U.S. SENATE, 

Washington, DC. 

The  Committee  met,  pursuant  to  notice,  at  2:30  p.m.  in  room 
SR–253,  Russell  Senate  Office  Building,  Hon.  Conrad  Burns,  pre-
siding. 

OPENING STATEMENT OF HON. CONRAD BURNS, 

U.S. SENATOR FROM MONTANA 

Senator BURNS. We’ll bring the Committee to order. 
Around  here,  when  you  get  to  the  last  week  before  the  August 
break,  it  gets  a  little  compressed.  We  have  to  do  many  things  in 
one  day  in  order  to  finish  our  work  before  we  go  home  on  the  Au-
gust  break.  And  so,  there  will  be  Members  in  and  Members  out.  I 
was  advised  by  the  Ranking  Member  to  start  the  hearing  this 
morning, and—or this afternoon, and we can do that. 

First  of  all,  I  want  to  thank  all  the  witnesses  for  coming.  This 
is a busy time of the year. I look forward to a stimulating exchange 
of  views  this  afternoon.  Some  of  us  were  gathered  here  a  year  ago 
at  a  hearing  that  I  convened  to  hear  about  the  problems  encoun-
tered by phasing in of Nielsen’s Local People Meters in several cit-
ies  around  the  country.  The  questions  then  were  whether  the  de-
ployment  caused  minority  and  other  groups  to  be  undercounted, 
and whether Nielsen had listed enough of its customers before roll-
ing out the technology. The answers appeared to be yes and no, re-
spectively. At the end of the hearing, Senator Boxer and I told the 
witnesses that it would be best if they could all work out the prob-
lems among themselves. 

Well,  it  seems  like  that  process  is  a  work-in-progress.  In  this 
technical area, that usually does not get a lot of attention, we have 
had  continued  controversy  around  this.  And  so,  we  have  a  bill.  I 
introduced  a  bill  because  I  wanted  a  solution  to  the  problem  and 
I didn’t see that voluntary industry efforts were making any head-
way  at  all.  I  still  think  a  voluntary  solution  would  have  been  best 
for all concerned. 

And I understand the Media Rating Council has come forth with 
a  voluntary  code  of  conduct,  but  the  Nielsen  organization  will  not 
sign  on  without  major  changes.  I  look  forward  to  hearing  more 
about that today. But I wonder what happens to voluntary coopera-
tion  once  things  get  tough,  or  once  Congress  is  not  paying  atten-
tion, as we are today. 

(1) 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00005 Fmt 6633 Sfmt 6633 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

2 

This  bill  is  not  about  Local  People  Meters.  This  Nielsen  tech-
nology may or may not be the state-of-the-art, but, if it is, it’s bet-
ter  than  the  diary  system.  And  if  Nielsen  customers  want  it,  then 
so be it. 

And I also do not believe it’s in the public interest to worry about 
whether  the  given  company’s  ratings  go  up  or  down.  That’s  some-
thing for the market to decide. And I think we can all agree about 
that. 

This  bill  is  about  accountability.  It’s  about  making  sure  that  the 
system  is  fair  and  accurate  for  all  Americans.  It  would  compel 
Nielsen to come to the table with the auditors at the Media Rating 
Council  and  accept  their  changes  if  minimum  accuracy  standards 
are not met. That is what I care about. That is why I got involved 
in this debate. And I believe I have constructed legislation that will 
make sure this is the case today and in the future. 

Nielsen  needs  some  kind  of  an  effective  oversight,  because  it  is 
the  only  game  in  town.  Companies  who  need  TV  ratings  data  do 
not  have  anywhere  else  to  go  today,  even  if  there  are  serious  con-
cerns about the numbers that they’re seeing as a result of Nielsen’s 
samplings.  MRC  oversight,  with  meaningful  enforcement  power, 
would  remedy  this  situation  in  the  best  possible  way,  because  the 
MRC is made up of Nielsen’s customers. The bill would not involve 
any  government  agency.  The  MRC  would  retain  its  independence 
and  responsiveness  to  the  members  as  a  private-sector  expert 
group. 

The  industry’s  self-regulating  model  has  been  approved  by  Con-
gress  many  times  and  in  many  different  sectors  of  the  economy.  I 
think the MRC model has been working well for the last 40 years. 
Maybe it is time for a change. We will find out only through hear-
ings and gaining more information. 

Recent  events  have  showed  us  that  the  MRC’s  lack  of  power  to 
enforce  its  findings,  though,  is  somewhat  of  a  problem.  They  need 
some  teeth.  And  I  would  hope  that  maybe  we  would  find  we  could 
give them some. 

The  bill  would  also  set  the  stage  for  a  strong  MRC  role  in  guar-
anteeing the accuracy of the technologies. We have several systems 
that  may  soon  be  deployed  by  Nielsen  and  others  that  would  cap-
ture time-shifting viewing, out-of-home viewing, and other methods 
that may not be developed yet. 

Of  special  interest  to  me,  though,  is  the  decision  that  the  MRC 
took in March to take another look at the diary system. This meth-
od, unchanged since the 1950s, is still in use in over 150 local tele-
vision stations around the country, including all of them, of course, 
in  Montana  and  many  others  around  the  country.  With  this  deci-
sion,  as  I  understand  it,  the  MRC  has  asked  Nielsen  to  cooperate 
in review of the accuracy of the diary system. I would hate to think 
that people in rural areas, in small towns all over the country, are 
less  important  than  the  people  in  the  big  cities  where  Nielsen  is 
spending  the  resources  on  the  people  meters.  Rural  viewers  are 
very important to me. When I ran a network in television and radio 
stations,  I  had  to  depend  totally  on  Nielsen  data  for  my  business. 
So, I hope Nielsen will cooperate with the MRC on this. 

If it does not, in my mind, that is another important reason that 

the bill should pass. 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00006 Fmt 6633 Sfmt 6633 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

3 

Nielsen ratings determine the value of literally billions of dollars 
in advertising. Because our TV industry is supported largely by ad-
vertising dollars, Nielsen ratings, in the end, determine which tele-
vision  shows  get  aired  and  which  get  canceled;  and  so,  ultimately, 
determine  what  kind  of  content  is  distributed  on  our  public  air-
ways. 

So,  television  rating  systems  have  extraordinary  cultural,  social, 
and  economic  implications.  Even  in  the  era  of  the  Internet,  tele-
vision  remains  our  national  town  hall.  It  is  a  medium  that  brings 
Americans  together,  and  it  is  shared  space  that  shapes  our  na-
tional  experience.  And  in  a  very  real  sense,  the  ratings  generated 
by  Nielsen  determine  content  that  is  available  in  that  shared 
space. So, the American public has a clear and compelling interest 
in  ensuring  that  these  ratings  systems  are  as  fair  and  accurate  as 
possible. 

All  viewers  must  be  counted.  I  hope  we  can  agree  on  that.  And 
I  believe  that  the  FAIR  Ratings  bill  is  an  important  step  in  that 
direction. 

I  have  no  one  to  hand  the  football  off  to,  so  we  will  start  taking 
testimony  this  morning.  We  want  to—or  this  afternoon—we  want 
to thank everyone in attendance. I know there’s a great deal of in-
terest  in  this  issue.  And  I  look  forward  to  hearing  the  testimony 
and the dialogue that we may have before it’s all over. 

First  of  all,  I’d  like  to  welcome  our  first  panel  of  testimony,  Mr. 
George  Ivie,  Executive  Director  and  CEO  of  the  Media  Rating 
Council. 

Thank you, Mr. Ivie, for coming this morning, and—or this after-

noon, and—I can’t get caught up—— 

[Laughter.] 
Senator BURNS.—this afternoon, and we look forward to your tes-

timony. 

STATEMENT OF GEORGE IVIE, EXECUTIVE DIRECTOR/CEO, 

THE MEDIA RATING COUNCIL, INC. 

Mr. IVIE. Senator Burns and distinguished members of the Com-
mittee,  my  name  is  George  Ivie,  and  I  serve  as  Executive  Director 
and  CEO  of  the  Media  Rating  Council.  I  thank  you  for  the  oppor-
tunity, Senator Burns, to testify this morning on television ratings 
accuracy and the FAIR Ratings Act. 

My  written  testimony  outlines  the  history  and  mission  of  the 
MRC and includes descriptions of our administrative and accredita-
tion procedures, and we believe we have sound operations and stat-
ed  policies  for  the  following:  voting  on  and  accrediting  research 
based  on  standards  compliance,  limiting  the  influence  of  any  one 
industry  sector  or  member  within  our  organization,  maintaining 
independence  from  measurement  services,  and,  most  importantly, 
ensuring  rigorous  industry-driven  audit  procedures.  For  example, 
about  independence,  our  membership  does  not  include  measure-
ment organizations. 

We  appreciate  the  Committee’s  interest  in  the  accuracy  of  tele-
vision ratings and Congress’ reaffirmation of the MRC’s role in the 
form of this FAIR Ratings Act; however, we have important sugges-
tions for your consideration in both of these areas. 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00007 Fmt 6633 Sfmt 6633 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

4 

As  you  are  all  aware,  a  significant  MRC  concern  has  been 
Nielsen’s  commercialization  of  the  San  Francisco,  Washington, 
D.C.,  and  Philadelphia  LPM  markets  prior  to  an  MRC  audit.  As 
you know, Nielsen controls the timing of these audits and the roll-
out  dates.  We  also  have  concern  about  Nielsen’s  failure  to  disclose 
adequate  test  data  for  some  of  the  LPM  implementations.  These 
situations prevent our illumination of the quality and performance 
of the new services prior to commercialization. 

We  have  sought,  and  received  in  June,  a  commitment  from 
Nielsen to the auditing and impact data closures we requested, and 
we hope that Nielsen remains committed to the audits of the LPMs 
and  their  other  significant  products  after  the  direct  focus  of  Con-
gress lessens. 

Related  to  the  FAIR  Ratings  Act,  our  focus  is  to  assure  audits 
and  committee  review  and  impact  data  disclosures  prior  to  com-
mercialization of new products. This focus is driven by the need to 
illuminate  the  quality  of  the  rating  products  to  users  so  they  can 
make informed usage judgments. We believe it’s important to avoid 
a  situation  where  non-accredited  products  are  prohibited  from 
being commercialized through a blanket rule, but we just as strong-
ly believe that these products should be audited. 

The MRC is not a political organization, and we have not sought 
Congressional  actions  in  the  form  of  a  ratings  bill.  The  legislation 
appears  to  raise  complex  issues  of  antitrust  and  liability  for  the 
MRC,  beyond  my  particular  training  and  expertise,  but  in  which 
we  obviously  have  a  great  interest.  We  remain  on  course,  seeking 
completion of the initiatives recommended in our January 27, 2005, 
letter  to  the  FTC  and  to  you,  Senator  Burns,  signed  by  a  strong 
majority  of  our  board.  These  items  include  agreement  by  Nielsen 
to  the  government  to  remain  in  the  MRC  audit  process  for  the  fu-
ture for its key products. It is in Nielsen’s power today, in this pub-
lic  government  forum,  to  reaffirm  their  commitment  to  the  MRC 
process for all their significant products, not just LPM and not just 
future products. 

This  seemingly  small  item  is  important  to  assure  that  Nielsen 
continues  to  respond  and  dialogue  with  the  industry  about  quality 
and transparency, which, in turn, should instill greater public con-
fidence. 

Most  importantly,  we  intend  to  gain  consensus  on,  and  adopt,  a 
voluntary  code  of  conduct  that  was  supplied  to  rating  services  for 
comment several weeks ago. The code is important because it adds 
detail  and  formal  structure  to  how  rating  services  are  expected  to 
act  on  audit  findings  and  interact  with  the  MRC.  Our  members, 
Arbitron, Media Mark Research, and other rating services, have ex-
pressed  support  of  this  approach.  This  week,  Nielsen  commu-
nicated  their  conceptual  agreement,  and  more  dialogue  is  needed. 
We  hope  you  will  agree  that  such  a  voluntary  code  of  conduct 
will do much to promote the vigorous self-regulation that Congress 
envisioned  in  1964,  which  is  still  very  much  needed  over  40  years 
later.  The  final  January  initiative  entailed  establishing  a  commu-
nication  linkage  between  the  MRC  and  appropriate  Congressional 
and  Executive  Branch  representatives  to  call  upon  when  needed. 
We believe the voluntary code of conduct is our key solution to the 
issues  we  face,  and,  when  adopted  by  Nielsen  and  other  rating 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00008 Fmt 6633 Sfmt 6633 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

5 

services,  this  code  will  provide  further  assurance  that  measure-
ment  services  are  meeting  the  MRC’s  mandate  of  accuracy  and 
transparency. 

In  closing,  the  MRC  has  strived  for  four  decades  to  be  faithful 
to  the  mission  Congress  defined  for  us.  As  always,  we  stand  ready 
to work with the Congress in any way that would be helpful. I very 
much  appreciate  the  care  and  thoughtfulness  of  you,  Senator 
Burns,  and  other  Members  of  the  Committee,  in  considering  the 
issues that significantly impact the media ratings marketplace. 

Whether  legislation  is  required  is  fundamentally  an  issue  and  a 
decision  for  Congress,  though  we  will  follow  this  debate  carefully 
to  ascertain  whether  such  an  initiative  could  affect  our  current 
work.  In  any  event,  we  believe  our  key  business  priorities  are  to 
seek Nielsen’s firm and long-term commitment to the accreditation 
process  and  seek  adoption  of  our  voluntary  code  of  conduct  by 
Nielsen and other measurement services. 

I would be happy to answer any questions you have. 
[The prepared statement of Mr. Ivie follows:] 

PREPARED STATEMENT OF GEORGE IVIE, EXECUTIVE DIRECTOR/CEO, 

THE MEDIA RATING COUNCIL, INC. 

I. Introduction to the MRC 

I  am  George  Ivie,  Executive  Director  and  CEO  of  the  Media  Rating  Council 
(MRC), and I am grateful for the opportunity to present our views on Nielsen’s im-
plementation of the local people meter (LPM) measurement methodology in general- 
market media research. I would like to begin by thanking Senator Burns and Rank-
ing  Member  Inouye  for  your  leadership  in  focusing  congressional  attention  on  this 
technical and important subject. 

The  MRC  is  a  non-profit  organization  that  reviews  and  accredits  audience-rating 
services through the use of rigorous audits. An MRC audit includes an independent, 
detailed, and objective examination of each aspect of the operations of a rating serv-
ice (including methodological protocols) through data provided to it by participating 
rating services. The central mission of the MRC is to secure for the media industry, 
audience  measurement  services  that  are  valid,  reliable,  and  effective  through  an 
independent  evaluation  process,  without  regard  to  outcome.  The  MRC  is  inde-
pendent  of,  and  external  to,  any  rating  service  and  guards  its  independence  zeal-
ously. 
1. History and Mission of the MRC 

During  1963  and  1964,  regulation  of  the  TV  and  Radio  industries  including  the 
purpose  and  accuracy  of  audience  research  were  the  subjects  of  extensive  public 
hearings.  This  process  culminated  with  a  progress  report  issued  to  the  89th  Con-
gress  of  the  United  States  (House  Report  No.  1212) 1 in  January  1966.  These  hear-
ings  were  held  by  a  Special  Subcommittee  on  Investigations  of  the  House  of  Rep-
resentatives Committee on Interstate and Foreign Commerce and are commonly re-
ferred to as the ‘‘Harris Committee Hearings on Broadcast Ratings.’’ 

After  an  extensive  investigation  and  3  days  of  testimony,  the  Committee  deter-
mined that Industry self-regulation, including independent audits of rating services 
(such  as  Nielsen  Media  Research,  Arbitron  or  MRI)  was  preferable  to  government 
intervention.  In  its  report,  the  Committee  concluded  as  follows:  ‘‘The  enactment,  at 
this  time,  of  legislation  providing  for  government  regulation  of  broadcast  audience 
measurement  activities  is  not  advisable.  The  administration  of  a  statute  providing 
for such regulation would place an unnecessary burden on the Federal Government, 
and  it  is  doubtful  that  more  would  be  accomplished  than  can  be  accomplished  by 
effective industry regulation.’’ 2 

The  Harris  Committee  hearings  resulted  in  the  formation  of  an  Industry-funded 
organization  to  review  and  accredit  audience-rating  services  called  the  Broadcast 
Rating  Council  (now  referred  to  as  the  MRC).  At  that  time,  the  Broadcast  Rating 

1 House Rpt. No. 1212, 89th Congress (1966). 
2 Id. at p. 21. 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00009 Fmt 6633 Sfmt 6621 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

6 

Council’s  proposed  Industry  self-regulation  procedures  were  reviewed  by  the  U.S. 
Justice Department and were found not to be in violation of the antitrust laws.3 

Aligned with the actions deemed necessary by the Committee, the activities of the 

MRC include, but are not limited to the following: 

• The  establishment  and  administration  of  Minimum  Standards  for  rating  oper-

• The  Accreditation  of  rating  services  on  the  basis  of  information  submitted  by 

ations; 

ices. 

such services; and 

• Auditing,  through  independent  CPA  firms,  of  the  activities  of  the  rating  serv-

The  MRC’s  mission  as  stated  in  its  By-laws  is:  ‘‘to  secure  for  the  media  industry 
and  related  users  audience  measurement  services  that  are  valid,  reliable  and  effec-
tive; to evolve and determine minimum disclosure and ethical criteria for media au-
dience  measurement  services;  and  to  provide  and  administer  an  audit  system  de-
signed  to  inform  users  as  to  whether  such  audience  measurements  are  conducted 
in  conformance  with  the  criteria  and  procedures  developed.’’ 4 This  mission  was  es-
tablished with the support and guidance of the House Committee. 
2. Standards 

Consistent  with  the  By-laws  of  the  BRC  and  its  mission,  it  developed  minimum 
standards  by  which  media  research  is  to  be  measured,  which  became  effective  on 
March 31, 1964 and have been maintained and updated by the MRC Board of Direc-
tors.5 The Standards relate to: (a) ethics and operations, and (b) disclosures. Ethical 
and Operational Standards govern the quality and integrity of the entire process by 
which  ratings  are  produced.  Disclosure  Standards  specify  the  detailed  information 
about a rating service’s methodology and each specific survey, which must be made 
available to users, the MRC and its CPA firm, as well as the form in which the in-
formation should be made available. 
3. MRC Accreditation Process 

The  MRC  Accreditation  process  is  completely  voluntary  and  there  is  no  legal  or 
compulsory  requirement  that  a  rating  service  submit  to  an  MRC  audit.  MRC  is 
often compared to similar private industry self-regulatory organizations such as the 
Joint  Commission  on  Accreditation  of  Healthcare  Organizations  (JACHO),  which  is 
an organization that audits and accredits participating hospitals for institutional fit-
ness  and  high  quality  patient  services.  Similarly,  the  MRC  lends  its  ‘‘seal  of  ap-
proval’’  to  rating  services  that  demonstrate  compliance  with  MRC’s  standards  of 
media  rating  research  and  that  make  complete  methodological  and  survey-perform-
ance disclosures to their customers after completing an extensive audit. Over thirty- 
five  rating  service  products  were  submitted  to  the  MRC  Accreditation  process  last 
year.  Of  these  thirty-five  products,  many  represented  media-types  other  than  tele-
vision. 

Accreditation  is  granted  by  the  MRC  Board  of  Directors  if  a  rating  service  com-
plies  with  the  MRC’s  Minimum  Standards  for  Media  Rating  Research  and  makes 
materially complete methodological and survey-performance disclosures to their cus-
tomers. 

The  MRC  has  used  several  nationally  known  CPA  firms  throughout  the  years  to 
perform these audits. At present, the audits are conducted by Ernst & Young, under 
contract  to  the  MRC.  Each  rating  service  agrees  to  pay  MRC  assessments  to  cover 
their  audit  cost;  the  MRC  collects  no  funds  from  rating  services  other  than  the  di-
rect  cost  of  the  Ernst  &  Young  audits.  To  be  clear,  the  MRC  derives  no  benefit,  fi-
nancially or otherwise, from the rating service. MRC’s revenue is solely derived from 
the  dues  paid  to  it  by  its  members.  In  addition,  unlike  most  CPA  firms,  Ernst  & 
Young maintains a specialized group of personnel who have responsibility for audit-
ing  rating  service  operations  and  assessing  compliance  with  the  MRC’s  unique 
Standards. This Ernst & Young team only works on media rating service audits. 

The central element in the monitoring activity of the MRC is its system of annual 
external audits of rating service operations. MRC audits serve these important func-
tions: 

3 Letter from William Orrick, Jr. Assistant Attorney General, Antitrust Division, U.S. Depart-
ment  of  Justice  to  Douglas  A.  Anello,  General  Counsel,  National  Association  of  Broadcasters 
(July 16, 1964) 

4 MRC  By-Laws.—Board  of  Directors,  Media  Rating  Council,  Effective  March  1964,  Updated. 
5 See  Minimum  Standards  for  Media  Rating  Research,  Media  Rating  Council,  Inc.  (last  up-

dated = 10/97). 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00010 Fmt 6633 Sfmt 6621 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

7 

• They determine whether a rating service merits Accreditation (or continued Ac-
creditation);  the  audit  report  and  related  insight  provided  by  the  CPA  firm  is 
the primary input into the Accreditation decision, 
• They  provide  the  MRC  with  the  results  of  detailed  examinations  by  CPA  audi-
tors  which  become  the  basis  for  quality  improvements  in  the  service,  either  by 
voluntary action or mandated by MRC as a condition for Accreditation, and 
• They  provide  a  highly  beneficial  psychological  effect  on  rating  service  perform-
ance.  Knowledge  that  CPA  auditors  may  review  their  work  is  a  powerful  spur 
for quality work by all field and home-office personnel of the rating service. 

The specific methodological approach of the rating service and the MRC Minimum 
Standards for Media Rating Research are the primary drivers of the audit scope for 
each  participating  rating  service  to  be  executed  by  the  CPA  firm,  on  behalf  of  the 
MRC.  Audits  are  required  to  be  conducted  at  least  annually.  The  MRC  establishes 
an  audit  committee  made  up  of  member  organizations  that  use  research  of  that 
media-type  to  evaluate  audit  results  and  recommend  a  position  on  ‘‘Accreditation’’ 
to  the  Executive  Director  of  the  MRC,  who  then  submits  such  recommendation  to 
the  MRC  Board  of  Directors.  Provision  is  also  made  for  the  suspension  or  with-
drawal of Accreditation and a documented, formal hearing procedure applies in such 
instances. 

The  MRC’s  audit  includes  an  independent,  detailed  and  objective  examination  of 
each significant aspect of the operations of a rating service. In the event that a rat-
ing  service  uses  outside  professional  vendors  (for  example,  for  sampling  procedures 
or  for  editing  and  tabulation  of  data)  these  sources  are  also  audited  and  reported 
upon. 

Resulting  audit  reports  are  very  detailed  (typically  150–300  pages);  containing 
many  methodological  and  proprietary  details  of  the  rating  service  and  illumination 
of the primary strengths and weaknesses of its operations. The reports are confiden-
tial  among  the  MRC  members,  who  all  sign  non-disclosure  agreements,  Ernst  & 
Young  and  the  rating  service.  Audit  reports  include  detailed  testing  and  findings 
for: 

• Sample design, selection, and recruitment 
• Sample composition by demographic group 
• Data collection and fieldwork 
• Metering, diary or interviewing accuracy 
• Editing and tabulation procedures 
• Data processing 
• Ratings calculations 
• Assessment of rating service disclosures of methodology and survey performance 
Pursuant to the last bullet above, the MRC mandates that rating services disclose 
many methodology and performance measures, which would be otherwise unknown, 
for example: 

such as young or ethnic persons 

• Source of sample frame 
• Selection method 
• Respondents by demographic group versus population 
• Response rates 
• Existence of special survey treatments for difficult to recruit respondent groups 
• Editing procedures 
• Minimum reporting requirements for media 
• Ascription and data adjustment procedures employed 
• Errors noted in published reports 
• Data reissue standards and reissue instances 
As  a  result  of  the  disclosures  that  a  rating  service  must  make  in  complying  with 
the  MRC  Accreditation  process,  specific  audit  findings  are  not  disseminated  to  the 
public  or  the  press  unless  waived  by  the  service,  the  MRC,  and  the  CPA  firm  that 
conducts  the  audit.  Public  disclosure  of  proprietary  techniques  can  be  detrimental 
to  a  rating  service’s  core  business,  for  example  endangering  patented  information, 
and the MRC takes very seriously its obligation to keep proprietary information con-
fidential  as  well  as  the  audit  reports.  Recently  a  controversy  erupted  between  the 
MRC  and  Nielsen  Media  Research  regarding  the  apparent  leak  of  information  re-
lated  to  the  audit  of  Nielsen’s  Los  Angeles  LPM  service  to  the  Los  Angeles  Times. 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00011 Fmt 6633 Sfmt 6621 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

8 

MRC  in  no  way  endorsed  or  condones  that  behavior  as  it  goes  directly  against  its 
code  of  confidentiality.  As  a  result  of  this  incident,  the  MRC,  in  conjunction  with 
its  members,  have  implemented  new  rules  for  the  viewing  and  discussion  of  draft 
and final audit reports among its membership. 

What should be made clear, however, is that the MRC can only publicly comment 
on  its  decision  to  grant,  deny,  suspend  or  withdraw  Accreditation  without  the  con-
sent of the rating service and the independent CPA auditing firm. 

Rating services that are awarded MRC Accreditation are given permission to dis-
play the MRC’s logo on the audited research product indicating compliance with our 
Standards.  MRC  Standards  are  publicly  available;  more  importantly,  the  extensive 
methodological  and  survey  performance  disclosures  mandated  by  the  MRC  are  re-
quired to be available to all rating service customers. 
II. MRC Membership, Membership Participation and ‘‘Due Process’’ 
1. Membership 

Membership  in  the  MRC  is  completely  voluntary  and  members  pay  annual  dues 
of  $10,500  (for  reference,  MRC  dues  were  $7,500  per  year  in  1964).  The  dues  are 
universal  in  the  sense  that  each  member  pays  the  same  amount  regardless  of  the 
overall  size  of  its  organization  and  are  set  at  a  level  that  allows  participation  by 
organizations  of  all  sizes.  The  Board  of  Directors  of  the  MRC  is  comprised  of  one 
appointed  representative,  generally  a  top  media  research  executive,  for  each  mem-
ber organization. Currently there are approximately 95 Board members in total rep-
resenting  television  and  radio  broadcasting,  cable,  print,  Internet  and  advertising 
agency  organizations  as  well  as  advertisers  and  other  trade  associations.6 As  indi-
cated by our membership list, MRC represents a very broad and diverse amalgama-
tion of the media industry as well as the largest clients of rating services. Addition-
ally, we have a provision for formal liaison relationships with the American Associa-
tion of Advertising Agencies, the Advertising Research Foundation and the Associa-
tion of National Advertisers. Membership is open to any media organization that re-
lies  on,  or  uses  media  research  and  presently  includes  both  general-market  media 
(e.g.,  the  ABC,  CBS,  FOX,  NBC  networks)  and  ethnic  media  organizations  (e.g., 
Black Entertainment and Television and Univision). Conversely, organizations such 
as Nielsen or Arbitron that produce media ratings data are not allowed to be mem-
bers of the MRC. 
2. Membership Participation 

MRC  members  play  a  critical  role  in  the  Accreditation  process  and  provide  valu-
able insight. MRC’s ‘‘Television Audit Committee’’ comprised of individual represent-
atives from various member organizations that have an interest in the accuracy and 
quality  of  the  rating  service’s  research.  The  individuals  that  sit  on  this  committee 
are  often  the  top  media  researchers  of  their  organizations  and  generally  do  not  in-
clude  television  executives  or  representatives  of  an  organizations’  marketing  divi-
sion.  It  is  in  this  committee,  along  with  the  oversight  of  the  MRC  Staff,  that  true 
industry  oversight  of  the  quality  and  accuracy  of  television  audience  measurement 
services is performed. 

As  discussed  earlier,  it  is  through  the  MRC  Accreditation  process  and  the  use  of 
rigorous  and  independent  audits,  that  a  rating  service  gains  MRC  Accreditation. 
However,  before  Accreditation  can  be  achieved,  the  Audit  Committee  has  the  task 
of  reviewing  a  draft  of  the  rating  service  audit  and  discussing  the  results  in  detail 
with the auditor (Ernst & Young) and the staff of the MRC. Additionally, the rating 
service  has  the  opportunity  to  provide  its  comments,  verbatim,  in  the  audit  report 
or in a separate letter supplied to the audit committee. This is a confidential process 
and  strict  guidelines  and  procedures  are  followed  during  this  review  because  of  the 
transparency requirement that a rating service must meet in order to gain MRC Ac-
creditation. 

Once  a  full  review  of  the  audit  has  been  completed,  the  MRC  presents  a  ‘‘staff 
recommendation’’  to  the  full  committee  on  whether  in  its  opinion  taking  all  the 
available  data  in  front  of  it;  the  rating  service  should  be  accredited.  This  rec-
ommendation  is  prepared  to  help  guide  the  committee  as  it  weighs  its  decision  on 
Accreditation.  The  audit  committee  will  then  vote  on  Accreditation,  which  in  turn 
serves as a recommendation for the MRC Executive Director to take to the full MRC 
Board  of  Directors  for  final  approval.  At  this  point  the  Executive  Director  will 
present  the  recommendation  of  the  audit  committee  to  the  full  Board  of  Directors 
along  with  his  assessment.  The  full  Board  then  has  the  responsibility  and  ultimate 
authority to vote to grant or deny Accreditation. 

6 Full membership list is attached. 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00012 Fmt 6633 Sfmt 6621 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

3. ‘‘Due Process’’ 

9 

One very important aspect of the voting and approval process is the controls and 
safe  guards  that  are  in  place  to  assure  that  a  vote  of  the  audit  committee  is  fair 
and impartial. The MRC has a formal policy for membership voting on MRC Accred-
itation  issues  that  provides  stringent  controls  and  eliminates  the  potential  for  out-
side influence, during and subsequent to the voting procedure. The policy is not in-
tended to stifle in any way the thoughtful discussion that takes place in preparation 
of the proposals. The policy is designed to insure a more proper accounting of ballots 
and  to  further  maintain  the  confidentiality  of  meeting  proceedings.  Specifically,  it: 

the Industry 

violation of the signed confidentiality agreement 

• Verifies that all votes are accounted for 
• Reduces the likelihood of miscounting votes 
• Limits  the  influence  of  any  one  member  organization,  or  collective  segments  of 
• Minimizes the information that can potentially be divulged to Non-Members, in 
• Maintains a physical record of the vote 
• Provides a means for verification 
Voting  within  the  MRC  can  occur  at  various  levels  and  follows  a  pre-established 
hierarchy. Below is an outline of the levels at which voting may take place including 
a summary of the MRC members that are entitled to participate, and the responsi-
bility of each group. 

• Sub-committee(s)— 
Subcommittees  are  comprised  of  a  sub-set  of  individuals  from  the  MRC  Com-
mittee(s) responsible for oversight of the measurement service. Any committee mem-
ber  claiming  to  have  a  business  or  professional  interest  in  the  matter  at  hand  can 
elect to participate in a subcommittee. The MRC Staff will work to ensure that the 
various  segments  of  the  industry  are  represented  in  the  Sub-committee.  The  Sub- 
committee  is  responsible  for  undertaking  a  detailed  review  of  the  issue.  Multiple 
sub-committee meetings may be held depending on the complexity of the issue. The 
Sub-committee  vote  is  designed  to  make  a  recommendation  to  the  Committee(s).  A 
tie  vote  will  necessitate  a  detailed  review  by  a  larger  Sub-committee  group  or  the 
Committee. 

• Committees— 
MRC Committees are comprised of MRC members who have a business or profes-
sional  interest  in  the  medium  for  which  the  Committee  has  oversight.  These  com-
mittees may be asked to undertake a detailed review based on the complexity of the 
issue. The Committee votes whether to accept the recommendation of the Sub-com-
mittee and the Committee vote is structured to make a recommendation and provide 
guidance to the Executive Director. A quorum is required on all voting matters and 
a tie vote will necessitate a detailed review by the Board of Directors. 

• Board of Directors 
The Board of Directors represents all active members of the MRC and vote on the 
recommendation  submitted  by  the  Executive  Director.  In  addition,  the  Board  is  re-
sponsible for the final vote on all Accreditation issues and a quorum is required on 
all voting matters. 

• Executive Director 
The Executive Director is responsible for making a recommendation to the Board 
of  Directors  and  considers  the  recommendation  of  the  Committee(s),  though  he  is 
not  required  to  recommend  the  Committee(s)  position  to  the  Board.  However,  the 
Executive  Director  must  convene  a  board  meeting  to  discuss  in  detail  any  rec-
ommendation whereby the Executive Director’s position differs from that submitted 
by the Committee. The Executive Director may take any issue directly to the Board 
of Directors for a vote. 
• Voting Guidelines 
All  active  Board  Members  are  entitled  to  a  vote  in  the  Accreditation  process.  A 
member company designates the representative(s) to attend meetings and vote. The 
MRC  recommends  the  voting  representative  be  a  senior  ranking  individual  with 
knowledge  of  the  subject  matter.  When  a  detailed  review  of  the  subject  matter  is 
called  for,  the  voting  representative  must  be  in  attendance  for  the  majority  of  the 
review  meeting.  Anyone  not  in  attendance  for  the  full  meeting  will  be  allowed  to 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00013 Fmt 6633 Sfmt 6621 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

10 

vote at the discretion of the MRC Executive Director. A member company represent-
ative may participate in-person, via phone or video-conference and is allowed to rep-
resent  a  maximum  of  two  votes,  for  multi-vote  organizations.  In  addition,  this  rep-
resentative is required to submit vote(s) in writing with the exception of those par-
ticipating  via  phone  or  conference  call.  Individuals  participating  via  electronic 
means (e.g., phone, etc.) have the option to cast votes via personal call to MRC Staff, 
fax, or e-mail. Verbal votes require follow-up written (e.g., fax, e-mail, etc) confirma-
tion. 

• Special Circumstances 
Special  circumstances  occur  when  an  MRC  member  whose  company  has  a  vested 
interest in the matter being considered. When this occurs, that member may partici-
pate in the review meeting but will not be allowed to vote. Situations of this nature 
will  be  disclosed  prior  to  the  start  of  the  meeting.  Any  un-anticipated  voting  con-
flicts are to be resolved by the MRC Executive Director. 

• Voting Results 
When  a  vote  takes  place  the  rating  service  will  be  advised  of  the  final  outcome 
as soon as possible and summary-voting results may be divulged to the Rating Serv-
ice  when  deemed  appropriate  by  the  Executive  Director.  Individual  member  votes 
will  not  be  divulged  by  the  MRC  and  members  are  free  to  state  their  voting  inten-
tion  prior  to  the  official  vote.  However,  members  may  divulge  their  individual  vote 
outside of the meeting subject to the policy of the signed Non-Disclosure Agreement 
on record at the MRC. 
III.  Status  of  LPM  Audits—Boston,  New  York,  Los  Angeles,  Chicago,  San 

Francisco, Philadelphia, and Washington, D.C. 

Nielsen’s  primary  products  cover  national  programs,  local  programs,  syndication, 
cable,  satellite,  as  well  as  dedicated  research  for  Hispanics  and  by  implication  the 
advertisements for all of these vehicles. Nielsen also provides several electronic tools 
and applications used to deliver ratings to their customers. The MRC accredits sev-
eral,  but  not  all,  of  Nielsen’s  products.7 Nielsen’s  National  Service  based  on  a  peo-
ple-meter  methodology  has  been  MRC-Accredited  since  the  late  1980s;  Nielsen’s 
meter-diary  based  Local  Service  was  originally  Accredited  in  the  1960s;  Nielsen’s 
National Hispanic Service (NHTI) has been Accredited since 2000. We believe these 
services  materially  comply  with  our  Standards,  although  the  MRC  does  maintain  a 
separate  ongoing  dialogue  with  Nielsen  regarding  quality  issues  noted  in  the  audit 
process  in  an  effort  to  improve  the  quality  of  research.  Other  Services  such  as 
Nielsen’s Hispanic Station Index (NHSI), and certain other Black and Hispanic Au-
dience Reports are not currently Accredited or audited. 
1. Boston 

Nielsen  Media  Research  first  ‘‘rolled  out’’  its  local  people  meter  (LPM)  in  Boston 
in  2001.  This  was  Nielsen’s  first  experience  with  the  LPM  in  a  general-media  local 
market  environment.  It  is  our  understanding  that  Boston  was  chosen  as  the  first 
market  by  Nielsen  because  of  several  factors,  including  its  more  homogenous  popu-
lation and smaller size. While one can argue about this characterization of the Bos-
ton  media  market,  it  became  clear  that  Nielsen’s  assumptions  about  easily  meas-
uring  the  market  proved  to  be  inaccurate.  During  calendar  years  2001  and  2002, 
the MRC audited Nielsen’s LPM rollout in Boston. The audit of the service was ex-
tensive  and  subsequently  the  MRC  denied  its  Accreditation  to  the  Boston  LPM 
based on strong concerns with Nielsen’s implementation of the service. However, de-
spite the concerns raised by the MRC audit and denial of Accreditation, Nielsen con-
tinued  a  commercial  implementation  of  the  Boston  LPM.  At  the  same  time,  most 
local broadcasters in Boston did not utilize Nielsen’s LPM services. However, during 
the ensuing year, Nielsen took extensive actions to cure the issues raised by MRC’s 
audit. Upon Nielsen making the recommended changes, MRC gave its Accreditation 
to  the  Boston  LPM  in  the  Fall  of  2002  approximately  9  months  after  its  initial 
audit. 

After its Boston experience, the MRC Television Committee took the unusual step 
of  recommending  to  Nielsen  that  future  LPM  implementations  only  be  commer-
cialized  after  Accreditation  is  achieved  and  that  new  LPM  sample  households  not 
be integrated into Nielsen’s National panel prior to achieving Accreditation. 

7 Complete List of MRC Accredited Services. 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00014 Fmt 6633 Sfmt 6621 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

2. New York 

11 

The  MRC  began  its  audit  process  of  the  New  York  LPM  (NYLPM)  during  the 
early  part  of  2004.  The  New  York  market  is  arguably  the  most  difficult  market  to 
measure  particularly  in  obtaining  the  cooperation  of  households.  The  market  is 
highly  diverse  and  represents  unique  challenges  in  compiling  accurate  and  reliable 
data. Fieldwork began in this market in April of 2004 and the MRC utilized its full 
audit  scope  and  procedures  for  assessing  the  service.  Ernst  &  Young  conducted  the 
audit using its standard Nielsen auditing team, which included bi-lingual personnel. 
There were many problems identified in the audit, including race and origin classi-
fication  errors,  excessive  and  excessively  disproportionate  faulting  and  metering 
issues.  The  market’s  performance  was  further  complicated  by  an  on-going  media 
campaign  in  the  New  York  market,  which  could  have  potentially  influenced  house-
hold  participation.  Concurrent  with  the  introduction  of  the  LPM,  the  MRC  closely 
monitored the existing meter/diary service in New York and found that this service 
had degraded. 

Subsequently on May 27, the MRC audit committee met to discuss the audit and 
the  MRC  staff  recommendation.  The  audit  committee  voted  to  withhold  Accredita-
tion  of  the  NYLPM  at  that  time  based  on  a  number  of  problems  identified  in  the 
Ernst  and  Young  audit  as  well  as  issues  identified  by  the  MRC  staff  and  the  audit 
committee  members.  The  MRC  sent  a  letter  to  Nielsen  that  communicated  detailed 
areas of concern and deficiencies with the NYLPM as identified by the audit process 
and suggested actions that Nielsen should take to improve the quality of the service 
and gain Accreditation. Nielsen commercialized the NYLPM on June 3, 2004. 

On  August  26,  2004,  the  MRC  convened  a  meeting  of  the  audit  committee  to  as-
sess  the  results  of  a  re-audit  performed  by  Ernst  &  Young  to  assess  performance 
of  certain  prior  audit  issues.  Nielsen  was  given  opportunity  to  address  the  Com-
mittee  during  part  of  the  meeting  to  share  their  perspective  on  the  improvement 
initiatives  and  the  performance  status  of  the  NYLPM.  After  private  deliberations 
the  committee  chose  to  continue  to  withhold  Accreditation  of  the  NYLPM  service. 
On August 31, 2004, a letter was sent to Nielsen informing them of the Committee’s 
decision and outlining the steps necessary to elevate the Accreditation status of the 
NYLPM,  namely  a  plan  for  updating  race  information  and  fault  rate  stabilization 
which would be observed through regular monitoring by the committee. 

On  October  29,  2004  after  review  of  a  credible  plan  submitted  by  Nielsen  to  ad-
dress  the  race  classification  issues,  and  observed  improvement  in  fault  rate  levels 
the  television  committee  voted  to  grant  Conditional  Accreditation  status  to  the 
NYLPM  allowing  Nielsen  to  apply  the  MRC’s  Accreditation  logo  to  the  New  York 
LPM rating reports. 

Since  Conditional  Accreditation  was  granted  in  October  2004,  the  television  com-
mittee has continually monitored the performance of the NYLPM, including update 
meetings  with  Nielsen  management  and  periodic  reviews  to  reassess  the  Accredita-
tion  status  of  the  NYLPM.  As  of  this  date,  the  NYLPM  service  remains  Condi-
tionally Accredited. 
3. Los Angeles 

On July 1, 2004, an MRC audit committee met to review an Ernst & Young audit 
of  the  Los  Angeles  LPM  service  (LALPM);  at  that  time  Nielsen  had  not  provided 
their  response  to  the  audit  findings,  a  key  component  of  the  MRC  review  process. 
The  MRC  decided  that  it  was  important  to  at  least  conduct  a  preliminary  review 
of  the  audit  findings  (i.e.,  absent  Nielsen’s  response)  so  that  it  could  provide  some 
illumination  of  the  performance  of  the  LALPM  in  advance  of  its  planned  commer-
cialization  on  July  8.  To  maintain  the  integrity  of  the  MRC  process,  the  committee 
elected  not  to  vote  on  Accreditation  at  the  conclusion  of  this  preliminary  review 
until Nielsen submitted their response for review. The Los Angeles market is a dif-
ficult  market  to  measure  due  to  its  ethnic  diversity  which  presents  unique  chal-
lenges in compiling accurate and reliable data. 

Despite  the  open  Accreditation  status  of  the  LALPM  Service,  Nielsen  went  ‘‘live’’ 
with  the  service  on  July  8,  2004.  It  was  clear  through  our  experiences  in  Boston 
and  New  York  that  Nielsen  was  not  yet  implementing  LPM  services  in  a  manner 
that is fully compliant with the MRC’s standards. 

The  audit  committee  met  on  July  30,  2004,  to  conclude  the  review  of  the  audit 
results,  including  Nielsen’s  response  which  was  presented  in-person  by  Nielsen 
management. After careful consideration the Committee chose to recommend Condi-
tional  Accreditation  of  the  LALPM  service  pending  Nielsen’s  submission  of  an  ade-
quate,  accepted  action-plan  to  address:  (1)  two  matters  of  non-compliance  with  the 
MRC’s  Minimum  Standards  for  Media  Rating  Research  cited  in  the  audit,  and  (2) 
two performance areas of the Los Angeles LPM Service considered needing improve-
ment.  In  addition,  an  on-going  monitoring  process  was  required  by  the  Television 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00015 Fmt 6633 Sfmt 6621 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

12 

Committee  to  assure  that  Nielsen  completes  the  improvement  initiatives  specified 
in its response to the Los Angeles audit, including the pending action-plan. 

On August 19, 2004, upon receipt and acceptance of Nielsen’s action-plan the Con-
ditional Accreditation period began and Nielsen was authorized to apply the MRC’s 
Accreditation logo to the Los Angeles LPM rating reports. 

Since  Conditional  Accreditation  was  granted  in  August  2004,  the  television  com-
mittee  has  continually  monitored  the  performance  of  the  LALPM,  including  update 
meetings  with  Nielsen  management  and  periodic  reviews  to  reassess  the  Accredita-
tion status of the LALPM. As of this date, the LALPM service remains Conditionally 
Accredited. 
4. Chicago 

The Chicago LPM (CHLPM) Service was commercialized by Nielsen on August 5, 
2004,  prior  to  an  MRC  audit.  Timing  for  MRC  audits  is  controlled  by  Nielsen  and 
fieldwork  was  not  scheduled  to  begin  until  July  2004,  leaving  insufficient  time  for 
completion  of  the  MRC  process  prior  to  the  LPM  service  going  ‘‘live’’.  The  Chicago 
market  contains  a  high  concentration  of  minority  population  groups  posing  a  par-
ticular challenge to measuring accurate and reliable viewing behavior. 

An  audit  committee  of  the  MRC  met  on  September  22,  2004,  to  review  the  find-
ings of the Ernst & Young examination of the CHLPM and based on the results the 
audit committee voted to follow the precedence set in Los Angeles and move to grant 
Conditional Accreditation to the CHLPM. The Conditional Accreditation status was 
scheduled  to  begin  following  receipt  and  acceptance  of  an  action-plan  structured  to 
address specific audit issues and would also require ongoing monitoring of key per-
formance  metrics  for  this  service.  On  October  1,  2004,  after  receipt  of  an  accepted 
action-plan,  Conditional  Accreditation  of  the  CHLPM  began  and  Nielsen  was  per-
mitted to apply the MRC Accreditation logo to the service reports. 

Since  Conditional  Accreditation  was  granted  in  October  2004,  the  television  com-
mittee has continually monitored the performance of the CHLPM service, including 
update meetings with Nielsen management and periodic reviews to reassess the Ac-
creditation status of the CHLPM. As of this date, the CHLPM service remains Con-
ditionally Accredited. 
5. San Francisco 

The  San  Francisco  LPM  (SFLPM)  was  commercialized  on  September  30,  2004, 
prior to an MRC audit and before providing comparative data to the existing Meter- 
diary service that would allow the marketplace to understand the impact of this sig-
nificant methodological change. MRC Standards require that measurement services 
disclose in advance the estimated impact of a methodological change. The San Fran-
cisco market is racially diverse, containing a high concentration of Asians, and this 
diversity  presents  specific  challenges  to  accurately  measure  television  viewing  be-
havior. 

Fieldwork  for  the  MRC  audit  began  in  November  2004,  3  months  after  Nielsen 
commercialized the service. Because of the voluntary nature of the MRC process, the 
timing of the audit is controlled by Nielsen. 

On  March  8,  2005,  five  months  after  the  SFLPM  service  was  commercialized  by 
Nielsen, an audit committee of the MRC met to review the Ernst & Young examina-
tion report of the SFLPM and recommended that the service be granted Conditional 
Accreditation  allowing  Nielsen  to  apply  the  MRC  Accreditation  logo  to  the  SFLPM 
reports.  Nielsen  was  informed  of  specific  actions  including  ongoing  monitoring  and 
performance improvements that would be required for the committee to consider re-
moval of the conditional aspect of the Accreditation. 

On  May  6,  2005,  the  television  committee  met  with  Nielsen  management  to  re-
view  the  status  of  the  LPM  improvement  initiatives  and  performance  metrics  and 
in  a  private  discussion  voted  to  elevate  the  status  of  the  SFLPM  to  full  Accredita-
tion. 
6. Philadelphia 

Nielsen commercialized the Philadelphia LPM on June 30, 2005, prior to an MRC 
audit,  consequently  this  service  is  not  Accredited.  An  MRC  audit  is  in  process  for 
this market with an expected committee review in October 2005. Because of the vol-
untary nature of the MRC process, the timing of the audit is controlled by Nielsen. 
7. Washington 

Nielsen commercialized the Washington LPM on June 30, 2005, prior to an MRC 
audit,  consequently  this  service  is  not  Accredited.  An  MRC  audit  is  in  process  for 
this market with an expected committee review in October 2005. Because of the vol-
untary nature of the MRC process, the timing of the audit is controlled by Nielsen. 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00016 Fmt 6633 Sfmt 6621 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

13 

IV.  Status  of  Nielsen  Hispanic  Measurement  Services—National  Hispanic 

Station Index—Los Angeles and National Hispanic Television Index 

1. Nielsen Hispanic Station Index—Los Angeles (NHSI–LA) 

The NHSI–LA Service was audited by MRC during 2000–2001 and, despite ongo-
ing commercial use of the service, Nielsen chose to not address the audit issues and 
terminated the Accreditation process after two unsuccessful attempts. Nielsen never 
submitted other NHSI markets to the Accreditation process. 
2. Nielsen Hispanic Television Index (NHTI) 

Nielsen’s NHTI Service has maintained MRC Accreditation since 2000. 
The broadcast television industry members of the MRC, as well as cable operators 
and  the  advertising  industry  have  all  voiced  their  support  for  the  MRC  process  in 
this  matter.  Central  among  the  organizations  expressing  this  support  are  the  Na-
tional  Association  of  Broadcasters,  the  Cabletelevision  Advertising  Bureau,  Radio 
Advertising Bureau, and the American Association of Advertising Agencies.8 
V. Conclusion 

Once  again,  the  MRC  would  like  to  thank  the  Committee  for  holding  this  impor-
tant  hearing  on  TV  Ratings  accuracy  and  the  FAIR  Ratings  Bill  and  for  allowing 
the MRC to provide testimony. I continue to believe that Congress was right in find-
ing that industry self-regulation is preferable to direct governmental intervention— 
provided  that  the  independence  and  integrity  of  such  an  auditing  process  can  be 
preserved. 

I  believe  that  all  of  the  stakeholders  involved  in  this  issue  would  agree  that  the 
accuracy  of  Television  Ratings  is  of  critical  importance  and  that  the  MRC  should 
play a central role in assessing the accuracy and quality of the new service. * 

Senator BURNS. Thank you very much. 
Those of you making statements, if we could hold them to around 

5 minutes, that would be great. 

He  has  to  be  a  master.  This  is  his  testimony  he  has  handed  in 
to the Committee, and he got it all in 5 minutes, and I think that’s 
pretty  good.  That’s  probably  the  standard  here.  Thank  you  very 
much. 

Now  we’ll  hear  from  Susan  Whiting,  President  and  CEO  of 

Nielsen Media Research. 

Thank you for coming today. We appreciate that very much. 
STATEMENT OF SUSAN D. WHITING, PRESIDENT/CEO, 

NIELSEN MEDIA RESEARCH 

Ms. WHITING. Thank you. 
Good  afternoon.  My  name  is  Susan  Whiting,  and  I’m  the  Presi-

dent and CEO of Nielsen Media Research. 

About  a  year  ago,  I  first  testified  before  this  Committee.  Since 
then,  Nielsen  has  worked  hard  to  follow  your  advice  and  to  make 
a superior measurement system even better. 

Nielsen  Media  Research  is  in  the  truth  business,  the  truth  of 
what  people  are  actually  watching  on  television  and  how  they  are 
watching  it.  Today,  for  example,  the  average  TV  household  has 
more than—— 

The CHAIRMAN. Could you pull that mike up a little closer? 
Ms. WHITING. Is that better? 
Today,  for  example,  the  average  TV  household  has  more  than 
100  channels.  Nielsen  has  made  more  advancements  and  invested 
more  money  in  TV  audience  measurement  services  than  at  any 
other  time  in  our  history.  These  new  investments  and  initiatives 

8 Press releases and Organizational statements on the LPM. 
* All  the  information  referred  to  in  the  footnotes  of  this  prepared  statement  have  been  re-

tained in Committee files. 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00017 Fmt 6633 Sfmt 6601 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

14 

have  resulted  in  improvements,  innovations,  and  change.  In  most 
cases,  changes  result  in  different  ratings,  but  they  also  provide  a 
better reflection of viewers’ actual behavior. 

As  you  may  have  experienced  with  your  voters,  it  is  very  hard 
to make everyone in your constituency happy. Nielsen is committed 
to  working  with  all  of  our  constituents,  our  thousands  of  clients, 
which  include  broadcasters,  cable  operators,  advertising  agencies, 
and  advertisers,  all  with  competing  and  often  conflicting  demands 
on a rating service. 

Nielsen  must  remain  independent  of  conflicting  interests  among 
its  diverse  client  base.  For  example,  on  the  legislation  we  are  dis-
cussing  today  two  powerful  players,  Tribune  and  Comcast,  have 
taken  opposite  positions  on  this  bill.  Often,  when  one  party  does 
not agree with our position, they say we are not listening, that we 
are arrogant. In fact, we are listening, not just to one, but to many 
voices. Given the progress we have made and the inherent conflicts 
within the industry we serve, we do not believe legislation is either 
necessary  nor  advisable.  I  believe  this  bill,  or  any  similar  legisla-
tion, is both unnecessary and harmful to the long-term interests of 
the entire television community. 

I  think  these  points  were  clearly  recognize  by  the  FTC  in  its 
March 30, 2005, response to your request that it consider oversight 
of  TV  ratings,  where  the  FTC  said  that,  in  Nielsen’s  case,  ‘‘well- 
constructed  industry  self-regulatory  efforts  can  be  more  prompt, 
flexible, and effective than government regulation.’’ 

The Media Rating Council and Nielsen have established a strong 
working  relationship  that  has  enabled  us  to  introduce  increasingly 
more accurate ratings systems. Recently, the MRC has put forward 
guidelines  for  all  MRC  members  and  measurement  services,  a  vol-
untary  code  of  conduct.  We  agree,  in  principle,  with  the  proposed 
code of conduct, and we are working with the MRC on it. For exam-
ple, we have already agreed that no future commercial rating serv-
ice will be launched before it is audited. 

That  is  why  this  bill  is  unnecessary.  Here  is  why  it  is  harmful. 
The  mandatory  accreditation  required  under  this  bill  would  slow 
ratings innovation to a crawl. New digital media are emerging with 
breathtaking  speed.  Advertisers  and  broadcasters  need  to  know 
what  impact  this  will  have  on  how  audiences  watch  TV.  If  ratings 
companies  have  to  operate  new  services  without  generating  rev-
enue,  it  is  unlikely  they  will  develop  or  implement  expensive  new 
audience  measurement  innovations.  This  is  also  a  significant  bar-
rier to entry into this market by any competitor. 

I think, Senator Burns, that you said it best when you remarked 
that  the  Internet  was  able  to  blossom  because  Congress  didn’t 
know how to regulate it. According to the same principle, Congress 
should  not  regulate  television  ratings  business.  We  do  not  believe 
it  is  good  policy  to  transform  the  MRC  into  a  vehicle  that  limits 
competition  from  new  program  sources,  especially  from  smaller, 
independent, and minority-owned stations and networks looking to 
compete  against  media  giants.  This  is  why  a  number  of  minority- 
oriented  channels  have  issued  voiced  opposition  to  legislation,  in-
cluding both TV One and BET. 

I  should  also  note  that  many  other  clients  representing  the  ad-
vertisers,  including  the  American  Association  of  Advertising  Agen-

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00018 Fmt 6633 Sfmt 6601 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

15 

cies,  the  Association  of  National  Advertisers,  and  the  AAF,  whose 
money  this  is  all  about,  community  groups,  and  public-interest  or-
ganizations have voiced their opposition to mandatory accreditation 
and the legislation. 

I  do  want  to  mention  one  initiative  that  came  about  from  our 
work with both our task force and the MRC, the creation of a Spe-
cial  Council  for  Research  Excellence.  We  created  this  council  in 
order  to  involve  the  industry  in  setting  the  direction  of  basic  re-
search and development. Nielsen has committed an additional $2.5 
million annually for special research, as recommended by the coun-
cil.  It  is  composed  of  40  clients  representing  the  entire  television 
industry  and  chaired  by  Mark  Kaline,  Global  Media  Manager  for 
Ford Motor Company, one of the largest buyers of television adver-
tising time in the United States. 

In conclusion, instead of legislation, we need to support the MRC 
by  agreeing  to  a  new  voluntary  audit  and  accreditation  standard 
that  will  enable  measurement  services  to  respond  more  quickly  to 
dynamic  changes.  Self-regulation  dictated  through  government 
mandate  has  many  of  the  same  disadvantages  as  direct  govern-
ment  oversight,  without  the  protection  of  formal  rulemaking  proc-
esses or public accountability. 

On  behalf  of  thousands  of  Nielsen  employees  in  the  United 
States, across 49 states, I would like to reiterate Nielsen’s commit-
ment  to  producing  the  most  accurate  TV  ratings  possible,  that  we 
continue  to  serve  a  broad  and  sometimes  contentious  client  base, 
and  that  we  are  committed  to  working  with  the  MRC,  our  clients, 
and community leaders to assure transparency and accuracy in the 
ratings. 

Thank you. 
[The prepared statement of Ms. Whiting follows:] 

PREPARED STATEMENT OF SUSAN D. WHITING, PRESIDENT/CEO, 

NIELSEN MEDIA RESEARCH 

Good  morning.  My  name  is  Susan  Whiting  and  I  am  President  and  Chief  Execu-

tive Officer of Nielsen Media Research. 

It was about a year ago that I first testified before this committee. Since then my 
team  and  I  at  Nielsen  have  worked  very  hard  to  follow  your  advice  and  to  make 
a superior measurement system even better. I have met with many Members of the 
Committee to hear their concerns and share Nielsen’s story, including our vision for 
the  future  of  audience  measurement  technology,  and  our  commitment  to  working 
with all of our clients. 

Nielsen Media Research is in the truth business: the truth of what people are ac-
tually watching on television, and how they are watching it. We all watch television 
differently  today  than  we  did  5  years  ago.  Today,  for  example,  the  average  TV 
household  has  more  than  100  channels  from  which  to  choose.  Consumers  are  also 
choosing digital technologies such as TiVo, Video on Demand and video gaming. 

With  this  diversity  of  entertainment  choices,  Nielsen  is  committed  to  providing 

the entire marketplace with the most accurate TV ratings possible. 

To anyone who has been involved in this industry for the past 5 years, it is clearly 
apparent  that  Nielsen  has  made  more  advancements  and  invested  more  money  in 
TV audience measurement services that at any other time in our history. 

During  the  last  year,  we  made  significant  investments  in  all  aspects  of  TV  audi-
ence  measurement—sampling,  data  collection,  data  processing,  and  data  delivery— 
which  we  believe  will  further  improve  the  accuracy  of  our  ratings.  We  continue  to 
invest  in  the  leading  edge  of  measurement  technologies  and  look  forward  to  new 
systems that will measure a broad spectrum of digital technologies. 

These new investments and initiatives produce change, and different clients react 

differently to these changes. 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00019 Fmt 6633 Sfmt 6621 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

16 

As  you  may  have  experienced  with  your  voters,  it  is  very  hard  to  make  everyone 
in  your  constituency  happy.  Nielsen  is  committed  to  working  with  all  of  our  con-
stituents, our clients, which include broadcasters, cable operators, advertising agen-
cies and advertisers—all with competing and often conflicting demands on a ratings 
service.  A  truly  independent  ratings  service,  offering  the  highest  quality  and  most 
accurate ratings, is vital for the marketplace to operate effectively. 

Nielsen  must  remain  independent  of  these  conflicting  interests.  For  example,  on 
the legislation we are discussing today, two powerful players, the National Associa-
tion  of  Broadcasters  and  Comcast  have  taken  opposite  positions  on  this  legislation. 
Unwarranted and Unwise Legislation 

Given  the  progress  we  have  made  and  the  inherent  conflicts  within  the  industry 
we  serve  we  do  not  believe  legislation  is  either  necessary  or  advisable,  in  fact  we 
feel it is unwarranted and harmful. 

I think these points were ably recognized by the Federal Trade Commission in its 
March  30,  2005  response  to  your  request  that  it  consider  oversight  of  TV  ratings. 
As  you  recall  from  its  response,  the  FTC  said,  that,  in  Nielsen’s  case,  ‘‘well  con-
structed  industry  self-regulatory  efforts  can  be  more  prompt,  flexible  and  effective 
than government regulation.’’ 

I  believe  S.  1372  is  both  unnecessary  and  harmful  to  the  long-term  interests  of 

the entire television community. 

First,  it  is  unnecessary.  The  Media  Rating  Council  and  Nielsen  have,  over  the 
past  40  years,  established  a  strong  working  relationship  that  has  enabled  us  to  in-
troduce  increasingly  more  accurate  ratings  systems.  Over  the  past  few  weeks,  for 
example,  the  MRC  has  put  forward  guidelines  for  all  MRC  members  and  measure-
ment  services—called  A  Voluntary  Code  of  Conduct—that  would  both  clarify  and 
strengthen  the  MRC’s  relationship  with  all  measurement  services  as  well  as  with 
its  own  membership.  The  MRC  recently  provided  to  its  members  and  all  measure-
ment  services—television,  radio,  newspaper  and  Internet—a  proposed  voluntary 
code  of  conduct  to  deal  with  the  rollout  of  new  measurement  technologies  in  the 
marketplace. Among the first things we have already agreed to, for example, is that 
no  future  commercial  ratings  service  will  be  launched  without  the  transparency  of 
a full audit having taken place. 

Other  elements  of  the  Code  are  under  discussion  at  this  time,  and  we  are  con-
fident that, after appropriate give and take, that the industry will reach agreement 
with  all  ratings  services  on  the  Code  and  we  can  submit  it  to  the  Justice  Depart-
ment  and  the  FTC  for  a  business  review.  We  believe  in  principle  that  the  proposed 
Voluntary Code of Conduct represents a valid approach to enhancing the MRC proc-
ess,  and  that  if  it  is  approved  by  MRC  members  and  all  measurement  services,  we 
intend to adopt it. 

In  other  words,  since  the  free-market,  private  enterprise  system  is  working,  we 

do not need a legislative solution to a problem that does not exist. 
That is why S. 1372 is unnecessary. Here is why it is harmful. 
The  mandatory  accreditation  required  under  S.  1372  would  slow  ratings  innova-
tion to a crawl. Vital new systems for measuring all forms of digital television could 
remain  idle  while  MRC  members  debated.  In  an  environment  that  is  becoming  in-
creasingly  governed  by  political  and  economic  self-interest,  that  process  could  lit-
erally  take  years.  Technology,  however,  won’t  wait.  Nor  will  clients.  The  transition 
from  analogue  to  digital  television  technologies  would  be  frustrated  at  the  lack  of 
timely measurement. 

As  you  know  when  you  watch  television,  and  from  your  experience  on  the  Com-
mittee, new digital media are emerging with breathtaking speed, and audiences are 
increasingly  willing  to  use  devices  like  DVRs  and  Video  on  Demand  to  take  control 
of  their  viewing  experiences.  The  sale  of  DVRs  is  expected  to  nearly  double  within 
2  years,  and  advertisers  and  broadcasters  need  to  know,  as  soon  as  possible,  what 
impact this will have on how audiences watch TV. 

If ratings companies are required to operate new services without generating rev-
enue  for  a  significant  period  of  time,  it  is  unlikely  they  will  develop  or  implement 
expensive new audience measurement innovations. Such a prospect also is a signifi-
cant  barrier  to  entry  into  this  market  by  any  competitor.  Indeed,  if  technology  and 
telecommunication  firms  faced  these  restrictions,  computers,  cell  phones  and  the 
Internet would still be on the drawing boards. 

We  do  not  believe  it  is  good  public  policy  to  transform  the  MRC  into  a  vehicle 
that  limits  competition  from  new  program  sources,  especially  from  smaller,  inde-
pendent,  and  minority-owned  stations  and  networks  looking  to  compete  against 
media  giants.  More  precise  ratings  technology  enhances  the  voice  of  minorities  by 
making  possible  niche  programming  on  new  cable  networks  and  television  stations 
aimed  at  the  African  American,  Hispanic,  Asian,  and  Arab-American  communities. 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00020 Fmt 6633 Sfmt 6621 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

17 

These  advancements  could  grind  to  a  halt  with  mandatory  ratings  accreditation. 
This  is  why  a  number  of  minority  competitors  had  issued  statements  in  opposition 
to legislation, including both TV One and BET. 
Working With the Task Force 

As you know, Nielsen continues to work closely with the Independent Task Force 
on Television Measurement. This Task Force was created last year at the suggestion 
of Congressman Charles Rangel, for the very purpose of offsetting the need for Con-
gressional  involvement.  The  Task  Force  worked  for  more  than  8  months—and  con-
tinues  to  work—and  released  a  major  report  to  Nielsen,  which  we  shared  with  the 
industry, that included recommendations in the areas of sampling, field operations, 
fault rates, diversity and communications. 

With your permission, Senator, I would like to submit for the record a copy of the 
Task  Force’s  report,  Nielsen’s  response,  and  the  follow-up  report  released  just  last 
month.  Considering  the  importance  of  this  Task  Force  Report  and  the  enormous 
commitment  in  time  and  effort  from  people  representing  a  diverse  spectrum  of 
Americans,  especially  former  Representative  Mrs.  Cardiss  Collins  who  chaired  the 
Task Force. I should also note that the Task Force has issued a statement in opposi-
tion to S. 1372, and I would also like to submit those comments for the record. 

The Task Force has, indeed, been the focus for many of the very constructive ini-
tiatives  that  we  have  been  sharing  for  some  time  now  with  our  clients,  others  in 
the  industry  and  with  Congress.  Yet  the  full  breadth  of  audience  measurement— 
including  sample  design,  sample  recruiting  and  maintenance,  data  collection  sys-
tems,  metering,  data  processing  and  data  reporting  (all  involving  hundreds  of  mil-
lions  of  dollars  in  spending  by  Nielsen)—have  improved  over  the  years  because  of 
the  painstaking  work  we  have  done  with  our  clients  through  the  Media  Rating 
Council’s accreditation process. 

I  do  want  to  mention  just  one  initiative,  and  this  came  about  from  our  work 
through the Task Force as well as with the MRC, and that is the creation of a spe-
cial  Council  for  Research  Excellence,  created  earlier  this  year.  We  created  this 
Council in order to involve the industry in setting the direction of basis R&D in the 
area of methodological research. 

In addition to the tens of millions of dollars we spend each year on methodological 
and  statistical  research,  Nielsen  has  committed  an  additional  $2.5  million  for  spe-
cial research as recommended by the Council. The Council is composed of 40 clients, 
including  the  MRC,  representing  the  entire  television  industry.  The  Council  is 
chaired by Mark Kaline, global media manager for Ford Motor Company, one of the 
largest buyers of television advertising time in the United States. 
Responding to a Changing Market 

Why would anyone agree to create a Council or serve on a Council when the MRC, 
under the bill, would be the final authority over everything pertaining to the ratings 
services? 

Instead  of  a  new  bill  we,  as  an  industry,  need  to  support  the  MRC  by  agreeing 
to a new, voluntary audit and accreditation standards that will enable measurement 
services  to  respond  more  quickly  to  dynamic  changes  in  the  television  landscape  so 
that  digital  technologies  including  Digital  Video  Recorders,  DVD  Recorders,  Video 
on  Demand,  and  Time  Shifting  can  be  included  in  the  measurement  of  audiences. 
Congress has mandated the shift in broadcast television from analogue to digital. 
Over  the  past  12  years,  we  have  supported  that  mandate  by  completely  revamping 
our  metering  and  reporting  technology  with  investments  of  over  a  hundred  million 
dollars.  I  can  only  assume  that  the  underlying  assumption  behind  this  mandate  is 
that  there  would  be  no  government-imposed  barrier  to  measuring  audiences  to  dig-
ital  television.  But  S.  1372  imposes  formidable  barriers  by  mandating  that  no  rat-
ings service could measure anything without the approval of the MRC. 

Since  the  last  time  we  were  here,  we  have  significantly  enhanced  our  ability  to 

more accurately measure all television audiences. For example: 

• On March 3, 2005, after more than 12 years of R&D, and hundreds of millions 
of dollars in spending, Nielsen introduced a new digital metering system, called 
the Active/Passive Meter System, or A/P Meter for short. The A/P Meter is fun-
damentally  a  set  meter,  but  it  is  also  a  platform  for  in-home  measurement  of 
many new digital television devices. In July 2005, Nielsen began rolling out the 
new A/P Meter system into the national and local People Meter samples. With-
out  this  system,  we  would  not  be  able  to  measure  digital  signals  and  there 
would be no viable business model for digital television. 
• In  May  we  began  to  implement  a  program  of  personal  coaching,  performance- 
based incentives and reminder mailings designed to reduce overall and differen-

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00021 Fmt 6633 Sfmt 6621 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

18 

tial  faulting  in  Local  People  Meter  markets.  This  represents  another  ongoing 
multimillion investment. 

• In June we delivered a plan for enabling measurement of Video on Demand pro-

gramming in our syndicated ratings panels. 

• DVR  measurement  has  been  successfully  implemented  in  our  set-meter  and 
diary markets. We remain on-schedule for installation of DVR households in the 
national and local People Meter samples beginning in January 2006. So far, we 
have installed more than 200 DVR households across 47 local markets. 

• In  June  2005,  Nielsen  completed  the  translation  of  all  of  its  recruitment  mate-
rials  for  sample  households  into  Spanish,  developed  key  recruitment  materials 
in Mandarin, Japanese, Korean, Vietnamese, and Tagalog. We are also tailoring 
our  ‘‘introductory  video’’  that  is  provided  to  new  sample  households  for  Asian 
audiences. We also recently added several training procedures on cultural sensi-
tivity to our 10-week Field Training program. 

Conclusion 

To conclude my remarks today, self-regulation dictated through government man-
date  has  many  of  the  same  disadvantages  as  direct  government  oversight,  without 
the protection of formal rulemaking processes or public accountability. 

What  is  more,  it  lacks  the  agility,  flexibility  and  resourcefulness  that  come  from 
free  market  forces.  Those  qualities  have  served  the  Media  Rating  Council  and  its 
members well for more than four decades, and they are worth preserving. 

I would like to reiterate Nielsen’s commitment to producing the most accurate TV 
ratings  possible;  that  we  serve  a  broad  and  sometimes  contentious  client  base;  and 
that we are committed to working with the MRC, our clients, and community lead-
ers to assure transparency and accuracy in the ratings. 

Finally  we  believe  in  the  voluntary  MRC  accreditation  process,  and  legislatively 

mandating this process would be harmful not just to Nielsen but to everyone. 

Thank you. 

Senator BURNS. Thank you. 
Now we’ll hear from Ceril Shagrin. 

STATEMENT OF CERIL SHAGRIN, 

EXECUTIVE VICE PRESIDENT FOR RESEARCH, UNIVISION 
Ms. SHAGRIN. Good morning, Mr. Chairman and members of the 
Committee.  Actually,  I’m  as  bad  as  you  are,  it  is  afternoon,  isn’t 
it? 

[Laughter.] 
Senator BURNS. It is afternoon. 
Ms.  SHAGRIN.  My  name  is  Ceril  Shagrin.  I  spent  27  years  at 
Nielsen  Media  Research,  during  which  time  I  interacted  with  the 
Media Ratings Council—— 

Senator  BURNS.  Pull  your  microphone—you’ve  got  a  nice  little 

soft voice, and we’d like to hear it. 
Ms. SHAGRIN. OK. Is that better? 
Senator BURNS. You bet. 
Ms. SHAGRIN. I was Nielsen’s first quality-assurance director and 
the primary contact for the review of the MRC audit scope and the 
audit  report.  While  at  Nielsen  Media,  I  was  the  primary  partici-
pant  in  the  development  and  rollout  of  the  National  People  Meter 
Service. I was responsible for the development and management of 
Nielsen  Hispanic  Services,  and  involved  in  the  development,  test-
ing, and rollout of all new services. 

For  the  past  6  years,  I’ve  been  employed  by  Univision  Commu-
nications,  where  I  oversee  research  needs  for  all  Univision  divi-
sions.  Currently,  I  am  the  Chairman  of  the  MRC  Television  Com-
mittee  and  I  am  proud  to  be  this  year’s  recipient  of  the  Malcolm 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00022 Fmt 6633 Sfmt 6601 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

19 

Beville  Award  for  my  commitment  to  the  highest  standards  in 
broadcast measurement research. 

For  the  past  33  years,  I’ve  had  a  close  relationship  with  the 
MRC, both as a representative of the provider of television ratings 
and  as  a  user  of  those  ratings  for  programming  decisions  and  for 
setting value and audience delivery. I have worked with 6 different 
MRC  Executive  Directors.  For  the  past  33  years,  I’ve  been  driven 
by  the  need  for  quality  research  and  reliable  audience  estimates. 
I  believe  the  MRC  has  been  a  major  contributor  to  achieving  that 
goal. 

The television landscape has changed dramatically from a three- 
network  environment  to  one  of  multiple  broadcast  and  cable 
choices. At the same time, the United States population has grown 
and  changed  to  a  multicultural  population.  In  order  to  meet  the 
quality standards of television audience measurement, the samples 
used  to  develop  audience  estimates  must  accurately  represent  the 
current and changing populations of Whites, Blacks, Hispanics, and 
Asians,  not  just  in  total  number,  but  demographically  within  each 
of these populations. 

While  the  data-collection  instrument  must  be  designed  to  accu-
rately  collect  viewing,  no  data-collection  device  can  eliminate  the 
bias of reporting sample that does not accurately represent the uni-
verse  being  measured.  Television  rating  services  must  make  deci-
sions  on  the  data-collection  tool  and  the  methodology  which  best 
captures  viewing  within  the  cost  parameters  the  individual  mar-
kets can support. 

Installing and maintaining a representative sample is difficult. It 
takes properly trained personnel, adherence to procedures, and con-
tinuous  testing  to  search  for  improvements.  It  requires  a  commit-
ment to standards. The minimum standards of 1975 no longer meet 
the challenges of audience measurement in 2005. Quality measure-
ment  requires  constant  third-party  monitoring  to  ensure  proper 
procedures  are  identified  and  followed.  The  MRC  provides  that 
function through continuing audit and review. 

The MRC Television Committee is made up of users of the audi-
ence  estimates—broadcast  networks,  cable  networks,  stations, 
agencies,  and  advertisers.  For  the  past  6  years,  I  think  I’ve  at-
tended  every  one  of  the  MRC  meetings  related  to  television  audi-
ence  measurement.  I  strongly  believe  the  MRC  audit  process  has 
contributed to the continuous improvement of the quality of TV au-
dience measurement. 

Attendees  of  these  meetings  invest  a  significant  amount  of  time 
reading  and  analyzing  audit  reports.  Meetings  are  long  and  de-
tailed.  They  are  well  attended.  No  one  is  allowed  to  vote  without 
the investment of time in the understanding of the audit issues. 

Nielsen  received  a  copy  of  the  audit  report  prior  to  distribution 
to  the  Committee,  and  their  comments  are  included  in  the  report 
sent  to  the  Committee  and  in  the  discussion  and  review  of  the 
audit. 

New  technologies  must  be  audited  before  being  put  into  produc-
tion. New editing rules, processing rules, sample design and main-
tenance procedures should be evaluated, and their impact on audi-
ence estimates dimensioned, prior to implementation to ensure con-
tinuation of quality standards. 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00023 Fmt 6633 Sfmt 6601 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

20 

While  my  written  testimony  states  that  prior  to  2004  I  can  re-
member  no  instance  when  Nielsen  implemented  any  material 
changes  in  methodology,  processing  rules,  or  data-collection  device 
without  prior  review  and  acceptance  by  the  MRC,  there  was  one 
exception. That was the Boston LPM market. 

Nielsen has said, in recent public statements, that mandatory ac-
creditation  would  result  in  termination  of  the  Nielsen  Hispanic 
Station  Index,  the  local  Hispanic  measurement  service.  While  dif-
ferent  sampling  procedures  are  used  in  some  NHSI  markets, 
there’s  reason  to  believe  they  could  not,  either  as  currently  de-
signed or with modifications, meet MRC standards or that increas-
ing the Hispanic samples in the NSI service could not provide reli-
able  Hispanic  audience  estimates.  I  have  confidence  that  Nielsen 
can do that. 

For  approximately  40  years,  Nielsen’s  local  and  national  tele-
vision  measurement  services  have  been  audited  and  accredited. 
Nielsen  has  met  the  MRC  quality  standards  and  continuously 
strive  for  improvement.  It  has  made  them  a  better  company,  and 
it has allowed the television industry to grow. 

Univision has taken a neutral position on the FAIR Ratings bill. 
We take a very strong position on the need for quality samples and 
procedures  for  eliminating  bias.  We  take  a  positive  position  on  the 
need for MRC audits. 

I’d  like  to  thank  the  Committee  for  the  opportunity  to  appear 

here today, and I look forward to answering any questions. 

[The prepared statement of Ms. Shagrin follows:] 

PREPARED STATEMENT OF CERIL SHAGRIN, 

EXECUTIVE VICE PRESIDENT FOR RESEARCH, UNIVISION 

Good morning, Mr. Chairman and members of the Committee. 
My  name  is  Ceril  Shagrin.  I  spent  27  years  at  Nielsen  Media  Research  during 
which  time  I  interacted  with  the  Media  Rating  Council  (MRC)  and  the  Ernst  & 
Young  auditors.  I  was  Nielsen’s  first  Quality  Assurance  Director  and  the  primary 
contact  for  the  review  of  the  audit  scope  and  the  audit  report.  While  at  Nielsen 
Media  I  was  a  primary  participant  in  the  development  and  roll  out  of  the  National 
People  Meter  Service,  responsible  for  the  development  and  management  of  Nielsen 
Hispanic  Services  and  involved  in  the  development,  testing  and  rollout  of  all  new 
services. 

For  the  past  6  years  I  have  been  employed  by  Univision  Communications  where 

I oversee the research needs for all the Univision divisions. 

Currently  I  am  the  Chairman  of  the  MRC  Television  Committee.  I  am  proud  to 
be  this  year’s  recipient  of  the  Malcolm  Beville  Award  for  my  commitment  to  the 
highest standards in broadcast measurement research. 

For  the  past  33  years  I  have  had  a  close  relationship  with  the  MRC  both  as  a 
representative  of  the  provider  of  television  ratings  and  as  a  user  of  those  ratings 
for programming decisions and for setting value on audience delivery. I have worked 
with 6 different MRC Executive Directors. For the past 33 years I have been driven 
by the need for quality research and reliable audience estimates. I believe the MRC 
has been a major contributor to achieving that goal. 

The television landscape has changed dramatically from a three network environ-
ment  to  one  of  multiple  broadcast  and  cable  choices.  At  the  same  time  the  United 
States population has grown and changed to a multicultural population. In order to 
meet  the  quality  standards  of  television  audience  measurement,  the  samples  used 
to  develop  audience  estimates  must  accurately  represent  the  current  and  changing 
populations  of  Whites,  Blacks,  Hispanics  and  Asians  not  just  in  total  number  but 
demographically within each of those populations. 

While the data collection instrument must be designed to accurately collect view-
ing, no data collection device can eliminate the bias of a reporting sample that does 
not  accurately  represent  the  universe  being  measured.  Television  ratings  services 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00024 Fmt 6633 Sfmt 6621 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

21 

must  make  decisions  on  the  data  collection  tool  and  methodology  which  best  cap-
tures viewing within the cost parameters the individual market can support. 

Installing  and  maintaining  a  representative  sample  is  difficult.  It  takes  properly 
trained personnel, adherence to procedures and continuous testing to search for im-
provements.  It  requires  a  commitment  to  standards.  The  minimum  standards  of 
l975 no longer meet the challenges of audience measurement in 2005. Quality meas-
urement  requires  constant  third  party  monitoring  to  ensure  proper  procedures  are 
identified  and  followed.  The  MRC  provides  that  function  through  continuing  audit 
and review. 

The  MRC  Television  Committee  is  made  up  of  users  of  the  audience  estimates: 
broadcast networks, cable networks, stations, agencies and advertisers. For the past 
6  years  I  have  attended  all  MRC  meetings  related  to  television  audience  measure-
ment.  I  strongly  believe  the  MRC  audit  process  has  contributed  to  the  continuous 
improvement  of  the  quality  of  TV  audience  measurement.  Attendees  of  these  meet-
ings invest a significant amount of time reading and analyzing audit reports. Meet-
ings  are  long  and  detailed.  They  are  well  attended.  No  one  is  allowed  to  vote  with-
out the investment of time in the understanding of the audit issues. Nielsen receives 
a copy of the audit report prior to distribution to the committee and their comments 
are  included  in  the  report  sent  to  the  committee  and  in  the  discussion  and  review 
of the audit. 

New  technologies  must  be  audited  before  being  put  into  production.  New  editing 
rules, processing rules, sample design and maintenance procedures should be evalu-
ated  and  their  impact  on  audience  estimates  dimensioned  prior  to  implementation 
to  ensure  continuation  of  quality  standards.  Prior  to  2004,  I  can  remember  no  in-
stance when Nielsen implemented any material changes in methodology, processing 
rules or data collection device without prior review and acceptance by the MRC. 

Nielsen  has  said  in  recent  public  statements  that  mandatory  accreditation  would 
result  in  termination  of  the  Nielsen  Hispanic  Station  Index  (NHSI),  the  local  His-
panic  measurement  service.  While  different  sampling  procedures  are  used  in  some 
NHSI  markets,  there  is  no  reason  to  believe  they  could  not  either  as  currently  de-
signed  or  with  modifications  meet  MRC  standards  or  that  increasing  the  Hispanic 
samples  in  the  NSI  service  could  not  provide  reliable  Hispanic  audience  estimates. 
For  approximately  40  years  Nielsen’s  local  and  national  television  measurement 
services have been audited and accredited. Nielsen has met the MRC quality stand-
ards and continuously strived for improvement. It has made them a better company 
and allowed the television industry to grow. 

Univision has taken a neutral position on the FAIR Ratings Bill. We take a very 
strong position on the need for quality samples and procedures for eliminating bias. 
We take a positive position on the need for MRC audits. 

I  would  like  to  thank  the  Committee  for  the  opportunity  to  appear  here  today, 

and I look forward to answering any questions. 

Senator BURNS. Thank you very much. 
Now  we’ll  hear  from  Ms.  Kathy  Crawford,  President,  Local 

Broadcast, MindShare Worldwide. 

And thank you for coming, Ms. Crawford. 

STATEMENT OF KATHY CRAWFORD, PRESIDENT, 

LOCAL BROADCAST, MINDSHARE 
Ms. CRAWFORD. Good afternoon, Senator Burns. 
My name is Kathy Crawford, and I am President of Local Broad-
cast  at  MindShare.  In  this  position,  I  help  our  clients  decide  what 
television station to advertise on in 210 local TV markets. 

In  the  last  few  years,  we  have  spent  billions  of  dollars  in  local 
TV. Advertising makes local television possible. Almost all local tel-
evision revenues come from major companies employing millions of 
people  trying  to  reach  customers.  But  the  bill  we  are  discussing 
today  was  not  written  with  them  in  mind.  In  fact,  I  am  very  con-
cerned  that  this  bill  will  make  it  harder  for  clients  to  buy  adver-
tising  with  any  confidence  that  they  are  spending  their  money 
wisely.  As  I  see  it,  the  bill  has  negative  implications,  not  only  for 
the  Local  People  Meter  markets,  but  also  for  all  local  markets.  I 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00025 Fmt 6633 Sfmt 6601 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

22 

believe  it  will  make  my  clients  far  less  willing  to  advertise  with 
local television stations, because we won’t have the information we 
need to negotiate fair rates with the stations. 

Over  the  past  40  years,  the  MRC  has  been  a  crucial  partner  in 
improving  the  quality  of  television  ratings,  but  I  am  concerned 
that, given the MRC member—giving the MRC members the power 
to block new technologies and new services will turn back the clock. 
Clearly, the business of television advertising is changing. When 
the  MRC  was  created,  broadcast  was  synonymous  with  television. 
But  today  there  are  scores  of  cable  networks,  like  Oxygen,  Spike, 
Black  Entertainment  Television,  Galavision,  as  well  as  local  cable 
channels appealing to many more ethnically-diverse portions of the 
community.  We  clearly  need  new  ratings  technology  to  keep  up 
with  these  changes,  but,  as  we’ve  seen  with  LPMs,  there’s  always 
some  resistance  to  change,  as  different  methodologies  yield  dif-
ferent rankings and change pricing. 

The same thing happened when the national broadcast networks 
and  national  advertisers  went  through  the  same  process  in  the 
1980s. Back then, no one tried to roll back this process through leg-
islation. 

With  the  Local  People  Meter,  we’ve  heard  a  great  deal  about 
fault rates. I believe this has been a red herring, an excuse to delay 
accreditation.  Indeed,  many  of  the  MRC  members  who  now  com-
plain  about  fault  rates  in  LPMs  regularly  voted  to  accredit  meter 
diary systems in which, quote/unquote, ‘‘fault rates were even high-
er.’’  If  MRC  members  are  so  concerned  about  fault  rates,  how  did 
those meter diary markets get accredited? Did the fact that broad-
casters’ ratings are higher under the diary than under LPMs have 
anything to do with this? 

We  need  an  accreditation  process  that  is  fast,  fair,  and  efficient. 
We  need  the  MRC  to  serve  its  traditional  role  as  a  forum  for  the 
industry  to  improve  the  overall  performance  of  the  measurement 
services. 

To that end, I believe the MRC’s voting procedures need to be se-
riously  overhauled.  Currently,  a  handful  of  the  broadcast  compa-
nies  can  control  the  MRC,  because  they  have  four  to  five  votes 
each,  through  their  ownership  of  cable  networks,  local  television 
stations,  syndication  networks,  and  national  networks.  I  don’t 
think  that  is  right.  But  if  you  do  try  to  change  the  MRC  from  a 
voluntary  industry  group  into  a  government-mandated  regulatory 
body, I don’t think anyone with a direct stake in the outcome of the 
vote should be in the MRC at all, given their incentive to vote their 
own self-interest. And if the MRC has different membership struc-
ture,  who  would  choose  the  members,  and  who  would  they  report 
to? 

Finally,  what  would  an  overhaul  like  this  cost,  and  who  would 
pay  for  it?  As  we’ve  seen  in  the  past,  the  television  industry  has 
not  wanted  to  pay  for  more  than  one  service.  That’s  too  bad,  be-
cause  I,  for  one,  would  like  to  see  more  competition  in  the  ratings 
business.  I  think  it  would  be  good  for  all  of  us,  including  Nielsen, 
because  it  would  drive  innovation  faster  and  further.  But  legisla-
tion  won’t  achieve  that  goal.  To  the  contrary,  this  will  effectively 
ensure  that  Nielsen  never  again  faces  any  competition.  No  com-
pany  would  invest  the  vast  amount  of  time,  resources,  and  dollars 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00026 Fmt 6633 Sfmt 6601 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

23 

needed to start a measurement service if they knew it could remain 
idle  for  a  year  or  more,  generating  no  revenue,  as  MRC  members 
debated  its  fate.  What  potential  Nielsen  competitor  could  afford 
that? 

This  legislation  stems  from  disagreement  among  private  compa-
nies  on  the  accuracy  of  ratings  in  certain  markets  and  among  cer-
tain  audience  segments.  What  we  have  here  is  a  complicated  tech-
nological  research  dispute  over  some  aspects  of  Nielsen’s  method-
ology that has been blown out of proportion into a would-be public- 
policy issue. 

In  this  regard,  are  current  television  ratings  adequate?  No.  Is 
there  room  for  improvement?  Always.  But  innovation  cannot  be 
mandated  by  the  government.  In  fact,  we’ve  seen  many  times  in 
the past when the government tries to interfere in the private sec-
tor, no matter what its good intentions, it usually makes the situa-
tion worse. 

The  MRC  has  played  an  important  role,  over  the  past  40  years, 
in making television the best-measured medium. Like any other in-
stitution,  it  can  operate  better.  But  I  believe  the  members  of  the 
MRC,  as  private  businesses  operating  in  the  free-enterprise  sys-
tem, can certainly work out for themselves how to make the organi-
zation more effective. 

Thank you. 
[The prepared statement of Ms. Crawford follows:] 

PREPARED STATEMENT OF KATHY CRAWFORD, PRESIDENT, 

LOCAL BROADCAST, MINDSHARE 

Good afternoon. My name is Kathy Crawford and I am President of Local Broad-

cast at MindShare. 
A Global Leader in Advertising 

MindShare  advises  some  of  the  world’s  largest  advertisers  on  what  advertising 
programs  to  pursue.  We  manage  all  aspects  of  media  investment,  from  strategy— 
including  targeting  and  spending—through  negotiation  and  placement  of  adver-
tising. 

We advise our clients on the best mix of media to enable them to reach their tar-
get audiences, whether via television, print, digital or on-line, out-of-home, radio, lo-
cally  and  nationally.  Moreover,  we  negotiate  rates  and  schedules  for  our  clients, 
such  as  the  most  effective  programming  on  specific  stations  or  networks;  the  right 
magazines; or the most appropriate websites; so that they reach their targets at the 
best price. 

In  addition,  we  need  to  know  that  our  clients  are  getting  what  they  pay  for.  It’s 
not  enough  to  simply  place  an  ad.  We  also  have  to  be  assured  that  it  has  run  and 
that the right audience is being reached. 

As  President  of  Local  Broadcast  at  MindShare,  I  help  decide  what  television  sta-
tions our clients advertise on in the 210 local markets. In the last few years we have 
spent billions in local broadcasting. Nothing is more important to them than making 
sure their money is well-spent on reaching the right targets. 

Advertising  makes  local  television  possible.  Almost  all  local  television  revenues 
come  from  advertisers—the  biggest  companies  in  the  world—trying  to  reach  view-
ers, but the bill we are discussing today was not written with them in mind. 

In  fact,  I  am  very  concerned  that  this  bill  will  make  it  harder  for  clients  to  buy 
advertising with any confidence that they are spending their money wisely. As I see 
it,  the  bill  has  negative  implications  not  only  for  the  Local  People  Meter  markets, 
but  also  for  all  local  markets.  I  believe  it  will  make  my  clients  far  less  willing  to 
advertise  with  local  television  stations  because  we  won’t  have  the  information  we 
need to negotiate fair rates with the stations. Let me explain why. 
Nielsen and Television Ratings 

Today,  Nielsen  is  the  only  research  service  in  the  U.S.  that  measures  television 
audiences, both nationally and locally. There used to be two systems but the indus-

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00027 Fmt 6633 Sfmt 6621 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

24 

try  decided  it  only  wanted  to  pay  for  one.  With  just  one  ratings  service  now,  all  of 
us in the industry are well aware of Nielsen’s shortcomings and its strengths. That 
is  why  we  work  closely  with  Nielsen,  and  with  our  suppliers,  to  ensure  that  the 
methodology  is  sound.  We  also  must  be  certain  that  its  systems  deliver  the  most 
accurate  information  as  quickly  as  possible,  so  we  can  appropriately  recommend  to 
our  clients  how  best  to  spend  their  ad  dollars  and  can  negotiate  with  the  stations 
based upon those ratings. 

Because  our  industry  is  pro-active  in  seeking  and  demanding  improvements  in 
ratings systems, we are constantly working on how to better understand the chang-
ing media landscape. 

The  Local  People  Meter  is  a  product  of  this  industry-wide  effort.  Nielsen  did  not 
decide to offer LPMs in a vacuum. This was a collective decision reached by the en-
tire  television  industry  because  advertisers  were  no  longer  willing  to  spend  billions 
of dollars on advertising based on ratings from outmoded systems. 

When measurement systems change, there always is some resistance as different 
methodologies  yield  different  rankings  and  possibly  change  pricing  structures.  The 
national  broadcast  networks  and  national  advertisers  went  through  the  same  proc-
ess  in  the  1980s  when  Nielsen  introduced  its  National  People  Meter  in  response  to 
industry pressures and the threat of competition from AGB. The difference then was 
that no one tried to roll back this progress through legislation. 
A Changing Television Landscape 

Clearly, the business of television advertising has changed considerably since the 

Media Rating Council was established in 1964. 

Back then, the only networks on TV were known by their initials—ABC, CBS and 
NBC—and local channels were all identified by call letters. Cable was still a young 
medium, heavily regulated to keep it out of the top 100 markets. And the first com-
munication satellite—Telstar—had just been launched 2 years before. 

Moreover, no one in the industry at that time could even have imagined the con-
cept  of  time-shifting,  when  people  can  watch  a  particular  show  when  they  want  to, 
not when the networks program it for them. 

In short, when the MRC was created, broadcast was synonymous with television. 
Obviously,  that’s  no  longer  the  case.  Today,  there  are  scores  of  cable  networks 
with  more  expressive  names  like  Oxygen,  Spike,  Black  Entertainment  Television, 
Galavision,  as  well  as  local  cable  channels  appealing  to  many  more  ethnically  di-
verse  portions  of  the  community.  Each  caters  to  very  different  audiences,  and  myr-
iad advertisers and their agencies work very hard to reach them. 

The  skies  are  filled  with  satellites  beaming  programming  around  the  world.  And 
everyone  in  the  industry  is  familiar  with  Video  on  Demand  and  Digital  Video  Re-
corders such as TiVo. 

With  the  proliferation  of  cable  and  satellite,  television  viewers  have  more  choices 
than  ever  before,  and  this  certainly  has  affected  ratings.  Viewing  has  not  declined 
but  it  is  now  spread  among  more  program  sources,  resulting  in  lower  ratings  for 
some  broadcaster  networks,  and  many  more  cable  networks  getting  some  ratings 
were  none  had  previously  existed.  Advances  in  technology  also  have  given  people 
many  more  options  beyond  television,  including  the  Internet,  mobile  phones  and 
video gaming. 
The Role of the Media Rating Council 

As  the  television  universe  expands,  my  clients—the  major  advertisers—demand 

the most accurate and reliable ratings system possible. 

American television today is the best measured advertising medium in the world. 
It is the only U.S. medium that uses electronic meters, which are far more accurate 
than  the  diaries  that  measure  radio  or  the  surveys  that  measure  newspapers  and 
magazines. 

But  I  am  concerned,  Senator  Burns,  that  your  bill,  by  giving  the  MRC  member-
ship the power to block new technologies and new services, will turn back the clock 
on  the  progress  we  have  made  in  developing  an  effective  television  ratings  system. 
The  MRC  staff  is  composed  of  business  professionals  whose  job  include  making 
sure  that  the  ratings  that  are  used  in  the  industry  meet  the  highest  standards  for 
accuracy.  They  do  this  by  insisting  on  transparency  to  all  the  participants  in  the 
market,  reviewing  independent  audits  and  working  with  measurement  services  to 
adopt better technologies and more rigorous procedures. 

However,  there  is  no  question  that  when  MRC  members  vote  on  whether  to  ap-
prove  new  technologies,  they  always,  to  some  degree,  consider  the  impact  on  their 
own  bottom  line.  Ironically,  this  resistance  to  change  makes  local  broadcasting  a 
less attractive option for my clients. 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00028 Fmt 6633 Sfmt 6621 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

25 

As it’s currently constituted, the MRC is still dominated by broadcasters. In some 
cases,  large  broadcasting  companies—through  their  co-ownership  of  broadcast  net-
works,  cable  networks,  broadcast  stations,  studios  and  syndicators—have  as  many 
as  four  or  five  votes  each,  while  cable  operators,  advertising  agencies  and  adver-
tisers each have just one. 

This  means  that  just  five  or  six  major  media  companies  could  work  as  a  bloc  to 

delay ratings systems that would hurt their bottom line. 

This is not speculation. If your bill were in effect today, Nielsen would have been 
prevented from introducing Local People Meters in the country’s largest media mar-
kets  even  though  the  information  they  are  producing  there  is  much  more  accurate 
than the meter/diary systems they replaced. 

There  is  no  question  that  LPMs  are  a  superior  ratings  service.  They  have  larger 
samples,  including  more  African  American  and  Hispanic  households;  they  better 
represent  the  communities  they  measure;  and  they  provide  the  immediate  demo-
graphic  data  that  my  clients  need  to  make  advertising  decisions.  Yet  in  New  York, 
for  example,  the  MRC  still  has  not  accredited  the  LPM  service,  even  though  it  was 
ready to be introduced almost 15 months ago. How can this be? 
Fault Rates Are a Red Herring 

Over the past year, we’ve heard a great deal about LPM fault rates. I believe this 

has been a red herring—an excuse to delay accreditation. 

First,  fault  rates  are  only  one  measure  of  sample  quality—and  not  the  most  im-
portant  one.  The  composition  of  the  sample  and  the  acceptance  rate  are  all  equally 
if  not  more  important.  However,  all  pale  in  comparison  to  the  sample  size  and  the 
superior data collection technology that LPMs use. 

But  the  real  reason  I  believe  fault  rates  are  a  red  herring  is  that  many  of  the 
MRC  members  who  now  complain  about  fault  rates  in  LPMs  regularly  voted  to  ac-
credit meter diary systems in which ‘‘fault’’ rates were even higher—not only for the 
overall market, but for people of color too. 

Indeed, on a comparative set-to-set basis, fault rates have consistently been high-
er  in  metered/diary  markets  than  Local  People  Meter  markets.  What’s  more,  while 
there  are  no  exact  comparisons  for  diaries,  as  many  as  14  percent  of  diaries  re-
turned  to  Nielsen  cannot  be  used—the  equivalent  of  faulting  in  diaries.  And  then 
of course there are those diaries that are never returned at all. 

If  MRC  members  are  so  concerned  about  fault  rates,  how  did  those  meter/diary 
markets get accredited? Did the fact that broadcasters’ ratings are higher under the 
diary than under LPMs have anything to do with this? 

Like  the  broadcasters,  I  too  am  concerned  about  fault  rates  in  Chicago  and  New 
York, but I am also concerned about fault rates in Glendive, Terra Haute, and Tal-
lahassee.  If  the  MRC  sets  impossibly  high  standards  for  LPM  markets,  how  can 
they justifying setting lower standards for non-LPM markets? 
An Unworkable Bill 

In short, I believe the bill is unworkable. 
As  I  noted  earlier,  the  MRC  was  created  to  deal  with  a  television  industry  that, 
essentially, no longer exists. TV audiences today are becoming more diverse, subdi-
viding  into  ever-smaller  segments.  In  response,  newer  networks  and  channels  are 
emerging to better serve these niche markets. Instead of 4–6 channels, the average 
U.S. household now receives in excess of 130 channels. 

At  the  same  time,  the  viewer  is  becoming  the  boss.  Growing  numbers  of  people 

are using digital technologies to choose what, when and how they watch. 

In  other  words,  we  need  an  accreditation  process  that  is  fast,  fair  and  efficient. 
None  of  which  is  attainable  under  the  pending  legislation,  because  the  MRC  was 
not created to be an objective standard-setting organization. 

The  MRC  should  however  serve  its  traditional  role  as  a  forum  for  the  industry 
to  improve  the  overall  performance  of  the  measurement  services.  To  that  end  I  be-
lieve the MRC’s voting procedures need to be seriously overhauled. Senator, I know 
you  support  the  concept  of  one-person/one  vote  and  I  assume  you  do  not  believe  it 
is fair for one company to have five votes and another to have only one. 

If  you  try  to  change  the  MRC  from  an  industry  group  working  to  improve  the 
services  offered,  and  try  to  make  it  a  more  regulatory  body,  we  would  have  to  con-
sider  whether  anyone  with  a  stake  in  the  outcome  of  the  votes  should  be  in  the 
MRC  at  all,  given  their  incentive  to  vote  their  own  self-interest.  And  if  the  MRC 
has  a  different  membership  structure,  who  would  choose  the  members  and  who 
would they report to? 

Finally, what would an overhaul like this cost and who would pay for it? 
In  a  free  market,  broadcasters,  cable  operators,  advertisers  and  their  agencies, 
among others, should be willing to foot the bill if they believe such changes are fea-

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00029 Fmt 6633 Sfmt 6621 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

26 

sible and beneficial. Just as they should be willing to pay for more than one rating 
service if they think that’s a practical solution. 

Still, as we’ve seen in the past, the broadcast industry has been unwilling to help 
finance  more  than  one  service.  That’s  too  bad,  because  I,  for  one,  would  like  to  see 
more  competition  in  the  ratings  business.  I  think  it  would  be  good  for  all  of  us,  in-
cluding Nielsen, because it would drive innovation faster and further. 

But  legislation  won’t  achieve  that  goal.  To  the  contrary,  this  will  effectively  en-

sure that Nielsen never again ever faces any competition. 

No  company  would  invest  the  vast  amount  of  time,  resources  and  dollars  needed 
to  start  a  measurement  service  if  they  knew  it  could  remain  idle  for  a  year  or 
more—generating  no  revenue—as  MRC  members  debated  its  fate.  What  potential 
Nielsen competitor could afford that? 
Trying to Legislate a Business-to-Business Issue 

I believe this legislation stems from a disagreement on the accuracy of ratings re-
porting in certain markets and among certain audience segments. It proposes exter-
nal,  mandatory  regulation  of  a  system  that  is  in  many  ways  self-regulating,  where 
participants themselves—buyers, sellers, stations—engage in ongoing dialogue about 
the system. 

Underlying our dialogue is the agency’s responsibility to its clients, and ultimately 
the clients’ responsibility to its customers (the same customers the television station 
is trying to reach with its programming). Also important is the broadcasters’ respon-
sibility  toward  dual  constituencies:  the  viewers  as  well  as  the  advertisers.  Con-
sequently, it is in everyone’s best interest that the public is served. 

What we have then is an industry research dispute over whether Nielsen’s meth-
odology accurately reports the size of the audience and how these procedures might 
be improved to more accurately report viewer behavior. 

It is not a question of whether a broadcaster is serving the public interest. Rather, 
it  is  a  matter  of  whether  the  yardstick  by  which  audiences  are  measured  does  so 
accurately.  Not  acknowledging  the  relationship  among  advertisers,  audiences,  and 
broadcasters would dampen the dialogue that seeks to improve the system. 
The Free Market as the Solution 

The founders of the Media Rating Council couldn’t have predicted what television 
would be like in the 21st century. But they did have the foresight to explicitly reject 
government  oversight  because  they  recognized  the  negative  impact  on  innovation 
and competition. 

That, at least, has not changed in over 40 years. 
Attempts  to  roll  back  the  clock  by  eliminating  systems  like  Local  People  Meters, 
or by slowing down the development of new technologies that measure time-shifting 
and on-demand services, will not stop change. 

Is this regard, are current television ratings fully adequate? No. Is there room for 
improvement?  Always.  But  innovation  cannot  be  mandated  by  the  government.  In 
fact we’ve seen many times in the past that when the government tries to interfere 
in the private sector—no matter what its good intentions—it usually makes the situ-
ation worse. 

The  MRC  has  played  an  important  role  over  the  past  40  years  in  making  tele-
vision the best measured medium. Like any other institution, it can operate better. 
But I believe the members of the MRC—as private businesses operating in the free 
enterprise system—can certainly work out for themselves how to make the organiza-
tion more effective. 

Thank you. 

Senator BURNS. Thank you. 
And  we’ll  hear  now  from  Gale  Metzger,  former  CEO,  SMART 

And  thank  you  for  coming  today.  Oops,  did  I  miss  somebody?  I 

Let’s  call  on  Mr.  Pat  Mullen,  who  is  President,  Tribune  Broad-

Media. 

did. 

casting. 

Pull your microphone up, if you would, Mr. Mullen, please. 
Mr. MULLEN. Certainly. 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00030 Fmt 6633 Sfmt 6601 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

27 

STATEMENT OF PATRICK J. MULLEN, PRESIDENT, 

TRIBUNE BROADCASTING COMPANY 

Mr. MULLEN. Mr. Chairman, thank you for the opportunity to ap-
pear before you to testify in support of S. 1372, which will go a long 
way  toward  assuring  that  there  is  a  strong,  independent  body  to 
ensure the reliability of television-audience measurement. 

My name is Pat Mullen. Our company, Tribune Broadcasting, op-
erates 26 major-market television stations located in 15 states from 
coast  to  coast,  including  stations  in  8  of  the  10  largest  markets. 
Our  station’s  success  has  depended,  in  every  case,  on  accurate 
count of our audiences. Our stations get a report card every morn-
ing from Nielsen. These ratings determine which programs remain 
on the air. We’re eager to compete with our fellow broadcasters and 
with cable and satellite, but to do this we must have an honest re-
port card. 

Mr. Chairman, I regret to say that the measurement system that 
we have today in the largest television markets is not worthy of the 
public trust. Congress has repeatedly acknowledged the importance 
of a free and robust broadcast service, which is particularly impor-
tant in times of crisis. It deserves a guaranteed minimum standard 
of accuracy because of the importance of television news, public af-
fairs, sports, and entertainment programming to this country’s cul-
ture and to our democracy. 

We are not here today in an attempt to secure a competitive ad-
vantage  over  our  competitors.  Our  company  welcomes  competition. 
The  problem,  Mr.  Chairman,  is  that  the  keys  to  our  success,  our 
ratings,  are  held  by  a  monopoly.  When  Nielsen  had  a  competitor, 
its  service  and  its  response  to  client  concerns  were  substantially 
better  than  they  are  today.  In  absence  of  competition,  we  are  left 
to  plead  for  fair  treatment  and  reliable  results.  Time  and  again, 
Nielsen has turned us away. 

We  have  no  choice  but  to  do  business  with  Nielsen.  And  despite 
recent ratings challenges, our company has always had a good rela-
tionship  with  Nielsen.  So,  we  are  here  today  reluctantly,  but  with 
a sense of urgency. 

In  1964,  the  Media  Ratings  Council  was  established,  at  the  urg-
ing  of  Congress.  The  MRC’s  mission  is  to  maintain  confidence  in 
audience  research  and  to  secure  measurement  services  that  are 
valid,  reliable  and  effective.  Historically,  participation  in  the  MRC 
process has been voluntary. The MRC cannot force anyone to com-
ply  with  its  procedures.  The  Local  People  Meter  Service  that 
Nielsen has implemented in New York and Chicago and other mar-
kets  has  yet  to  be  accredited  by  the  MRC.  And  without  quoting  a 
myriad  of  numbers,  it  is  worth  nothing  that  in  New  York,  on  the 
average  day  for  the  week  ending  July  10,  the  viewing  choices  of 
nearly one-third of Black and Hispanic men ages 18–34 in the LPM 
sample  were  not  reflected  in  the  ratings.  Despite  this,  Nielsen  has 
just  launched  the  LPM  service  in  Washington,  D.C.,  and  Philadel-
phia, without MRC accreditation. It is clear to me that Nielsen sub-
mits  to  the  MRC  processes  only  when  it  suits  its  aggressive  busi-
ness strategies. 

In  numerous  meetings,  e-mails,  and  letters  over  the  past  year, 
Tribune  has  pointed  out  defects  in  the  Nielsen’s  LPM  sample. 
Nielsen  has  acknowledged  the  difficulties  and  has  promised  to  fix 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00031 Fmt 6633 Sfmt 6601 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

28 

these  problems.  But,  despite  Nielsen’s  effort,  it  has  failed  to  fix 
these problems. 

For  these  reasons,  in  a  letter  dated  May  25,  2005,  Tribune  and 
17 other broadcast companies urged Nielsen to postpone the sched-
uled  deployment  of  the  LPM  service  in  Philadelphia  and  Wash-
ington,  D.C.,  Nielsen  refused.  In  response,  the  MRC,  under  the 
guidance of Executive Director and CEO George Ivie, recommended 
a  meeting  between  Nielsen  and  either  the  MRC’s  Television  Com-
mittee  or  the  full  board,  or  that  Nielsen  participate  in  the  MRC 
mediation process. Broadcasters accepted, with a preference for me-
diation. Nielsen refused both. 

Finally, on June 28, the MRC Board of Directors approved a res-
olution recommending that Nielsen offer LPM service in additional 
markets  only  after  completing  an  MRC  audit.  Nielsen—or,  excuse 
me, Tribune then asked Nielsen to accept the MRC Board’s resolu-
tion  and  delay  the  scheduled  launch  in  Philadelphia  and  Wash-
ington, D.C. Nielsen’s response again was an immediate no. 

Had  Nielsen  been  more  responsive  to  these  concerns  of  broad-

casters and of the MRC, I doubt that we would be here today. 

A  promising  new  measurement  service,  Arbitron’s  Portable  Peo-
ple  Meters  System,  is  being  tested  in  the  Houston  market.  This 
new  passive  technology  measures  both  television  and  radio  audi-
ences. Arbitron has licensed this technology in Singapore, Norway, 
and  Canada.  Unfortunately,  Nielsen  has  the  contractual  option  to 
form  a  joint  venture  with  Arbitron  to  market  the  PPM  television 
service  in  the  United  States.  Because  PPMs  are  an  alternative  to 
Nielsen’s  proprietary  LPM  service,  it  appears  highly  unlikely 
Nielsen  will  allow  the  PPM  technology  to  compete  with  its  LPM 
service. 

Throughout  Tribune’s  long  history,  we  very  rarely  have  peti-
tioned for Federal intervention in the marketplace; however, in this 
case,  despite  our  efforts,  we  simply  do  not  have  the  ability  to  per-
suade Nielsen to submit to voluntary MRC processes. And because 
Nielsen  is  a  monopoly,  we  have  nowhere  else  to  turn  to  get  accu-
rate and reliable ratings. 

S. 1372, the FAIR Ratings Act, would correct this market failure. 
The bill would not impose any undue burden on parties to the proc-
ess and would enable the MRC to fulfill its mission. 

In  my  written  testimony,  I  provided  examples  and  written  com-
munications 17 showing  that  we  are  not  dealing  with  a  trivial  dis-
pute  or  sour  grapes  because  our  ratings  are  down.  And  after  more 
than  a  year’s  experience  in  New  York  and  Chicago,  the  LPM  sys-
tem continues to be embarrassingly defective. 

Clearly, the free market cannot solve this problem, which is a se-
rious one. Free over-the-air broadcasters, unlike our cable and sat-
ellite competitors, depend on a single revenue stream, which is de-
rived  from  advertising.  We  do  not  charge  a  subscriber  fee,  and  we 
make our service available free to all. Accurate and reliable ratings 
are keys to the health of our business. 

Mr.  Chairman,  we  appreciate  your  allowing  us  to  take  the  time 
today to express our views and urge the Committee to favorably re-
port S. 1372. 

17 Information referred to has been retained in Committee files. 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00032 Fmt 6633 Sfmt 6601 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

29 

Thank you. 
[The prepared statement of Mr. Mullen follows:] 

PREPARED STATEMENT OF PATRICK J. MULLEN, PRESIDENT, 

TRIBUNE BROADCASTING COMPANY 

Mr.  Chairman  and  members  of  the  Committee,  thank  you  for  the  opportunity  to 
appear  before  you  today  to  testify  in  support  of  S.  1372,  which  will  go  a  long  way 
toward  assuring  that  there  is  a  strong  independent  body  to  oversee  the  reliability 
of television audience measurement. 

My  name  is  Pat  Mullen.  Our  company,  Tribune  Broadcasting,  operates  26  major 
market television stations located in 15 states from coast to coast, including stations 
in 8 of the 10 largest markets. 

All  of  these  TV  stations  are  what  used  to  be  called  ‘‘independent’’  stations—local 
stations  that  did  not  have  the  legacy  of  a  network  identification  to  hold  loyal  view-
ers  year  after  year.  Through  innovative  local,  sports  and  syndicated  programming, 
Tribune’s  stations  have  provided  viewers  with  an  alternative  to  the  ‘‘traditional’’ 
networks,  attracting  viewers  to  programs  they  could  not  find  elsewhere.  Their  suc-
cess has depended in every case on an accurate count of our audience. New stations, 
small  stations,  UHF  stations,  as  well  as  broadcast  pioneer  stations  like  WGN–TV 
in Chicago, KTLA in Los Angeles and WPIX in New York, have found they can com-
pete  and  succeed  if  they  provide  new  and  better  programming  options  for  viewers. 
Our  stations  get  a  report  card  every  morning  from  Nielsen.  Those  ratings  deter-

mine the viability of our business. 

• They determine the value of our advertising. 
• This  in  turn  determines  how  much  money  can  be  invested  in  new  and  better 
• And ratings also determine which programs remain on the air, and which ones 

programming, and in new digital technology. 

will be taken off for apparent lack of viewer interest. 

Today,  all  but  one  of  Tribune’s  television  stations  have  affiliated  with  the  newer 
networks,  The  WB  and  Fox.  We  are  eager  to  compete  with  our  fellow  broadcasters, 
and  with  the  ever-increasing  number  of  networks  vying  for  viewers’  attention  over 
cable  and  satellite.  But  to  do  this  we  must  have  an  honest  report  card.  A  trust-
worthy measurement of the size and composition of each competitor’s audience. 

Mr. Chairman, I regret to say that the measurement system we have today in the 
largest  television  markets  is  not  worthy  of  public  trust.  It  does  not  have  the  trust 
of our company or that of more than a dozen other responsible broadcasters. 

Congress has repeatedly acknowledged the importance of a free and robust broad-
cast  service,  which  is  particularly  important  in  times  of  crisis.  We  believe  the  sys-
tem  of  over-the-air  television  in  America  demands  statistically  valid  and  reliable 
measurement  of  its  audience.  It  deserves  a  guaranteed  minimum  standard  of  accu-
racy  because  of  the  importance  of  television  news,  public  affairs,  sports  and  enter-
tainment programming to this country’s culture and to our democracy. 

In times of crisis, from hurricanes in Florida to fires in California, when the cable 
is  out  and  satellite  service  is  interrupted,  broadcasters  serve  as  the  first  responder 
on  the  scene,  transmitting  potentially  life  saving  information  to  our  fellow  citizens. 
We are proud of that record of service. It may prove even more vital if, as in London 
and Madrid, terrorist attacks continue to spread beyond the war zone in the Middle 
East. 

But  we  are  not  here  today  in  an  attempt  to  secure  an  advantage  over  our  multi- 
channel  competitors  or  to  slow  the  erosion  of  our  audiences  caused  by  the  growing 
choices available to viewers. Our company welcomes competition. 

The  problem,  Mr.  Chairman,  is  that  the  keys  to  our  success—our  ratings—  are 
held  by  a  monopoly.  When  Nielsen  had  a  competitor,  its  service  and  its  response 
to  client  concerns  were  substantially  better  than  they  are  today.  In  the  absence  of 
competition,  we  are  left  to  plead  for  fair  treatment  and  reliable  results.  Time  and 
time again, Nielsen has turned us away. 

We  have  no  choice  but  to  do  business  with  Nielsen.  Ratings  are  the  currency  on 
which  the  advertising  business  operates.  And  despite  recent  challenges,  our  com-
pany has always had a good relationship with Nielsen. So we are here today reluc-
tantly, but with a sense of urgency. 

In  1964,  the  Media  Rating  Council  was  established  at  the  urging  of  Congress.  It 
is a nonprofit organization whose membership includes representatives of broadcast 
TV and radio, cable television, print, advertisers, ad agencies, and now Internet con-
stituencies.  The  MRC’s  mission  is  to  maintain  confidence  in  audience  research  and 
secure  measurement  services  that  are  valid,  reliable  and  effective.  MRC  does  this 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00033 Fmt 6633 Sfmt 6621 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

30 

through  audits  to  test  the  methodology  and  credibility  of  research  services,  and  ac-
creditation  to  certify  services  that  meet  the  MRC’s  minimum  standards.  Research 
services must disclose their data to the MRC to enable it to validate their measure-
ments. 

The Media Rating Council is a classic example of industry self-regulation. It con-
sumes no tax dollars nor requires government oversight. It does its job quietly, pro-
fessionally and efficiently, with participation by all segments of the industry. In our 
experience  the  MRC  has  never  been  used  for  private  gain  by  one  member  over  an-
other, or to delay or stop innovation. The very existence of the MRC’s auditing and 
accreditation  processes,  and  its  diverse  make-up,  tend  to  keep  participants  honest. 
Historically,  participation  in  the  MRC’s  processes  has  been  voluntary.  The  MRC 
cannot  force  anyone  to  comply  with  its  procedures,  and  it  cannot  require  a  ratings 
service  to  submit  to  an  audit  or  to  offer  only  accredited  measurement  services.  Un-
fortunately,  Nielsen  has  chosen  to  ignore  the  MRC’s  guidance  in  deploying  Local 
People Meter (LPM) service. 

The LPM service that Nielsen has implemented in New York and Chicago has yet 
to be accredited by the MRC. It is worth noting here that in New York, on the aver-
age day for the week ending July 10, the viewing choices for nearly one-third of the 
Black  and  Hispanic  men  ages  18–34  in  the  Nielsen  LPM  sample  were  not  reflected 
in  the  ratings.  (Additional  detail  is  available  in  the  attachments  to  this  testi-
mony.)** 

Despite  these  kinds  of  obvious  flaws,  Nielsen  has  just  launched  its  LPM  service 
in  Washington,  D.C.  and  Philadelphia—also  without  MRC  accreditation.  It  is  clear 
to me that Nielsen submits to MRC processes only when it suits its aggressive busi-
ness strategies. 

Tribune has tried to work constructively with Nielsen and to suggest ways to im-
prove  audience  measurement.  In  numerous  meetings,  e-mails  and  letters  over  the 
past  year,  Tribune  has  pointed  out  defects  in  Nielsen’s  LPM  sample  and  faulting 
rates.  The  problems  being  presented  have  led  to  significant  under-reporting  of  im-
portant audience segments. Nielsen has acknowledged difficulties and has promised 
to fix the problems. But despite Nielsen’s efforts, it has failed to fix these problems. 
For these reasons, in a letter dated May 25, 2005, Tribune and 17 other broadcast 
companies  embraced  the  new  technology  but  urged  Nielsen  to  postpone  the  sched-
uled  deployment  of  LPM  service  in  Philadelphia  and  Washington  until  the  MRC 
deemed the system reliable in markets where it was already being used. 

Nielsen responded the following day. It said ‘‘the broadcast group request for some 
sort  of  mandatory,  prior  MRC  accreditation  raises  considerable  antitrust  concerns.’’ 
Nielsen rejected the industry’s proposal and the legitimate concerns detailed in our 
letter. 

In response, the MRC, under the guidance of Executive Director/CEO George Ivie, 
recommended  a  meeting  between  Nielsen  and  either  the  MRC’s  Television  Com-
mittee  or  the  full  MRC  Board,  or  that  Nielsen  participate  in  the  MRC  mediation 
process.  Broadcasters  said  we  would  accept  either  approach,  with  a  preference  for 
mediation.  Nielsen  refused  both,  saying  mediation  would  be  ‘‘unnecessarily  cum-
bersome and time consuming.’’ 

Finally,  on  June  28,  the  MRC’s  Board  of  Directors  approved  a  resolution  recom-
mending that Nielsen offer LPM service in additional markets only after completing 
an  MRC  audit.  Tribune  then  asked  Nielsen  to  accept  the  MRC  Board’s  resolution, 
delaying  the  scheduled  LPM  launch  in  Philadelphia  and  Washington.  Nielsen’s  re-
sponse was an immediate, ‘‘No.’’ 

So  the  company  continues  to  ignore  the  legitimate  concerns  of  its  customers  and 
the  MRC.*  Its  actions  are  those  of  the  classic  unregulated  monopoly,  accountable 
to  no  one.  Had  Nielsen  been  more  responsive  to  broadcasters’  or  the  MRC’s  con-
cerns, I doubt we would be here today. 

A  promising  new  measurement  service,  Arbitron’s  portable  people  meter  (PPM), 
is  being  tested  in  the  Houston  market.  This  new  technology  measures  both  tele-
vision  and  radio  signals,  and  I  believe  Arbitron  plans  to  use  this  system  for  radio 
ratings starting in 2006. Arbitron has licensed this technology in Singapore, Norway 
and  Canada.  Although  Arbitron  is  managing  this  test,  Nielsen  has  the  contractual 
option to form a joint venture with Arbitron to market PPM television service com-
mercially in the United States. Thus, it is our understanding that Nielsen could ef-
fectively control how and when PPM technology will be deployed for television meas-
urement.  Because  PPMs  are  an  alternative  to  Nielsen’s  proprietary  LPM  service,  it 

** Attachments retained in Committee files. 
* Correspondence submitted with this testimony documents this frustrating process. The sub-

mitted material has been retained in Committee files. 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00034 Fmt 6633 Sfmt 6621 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

31 

appears  highly  unlikely  Nielsen  will  allow  the  PPM  technology  to  compete  with  its 
LPM service. 

We hope this testimony makes clear the need for government intervention in this 
critical  segment  of  the  U.S.  economy.  Throughout  Tribune’s  long  history  in  both 
print and broadcast journalism, we very rarely have petitioned for Federal interven-
tion  in  the  marketplace.  Like  many  of  my  fellow  broadcasters,  I  personally  have 
spent  many  days  trying  to  reach  a  private  solution  to  this  problem  with  Nielsen. 
We simply do not have the ability to persuade Nielsen to submit to MRC processes 
and  roll  out  its  new  measurement  systems  only  after  they  have  proved  reliable  to 
an independent and expert body, the Media Rating Council. 

And because Nielsen is a monopoly, we have nowhere else to turn to get accurate 

and reliable ratings. 

S.  1372,  the  FAIR  Ratings  Act,  would  correct  this  market  failure  by  requiring 
MRC  accreditation  before  the  commercial  introduction  of  any  commercial  ratings 
measurement  system.  The  dispute  resolution  system  established  by  the  bill  would 
provide ready means to test the reliability of new measurement systems, and would 
encourage companies that design them to vet them thoroughly, ensuring their credi-
bility  and  integrity  before  they  are  launched  commercially.  The  bill  would  not  im-
pose any undue burden on parties to the process, and would enable the Media Rat-
ings Council to fulfill its mission of encouraging the development of reliable and im-
proved ratings measurement systems, which we fully support. 

The  examples  included  in  this  report  demonstrate  that  we  are  not  dealing  with 
a  trivial  dispute  or  sour  grapes  because  our  ratings  are  down.  After  more  than  a 
year’s experience in New York and Chicago, the LPM system continues to be embar-
rassingly defective. 

Sampling issues abound, including problems with response rates, in-tab represen-

tation and fault rates. For example: 

• New York’s LPM response rate averaged 25.3 percent for the week ending July 
3,  2005.  This  means  that  3  out  of  every  4  households  initially  designated  as 
sample  households  refused  installation  of  a  people  meter  in  their  home  or  ac-
cepted a meter but did not contribute any viewing data. 

• Young  men  ages  18–34  have  been  persistently  under-represented  in  Boston, 
Chicago,  Los  Angeles,  New  York,  Philadelphia  and  San  Francisco.  Fault  rates 
for  men  18–34  generally  are  twice  as  high  as  those  for  men  ages  55+  in  LPM 
samples. 

• Fault rates remain unacceptably high for important audience segments such as 
African Americans and Hispanics despite new coaching initiatives. On the aver-
age day in New York for the week ending July 10, the viewing choices of nearly 
one-third  of  the  Black  and  Hispanic  men  ages  18–34  in  the  LPM  sample  were 
not reflected in the ratings. 

• Chicago sample data for the week ending July 10th show that almost one-third 
of the 443 African Americans installed in the sample were not in tab—meaning 
their television viewing was not counted in the ratings. 

• Households  of  5  persons  or  more  have  been  persistently  under-represented  in 
the total samples in New York, Los Angeles, Chicago and Boston. In New York, 
for  the  week  ending  July  10,  the  viewing  choices  of  more  than  1  in  4  of  the 
Black  and  Hispanic  households  of  5  or  more  persons  in  the  LPM  sample  were 
not reflected in the ratings. 

• Fault  rates  for  households  of  5  or  more  are  generally  2  to  3  times  as  high  as 

in one-person households. 

Clearly,  the  free  market  cannot  solve  this  problem,  which  is  a  serious  one.  Free 
over-the-air  broadcasters,  unlike  our  cable  and  satellite  competitors,  depend  on  a 
single  revenue  stream,  which  is  derived  from  advertising.  We  do  not  charge  a  sub-
scriber fee, and we make our service available free to all. Accurate and reliable rat-
ings are key to the health of our business. Mr. Chairman, we appreciate your allow-
ing us the time to make our views known, and urge the Committee to favorably re-
port S. 1372. 
Thank you. 

Senator BURNS. Thank you very much. 
Now  we’ll  have  Mr.  Gale  Metzger,  Former  President,  Statistical 

Research Inc. 

Thank you for coming today. 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00035 Fmt 6633 Sfmt 6601 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

32 

STATEMENT OF GALE METZGER, FORMER PRESIDENT, 

STATISTICAL RESEARCH INC. 

Mr. METZGER. Thank you, Senator Burns. And thank you for the 

invitation. 

I am Gale Metzger. My entire career has been spent in the audi-
ence-measurement  arena.  I  began  at  the  A.C.  Nielsen  Company, 
and then for 32 years I was President of Statistical Research, Inc., 
a  company  that  I  founded  with  Dr.  Gerald  Glasser,  of  New  York 
University. In 1963, I participated in the Congressional hearings as 
a  Nielsen  employee.  SRI,  our  firm,  conducted  methodological  re-
search for the industry for over 30 years. In the 1990s, we created 
and operated a ratings laboratory under the name of SMART. Cur-
rently, I am a senior consultant with Knowledge Networks, Inc. 

I  appear  today  representing  myself,  my  own  views  and  interpre-
tations. There are no lawyers, no public-relations people or anyone 
else behind me telling me what to say. I speak from a lifetime’s ex-
perience  and  a  deep  commitment  to  the  understanding  that  re-
search quality makes a difference. Good information helps markets 
work better. Bad information undercuts business performance. 

I will briefly address three points: 
First,  the  Media  Rating  Council.  I  was  present  when  the  Broad-
cast  Rating  Council,  now  the  Media  Rating  Council,  was  formed.  I 
participated  in  the  debates  around  the  operating  protocols.  I  was 
the  Nielsen  person  who  was  responsible  for  structuring  the  first 
audit of its services. SRI’s Syndicated Audience Measurement Serv-
ice to the radio industry, RADAR, was audited by the MRC for over 
30 years. 

The  MRC  serves  a  vital  role  in  our  industry.  An  important  by-
product  of  its  work  is  to  encourage  innovations  and  improvements 
in  methods.  Whether  I  was  working  at,  or  owned,  a  service  that 
was being audited, the MRC helped me do a better job. If audit re-
ports  were  open  and  available  to  all  clients,  they  would  be  even 
more valuable. 

Media  ratings  systems  are  frail,  sometimes  more  so  than  we 
practitioners  like  to  admit.  To  use  information  from  these  systems 
intelligently  and  effectively,  users  need  to  know  what  is  going  on, 
and  they  need  to  know  before  the  data  hit  the  marketplace,  not 
after.  Hence,  I  agree  with  the  intent  of  the  proposed  legislation, 
which  is  that  all  services  providing  marketplace  currency  be  ac-
credited by the MRC. 

I  understand  that  Nielsen  has  expressed  objections  to  the  pro-
posals and stated they would lead to less innovation and less com-
petition.  The  opposite  would  be  true.  It  would  be  difficult  to  have 
less  competition  or  less  innovation  than  we  have  now.  And  I  must 
insert  that  I  have  a  totally  different  view  than  was  expressed  by 
Ms.  Whiting  and  Ms.  Crawford  on  the  effects  on  competition  and 
innovation. 

It is in Nielsen’s and the industry’s best interests to embrace the 
intent  of  this  legislation.  I,  further,  believe  that  complete  coverage 
of  all  services  is  what  the  industry  committed  to  achieve  in  testi-
mony before the Congress in 1963. 

Changes  in  the  industry  structure  have  made  the  MRC  even 
more important today. The networks once dominated national tele-
vision.  They  were  permitted  to  work  together  on  issues  related  to 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00036 Fmt 6633 Sfmt 6601 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

33 

methodology.  Then,  there  was  a  balance  of  power  between  Nielsen 
and  the  networks.  With  a  fragmented  medium,  no  single  client  or 
group of clients wield that much influence. In effect, if Nielsen does 
not  answer  to  the  MRC,  it  answers  to  no  one.  I  believe  this  ex-
plains,  in  part,  Nielsen’s  new,  more  aggressive  posture  with  the 
MRC. 

Nielsen and others may have particular points about the legisla-
tion  that  warrant  discussion.  I’m  confident  details  can  be  worked 
out if we have sufficient desire on the part of all concerned parties 
to  do  so.  That  has  apparently  not  been  the  case  for  the  past  year, 
so I think I understand the reasons why you, Senator Burns, intro-
duced this bill. 

Second,  why  are  we  here?  I  submit  that  we  are  here  because 
Nielsen  clients  feel  they  are  hostages  to  a  company  that  controls 
their  basic  well-being.  Further,  Nielsen  operations  are  deficient, 
and  those  deficiencies  jeopardize  those  clients’  businesses.  This  is 
not  a  manufactured  controversy.  There  is  a  real  problem.  When 
emotions  run  as  high  as  they  currently  do  among  a  large  share  of 
clients, something is not right. 

Evidence  of  the  industry’s  effort  to  bring  improvement  include 
the  network  support  of  SRI’s  methodological  research,  the  support 
of  CBS  and  others  for  the  AGB  initiative,  and,  more  recently,  the 
support  of  30  networks,  advertisers,  and  agencies  of  our  SMART 
Ratings Laboratory. 

Nielsen  deficiencies  are  several  and  significant.  Perhaps  the 
broadest complaint is that Nielsen is not responsive on data-quality 
issues  and  to  client  concerns  unless  the  threat  of  competition  is 
raised. 

The  people  meter  was  introduced  by  Nielsen  in  1987  only  after 
a  British  company,  AGB,  tried  to  enter  the  U.S.  market  with  a 
similar  meter.  Nielsen’s  new  AP  meter  was  announced  in  1995, 
only after the SMART Laboratory was underway with a new meter 
in  development.  When  SMART  went  away,  the  introduction  of  the 
AP  meter  was  delayed.  Ten  years  after  the  fact,  the  AP  meters 
have just begun to roll out. 

In  sum,  clients  will  tell  you  that  when  the  threat  of  competition 
is present, Nielsen is a different company than when, as now, there 
is no threat. 

A more specific deficiency is Nielsen’s metering technology. It has 
not  kept  pace  with  modern  media.  We  are  moving  rapidly  into  the 
21st  century  with  an  aged  20th-century  meter  platform.  The  high 
fault  rates  in  the  Nielsen  sample  is  evidence  of  their  out-of-date 
technology.  Fault  rates  are  high  because  the  meters  are  not  state- 
of-the-art.  The  fault  is  with  the  meters  and  how  they  operate.  The 
fault is not with the homes or the people in them. 

Are Nielsen’s new systems better than the old? Are the audience 
estimates  more  accurate?  The  truth  is,  no  one  knows.  And  that  is 
disconcerting. We do not know the effect of skipped homes or fault-
ing  homes.  What  is  known  is  that  Nielsen  is  producing  more  data 
and generating more revenue than ever before. 

Data  access  is  a  core  deficiency  of  Nielsen.  Clients  cannot  get  to 
information  they  need  for  decisions.  Data  access  is  an  important 
component of quality. 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00037 Fmt 6633 Sfmt 6601 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

34 

Nielsen  weighting  procedures  are  still  another  point  of  conten-

tion. 

The real problem with each of these and other deficiencies is that 
they  all  affect  audience  levels.  Some  reported  audience  ratings  are 
higher,  and  some  lower,  than  is  the  reality.  Some  organizations’ 
bottom  lines  are  improved,  and  some  are  made  worse.  This  obser-
vation  leads  to  the  last  deficiency  that  I  cite  today:  Nielsen  is  al-
most cavalier about making changes in procedures. If measurement 
techniques  change,  some  audiences  will  be  greater,  and  some  less-
er,  than  before.  The  real  audience  has  not  changed,  but  the  re-
ported audience change. Some win, some lose. The only way to pre-
pare  for  such  events  is  to  communicate  planned  changes  with  evi-
dence  to  the  benefits  to  the  industry  and  to  supply  an  abundance 
of  data.  To  force-feed  a  change  invites  disaster.  That  is  what 
Nielsen effectively did, and they reaped what they sowed. 

Nielsen  publicly  proclaimed  their  shock,  their  dismay  and  sur-
prise at the industry’s reaction to the LPM. Such reactions, to me, 
speak of posturing or a lack of understanding of their clients’ legiti-
mate concerns. 

Third, and last, the need for action. At the 1963 hearings on rat-
ings,  Chairman  Harris,  of  the  House  Committee  on  Interstate  and 
Foreign  Commerce,  referred  to  the  ratings  industry  as  being  in  an 
intolerable  situation.  Today,  many  also  feel  that  situation  is  intol-
erable. 

I see confusion in the marketplace about the nature of the prob-
lem.  More  data  does  not  equal  better  data.  Also,  it  is  unfortunate 
that  a  large  part  of  the  discussion  about  the  LPM  has  focused 
mainly on minority measurement issues. I do not believe the prob-
lem is associated only with minorities, and not only with the LPM. 
The LPM controversy is the tip of the iceberg. 

I  know  about  minority  measurements.  For  over  25  years,  SRI 
served  the  National  Black  Network  and  Sheridan  Broadcasting  as 
part of our RADAR service. Measurements for minorities should be 
judged  by  the  same  quality  standards,  and  subject  to  the  same 
audit review, as are all other media audience measurements. 

Audience  measurements  should  be  inspected  for  all  important 
population  subgroups,  but  I  do  not  believe  race  or  ethnicity  is  the 
primary  issue  with  the  LPM.  I  believe  the  issue  is  how  a  monopo-
list relates to its clients. The issue is whether these Nielsen ratings 
data, when used as currency, are really ‘‘funny money.’’ We just do 
not know enough about Nielsen research quality. 

Susan  looks  at  Nielsen  Media  Research  and  sees  a  glass  full.  I 
see  a  gallon  jug  with  a  few  drops  of  water  in  the  bottom,  sloshing 
around. 

Whether this proposed legislation goes too far, or not far enough, 
I  shall  leave  for  others  to  judge.  The  MRC  is  essential,  but  it  may 
not  be  sufficient.  Many  feel  the  need  for  a  joint  industry  effort  to 
set  specifications  and  award  an  industry  contract,  as  occurs  in 
other  parts  of  the  world.  In  that  direction,  the  Advertising  Re-
search Foundation has structured an audience measurement initia-
tive which is currently being discussed. 

Like most others here, I favor free market solutions for free mar-
kets.  Where  there  are  multiple  buyers  and  sellers,  there  is  seldom 
cause  for  the  government  to  become  involved.  However,  here  we 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00038 Fmt 6633 Sfmt 6601 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

35 

have  a  monopoly.  Legislation  may  be  the  only  way  to  get  Nielsen 
to the table, and I think this bill is the right way to go. And further 
action  may  be  needed  to  deal  with  the  possible  industry  initiative 
to further improve the situation. 

Thank you very much. 
[The prepared statement of Mr. Metzger follows:] 

PREPARED STATEMENT OF GALE METZGER, FORMER PRESIDENT, 

STATISTICAL RESEARCH INC. 

I am Gale Metzger. My first professional job was with the A. C. Nielsen Company. 
For  32  years,  I  was  President  of  Statistical  Research,  Inc.  a  media  and  marketing 
research  company  that  I  founded  with  Dr.  Gerald  Glasser  of  New  York  University. 
I have been active in the industry and served as Chairman of the Board of the Ad-
vertising  Research  Foundation  and  President  of  the  Radio  and  Television  Research 
Council and the Market Research Council. 

In 2001, SRI was sold in two parts. Our network radio measurement service went 
to  ARBITRON  and  the  other  operations  were  sold  to  Knowledge  Networks,  Inc.— 
a firm I continue to work with as a senior consultant. 

For 48 years, I have been engaged in media research. Over 40 years ago, I partici-
pated in the 1963 Congressional Hearings as a Nielsen behind-the-scenes overnight 
supplier  of  answers  to  questions  posed  by  congressional  staffers.  Fifteen  years  ago, 
at  the  request  of  key  industry  stakeholders,  our  firm  (SRI)  conducted  an  in-depth 
review of Nielsen’s newly introduced people meter system which resulted in a seven 
volume  600-page  report.  Nielsen  called  that  work  ‘‘an  outstanding  effort’’  and  the 
industry characterized it as a blueprint for progress. 

SRI  conducted  methodological  research  for  the  industry  for  over  30  years.  In  the 
1990s  we  created  and  operated  a  ratings  laboratory  under  the  name  of  SMART. 
SMART  was  an  acronym  for  Systems  for  Measuring  And  Reporting  Television.  All 
of that work was dedicated to understanding and improving measurement methods. 
The  SMART  laboratory  was  successful  in  developing  new,  user-friendly  TV  meters 
and  in  providing  audience  data  to  client  desktops  along  with  analytic  software  to 
enable  use  of  ratings  information  for  business  decisions  on  a  timely  basis.  In  1999, 
SMART  was  proposed  as  a  competitive  system  to  Nielsen.  The  necessary  capital  to 
launch the service, however, was not forthcoming. 

In  January  of  this  year,  I  was  asked  by  the  Advertising  Research  Foundation  to 
provide  a  historic  overview  of  TV  audience  measurement  in  the  United  States  at  a 
special meeting it convened on the topic of Accountability of Audience Measurement. 
I  am  submitting  the  paper  provided  there  as  an  addendum  to  my  testimony  today. 
I  appear  today  representing  my  own  views  and  interpretations  of  current  events 
in the television audience measurement business. I have no lawyers, no public rela-
tions  people  or  anyone  else  behind  me  telling  me  what  to  say.  I  speak  from  a  life-
time’s experience and a deep commitment to the understanding that research qual-
ity  makes  a  difference.  Good  information  helps  markets  work  better;  bad  informa-
tion undercuts business performance. 

I will briefly address three general points. 
• First, the role and value of the MRC to the audience research business. 
• Second, why we are here? Why is legislation being considered? 
• Third,  the  need  for  action  to  enable  the  television  ratings  process  to  facilitate 

rather than frustrate the marketplace. 

Media Rating Council 

I was present when the Broadcast Rating Council, now the Media Rating Council 
was  formed.  I  participated  in  the  debates  around  the  operating  rules  and  helped 
with  drafting  the  disclosure  standards  that  are  part  of  the  MRC  protocol  today.  I 
was  the  person  at  Nielsen  who  was  responsible  for  structuring  the  first  audit  of 
Nielsen. In later years, SRI provided a syndicated audience measurement service to 
the  radio  industry,  RADAR,  which  service  was  audited  by  the  MRC  for  30  years. 
I  have  deliberated  and  consulted  with  MRC  executive  directors  for  over  40  years. 
The  MRC  serves  a  vital  role  in  our  industry.  By  assuring  disclosure  of  research 
company methods and by auditing the accuracy and completeness of disclosure, the 
MRC  enables  an  informed  market.  An  important  byproduct  of  is  work  is  to  encour-
age  innovations  and  improvements  in  methods.  MRC  reporting  and  tracking  of  key 
quality indicators, appropriately and constructively pressures research companies to 
rectify weaknesses. 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00039 Fmt 6633 Sfmt 6621 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

36 

When  I  was  working  at  or  owned  a  service  that  was  being  audited,  the  MRC 
helped  me  do  a  better  job.  Totally  independent,  it  gave  research  company  manage-
ment an objective quality control report. When I was at Nielsen or in my own busi-
ness,  I  was  paying  an  audit  firm  and  I  wanted  maximum  value  from  that  expendi-
ture,  just  as  any  other  expense.  Hence,  there  were  occasional  discussions  between 
the  researcher  and  the  auditor  around  the  audit  plans  and  the  most  effective  use 
of  audit  resources.  There  was  a  healthy  dialogue,  and  as  a  result  audit  operations 
were improved. 

I  have  always  believed  that  audit  reports  should  be  open  and  available  to  all  cli-
ents  whether  or  not  the  clients  were  members  of  the  MRC.  I  was  happy  to  show 
my  audit  reports  to  my  clients.  All  media  rating  systems  are  frail,  sometime  more 
so  than  we  practitioners  like  to  admit.  We  manufacture  numbers  (statistical  esti-
mates)  that  have  broad  business  and  social  implications.  We  use  methods  that  are 
subjective  and  often  less  than  ideal.  To  use  information  from  these  systems  intel-
ligently  and  effectively,  users  need  to  know  all.  And  they  need  to  know  before  the 
data hit the marketplace, not after. 

Hence, I agree with the intent of the proposed legislation which is that all services 
providing  marketplace  currency  be  accredited  by  the  MRC.  I  understand  that 
Nielsen has expressed objections to the proposals and stated that the proposed plan 
would  lead  to  less  innovation  and  less  competition.  First,  it  would  be  difficult  to 
have less competition or less innovation than we have now. Second, it is my impres-
sion  that  Nielsen  has  become  a  reluctant  participant  and  not  permitted  select  com-
ponents of their services—new and old—to be examined by the MRC process. 

During the Congressional Hearings in 1963, Nielsen clients were incensed because 
they  were  unaware  of  some  Nielsen  procedures  disclosed  at  the  hearings.  There  is 
a principle that characterizes all successful service businesses—keep your clients in-
volved and informed. Never surprise a client. I believe it is in Nielsen’s and the in-
dustry’s best interest to embrace the intent of this legislation. I further believe that 
complete coverage of all services was what the industry committed to achieve in tes-
timony before the Congress in 1963. 

An  important  change  in  the  industry  structure  over  the  past  20  years  has  made 
the  MRC  industry  role  even  more  important  today.  When  the  networks  effectively 
dominated  the  national  television  arena  and  were  permitted  to  work  together  on 
issues  related  to  research  methodology,  there  was  a  balance  of  power  between 
Nielsen  and  the  networks.  With  a  fragmented  medium,  no  single  client  or  group  of 
clients wields that much influence. In effect, if Nielsen does not answer to the MRC, 
it answers to no one. I believe this explains, in part, their new, more aggressive pos-
ture with the MRC. 

Nielsen and others may have particular points about the legislation that warrant 
discussion. I am confident that details can be worked out to the benefit of all, if we 
have sufficient desire on the part of all concerned parties to do so. That has appar-
ently  not  been  the  case  for  the  past  year,  so  I  think  I  understand  the  reasons  why 
Senator Burns introduced his bill. 
Why We Are Here 

I submit that we are here because Nielsen clients feel they are hostages to a com-
pany  that  controls  their  basic  well-being;  further,  that  Nielsen  operations  are  defi-
cient  in  important  regards  and  those  deficiencies  jeopardize  the  clients’  businesses. 
This  is  not  a  manufactured  controversy;  there  is  a  real  problem.  We  are  not  here 
because  of  normal,  expected  competitive  posturing.  I  do  not  defend  the  actions  of 
some  media  companies,  but  I  recognize  their  actions  as  a  response  to  dealing  with 
a  monopolist  who  is  unresponsive  to  the  fundamental  issues.  When  emotions  run 
as high as they currently do among a large share of the client community, you know 
something here is not right. 

The  industry’s  natural  response  should  be  to  work  quietly  with  Nielsen  to  im-
prove. Nielsen is the industry’s nest and a bird does not foul its own nest! Agencies 
do  not  want  to  say  to  advertisers  that  I  am  spending  your  hundreds  of  millions  of 
dollars  on  meaningless  numbers;  nor  do  the  media  want  to  say  to  advertisers  that 
I am taking your hundreds of millions of dollars on meaningless numbers. So while 
the  industry  has  often  striven  for  a  constructive  response,  Nielsen  simply  does  not 
react. I believe that Nielsen has been its own worst enemy in thwarting a construc-
tive dialogue. 

Evidence of the industry’s efforts to bring improvement include the networks sup-
port  of  SRI’s  methodological  research,  the  support  of  CBS  and  others  of  the  AGB 
initiative  and  more  recently,  the  support  of  thirty  networks,  advertisers  and  agen-
cies for the SMART ratings laboratory. 

Nielsen  deficiencies  are  several  and  significant.  Perhaps  the  broadest  complaint 
is  that  Nielsen  is  not  responsive  on  data  quality  issues  and  to  client  concerns—un-

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00040 Fmt 6633 Sfmt 6621 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

37 

less the threat of competition is raised. The people meter was introduced by Nielsen 
in  1987  only  after  a  British  company  AGB  tried  to  enter  the  U.S.  market  with  a 
similar  meter.  Nielsen’s  new  A/P  meter  was  announced  in  1995  when  the  SMART 
laboratory  was  in  process.  It  was  noticed  by  all  that  when  SMART  went  away,  the 
introduction of the A/P meter was delayed. Ten years after the fact, the A/P meters 
have just begun to roll-out. 

The A/P meter involves changes in Nielsen operations. Research should have been 
conducted  to  know  how  best  to  proceed.  When  SMART  was  in  operation,  Nielsen 
published  a  copyrighted  research  plan  that  was  well  framed.  After  SMART  went 
away, the plan was forgotten and the industry is now faced with core operating pro-
cedures that are effectively untested and unproven. 

In  sum,  clients  will  tell  you  that  when  competition  or  the  threat  of  competition 
is  present,  Nielsen  is  a  different  company  than  when,  as  now,  there  is  no  competi-
tion. 

A  more  specific  deficiency  is  Nielsen’s  metering  technology.  It  has  not  kept  pace 
with  modern  media.  That  means  Nielsen  has  been  unable  to  measure  many  new 
forms  of  TV  receivers.  As  a  result,  homes  that  are  selected  to  be  in  their  samples 
are passed over and other homes with only old technology replace them. For exam-
ple,  in  the  Nielsen  People  Meter  system  today,  you  are  not  counted  if  you  have  a 
TiVo—or any other Digital Video Recorder (DVR). Your neighbor who does not have 
a TiVo takes your place in representing America’s viewing. TiVos have been around 
for 6 years. Nielsen says they will meter and report usage in DVR homes tomorrow. 
Tomorrow remains elusive. We are moving rapidly into the 21st century with aging 
20th century technology. 

The high fault rates in the Nielsen sample is further evidence of their out-of-date 
technology.  A  fault  is  what  the  name  implies.  It  means  that  some  homes  that  do 
have  meters  are  not  processed,  are  not  counted,  because  something  is  wrong  with 
the  data  from  that  home.  Faults  have  been  around  forever.  Current  fault  rates  in 
Nielsen  Local  People  meter  samples  are  high  because  the  meters  are  not  state-of- 
the-art.  The  fault  is  with  the  meters  and  how  they  operate;  the  fault  is  not  with 
the home or the people in it. Our goal in the SMART laboratory was to reduce fault 
rates  to  5  percent  or  less.  Though  the  target  level  was  not  achieved  before  the  lab 
was dismantled, we were gaining on it. In fact, we were under 10 percent—and my 
engineers assured me that we would get there. 

Are  Nielsen’s  new  systems  better  than  the  old?  Are  the  audience  estimates  with 
the  samples  omitting  bypassed  and  faulted  households  more  accurate?  The  truth  is 
that no one knows and that is disconcerting. What is known is that Nielsen is pro-
ducing  more  data  and  generating  more  revenue  than  ever  before.  Perversely, 
Nielsen  reports  they  are  beginning  to  measure  TiVo  households  under  the  old  local 
meter/diary measurements. 

Data  access  is  another  core  deficiency  of  Nielsen.  Data  access  is  an  important 
component  of  quality.  The  best  information  is  of  no  value  if  you  cannot  get  to  it. 
Clients  cannot  access  the  information  they  need  to  make  business  decisions  on  a 
timely  basis.  Nielsen  analysis  has  always  been  slow  and  expensive.  They  place  a 
tourniquet on information flow by their ineptness and cost. SMART showed the way 
as  to  how  to  do  it  better.  Nielsen  has  not  seen  fit  to  open  up  the  process  to  allow 
effective use of their information. 

Nielsen  weighting  procedures  are  another  point  of  contention.  With  an 
unweighted  sample,  all  people  count  the  same.  Weighting  a  sample  means  that 
some  people  count  more  than  others  in  the  statistical  process.  There  are  several 
good reasons for considering weighting. The issue here is that Nielsen has changed 
its  attitude  toward  weighting  which  they  had  touted  for  50  years.  The  old  position 
was that the sample should not be weighted for demographic characteristics because 
a  pure  probability  sampling  approach  was  superior.  The  new  position  is  a  180  de-
gree  shift.  Nielsen  virtually  recommends  weighting  on  every  variable.  The  problem 
is that when a statistician advocates weighting, there is an implication that the re-
sulting  data  quality  are  improved.  Nielsen’s  arguments  for  weighting  are  novel, 
unproven  by  independent  research  and  to  my  knowledge  not  supported  by  theory. 
My  conviction  is  that  they  should  have  introduced  some  kind  of  weighting  years 
ago.  Statisticians  agree  with  judicious  weighting  while  being  concerned  about  the 
abuse of weighting. It is like putting a new coat of paint over old wood. The result-
ing  weighted  sample  may  look  better  but  the  non-responding  households  are  still 
missing. 

The  real  problem  with  each  of  these  and  other  deficiencies  is  that  they  all  affect 
audience  levels.  That  means  that  some  audiences’  ratings  are  higher,  and  some 
lower,  than  is  the  reality.  Some  organization’s  bottom  lines  are  improved  and  some 
made worse. 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00041 Fmt 6633 Sfmt 6621 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

38 

That  observation  leads  to  the  last  deficiency  that  I  cite  today.  Nielsen  is  almost 
cavalier  about  making  changes  in  procedures.  I  know  from  experience  that  two  ac-
tions  can  turn  a  marketplace  on  its  ear.  If  a  pricing  formula  is  changed  such  that 
some  pay  more  and  others  pay  less  than  previously,  turmoil  will  be  assured.  Simi-
larly,  if  measurement  techniques  are  changed,  some  audiences  will  be  greater  and 
some  lesser  than  before.  The  real  audience  will  not  have  changed  but  the  reported 
audience changes. Some win; some lose. 

The only way to prepare for such events is to communicate planned changes with 
evidence on the benefits to the industry and to supply an abundance of data (includ-
ing parallel measurements, if necessary). This would enable the industry to prepare 
for  an  orderly  transition  from  one  operating  frame  to  another.  To  force  feed  a 
change  invites  disaster.  That  is  what  Nielsen  effectively  did,  and  they  reaped  what 
they  sowed.  Nielsen  publicly  proclaimed  their  shock,  their  dismay  and  surprise  at 
the  industry  reaction  to  the  way  in  which  the  LPM  was  introduced.  Such  reactions 
to me speak of posturing or a lack of understanding of their clients’ legitimate con-
cerns. 
Need for Action 

In  connection  with  the  1963  hearings  on  ratings,  Chairman  Harris  of  the  House 
Committee on Interstate and Foreign Commerce referred to the ratings industry as 
being in an ‘‘intolerable situation.’’ Many today also feel that the situation is intoler-
able. Something must be done to bring balance to the relationship between Nielsen 
and  the  industry  it  is  supposed  to  serve.  As  with  economic  trends,  I  do  not  believe 
this  can  go  on  forever.  If  an  economy  is  constantly  in  deficit,  that  economy  eventu-
ally collapses. Some believe that because it is so difficult to bring improvements into 
this  system  that  it  too  will  eventually  collapse.  The  wheels  will  come  off  the  bus. 
I  see  confusion  in  the  marketplace  about  the  nature  of  the  problem.  More  data 
does not equal better data. Also, it is unfortunate that a large part of the discussion 
about the LPM has focused mainly on minority-measurement issues. I do not believe 
the  problem  is  associated  only  with  minorities.  The  key  independent  variable  with 
respect  to  meter  performance  is  the  number  of  TV  sets  in  the  home.  More  sets 
equals more problems and more faults. That is due to an out-of-date meter platform. 
In  the  late  1960s  and  early  1970s,  SRI  did  several  comparisons  of  Nielsen  and 
ARBITRON  data.  Clients  complained  that  one  service  favored  their  competitor  or 
visa versa. Often, the differences were random and a function of small sample sizes. 
Yet people thought they saw patterns. I believe there is more speculation and polit-
ical positioning going on than solid data analyses. 

I  know  about  minority  measurements.  For  over  25  years,  we  served  the  National 
Black  Network  and  Sheridan  Broadcasting  as  part  of  our  RADAR  service.  In  the 
early  1970s,  we  produced  special  measurements  of  Spanish  audiences  in  the  New 
York  area  which  P&G  (uncharacteristically)  urged  their  agencies  to  use  in  buying 
NY  Spanish  television.  Measurements  for  minorities  should  be  judged  by  the  same 
quality guidelines and subject to the same audit review as are all other media audi-
ence measurements. While I believe audience measurements should be inspected for 
all important population subgroups, I do not believe race or ethnicity is the primary 
issue with the LPM. 

I believe the issue is how a monopolist relates to its clients. The issue is whether 
these  Nielsen  ratings  data,  when  used  as  the  currency,  is  really  funny  money.  We 
just do not know enough today about the Nielsen research quality. 

Nielsen  has  a  difficult  task.  But  syndicated  services  exist  here  and  around  the 
world  without  the  acrimony  and  anger  that  characterizes  the  U.S.  television  mar-
ketplace.  I  believe  Nielsen  has  the  ability—and  needs  to  find  the  will—to  serve  its 
market proactively. At the end of the People Meter review in 1988 we recommended 
that Nielsen concentrate on three initiatives: 

• Defined procedures and quality control 
• Methodological research 
• Client Involvement 
Nielsen  seemed  to  endorse  those  proposals  and  I  hope  they  may  reinspect  their 
position  today  and  truly  strive  to  work  with  the  industry  openly  and  forthrightly. 
Whether  this  proposed  legislation  goes  too  far  or  not  far  enough  I  shall  leave  for 
others to judge. Like most others here, I believe a voluntary industry solution is the 
best  one.  But  failing  that,  legislation  may  be  the  only  way  to  get  Nielsen  to  the 
table,  and  I  think  this  bill  is  the  right  way  to  go.  I  am  absolutely  convinced  that 
something must be done. 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00042 Fmt 6633 Sfmt 6621 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

39 

A  disclaimer:  some  of  the  points  articulated  herein  (e.g.,  the  discussion  of 
weighting)  are  simplified  for  purpose  of  clarity.  The  author  trusts  that  the 
thrust of the discussion is clear. 

ATTACHMENT—HISTORY OF TV AUDIENCE MEASUREMENT IN THE USA 

(BY GALE D. METZGER) 

Introduction 

Simon Schama’s, Dead Certainties, is a good read. Professor Schama affirms that 
the dead, really are dead; everything else—why they died, how they died—is a mat-
ter  of  interpretation.  History  is  in  the  eye  of  the  beholder.  For  some,  his  book 
marked the death of any certainty about history. 

I  have  few  absolutes  to  offer  in  my  30-minute  history  of  television  audience  re-
search  in  the  USA.  You  will  hear  my  interpretation  of  events  and  my  view  of  how 
today contrasts with the past. 

For a more complete history of radio and TV measurement prior to the mid-1980s, 
you  should  read  Mal  Beville’s  excellent  book:  Audience  Ratings,  published  in  1988. 
Another  document  that  I  commend  to  your  reading  is  Thirty  Years  of  CONTAM, 
published in 1995. 

I  speak  from  my  own  personal  knowledge  of  47  years  in  the  business.  I  shall  re-
call the Congressional hearings of 1963 and the associated fear of government regu-
lation. What was done by Nielsen and the industry to deal with this threat? 

Then I will look at the 1980s and 1990s and how the industry and Nielsen acted 
in  response  to  many  of  the  same  problems  we  face  today—albeit  on  a  lesser  scale. 
Last, a review of today’s situation and the lack of resources dedicated to improving 
ratings quality. 
A. C. Nielsen 

Sadly,  I  assure  you  with  dead  certainty  that  the  central  figure  in  the  history  of 
TV  audience  measurement,  Arthur  Charles  Nielsen,  is  deceased.  Born  in  1897,  he 
died in 1980. He left a substantial legacy. 

A. C. Nielsen was the son of a Danish immigrant. His father worked for 40 years 
in  Quaker  Oats  accounting  division.  His  son  inherited  his  bean-counter  mentality. 
Witness  the  label  ‘‘audit  pioneer’’  in  the  ARF’s  1977  tribute  to  ‘‘The  Founding  Fa-
thers  of  Advertising  Research.’’  Mr.  Nielsen—as  he  was  addressed  by  most—was  a 
trained  engineer  and  a  scientist.  He  graduated  from  the  University  of  Wisconsin’s 
engineering  school  with  an  extraordinary  academic  record.  In  1923,  he  started  the 
A.  C.  Nielsen  Company  with  money  borrowed  from  friends.  He  was  an  excellent 
businessman,  a  man  of  strong  character  and  conviction.  I  knew  him  as  a  kind  and 
intellectually  generous  person.  For  me,  he  was  the  proverbial  man  with  a  steel  fist 
in a velvet glove. 

The  Nielsen  Company  was  a  research  company  that  produced  good  services  and 
reasonable  profits.  It  reflected  Art  the  scientist/auditor.  He  chose  a  micrometer  as 
a company symbol and a favorite authority he loved to quote was the scientist, Lord 
Kelvin, who said: 

‘‘If  you  can  measure  that  of  which  you  speak,  and  can  express  it  by  a  number, 
you know something of your subject.’’ 

That A. C. Nielsen Company was one I was proud to work for from 1958 to 1969. 
The  Nielsen  business  progressed  from  performance  surveys  of  industrial  machin-
ery  in  1923  to  retail  sales  measures  in  1933  and  to  radio  audience  measurement 
in  1942.  In  1950,  television  audiences  were  added  to  the  package.  He  invested  17 
years and $15,000,000 before achieving a break-even financial position in the media 
business.  That  is  focusing  on  the  long  term.  That  is  a  person  who  did  not  have  to 
answer to Wall Street. 

His  primary  objective  was  to  provide  accurate  and  thorough  research  to  support 
marketing  efficiencies.  He  knew  that  good  information  lubricated  economic  gears. 
He  wanted  to  provide  the  tools  to  assess  advertising  and  promotion  options  in  the 
marketing  process.  He  wanted  to  ‘‘further  the  science  of  marketing  research.’’  So 
that,  while  his  name  is  primarily  associated  with  television  research,  his  personal 
goals were broader. 
Congressional Hearings of 1963 

I shall skip the stories of the early competition in audience research, well told in 
Mal’s book. I begin in 1963. Hearings were held before the Committee on Interstate 
and  Foreign  Commerce  of  the  House  of  Representatives.  The  subject  was  ‘‘The 
Methodology,  Accuracy  and  use  of  Ratings  in  Broadcasting.’’  There  are  several 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00043 Fmt 6633 Sfmt 6621 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

40 

thoughts  on  how  the  hearings  came  to  be.  The  role  of  ratings  as  highlighted  in  the 
quiz show scandals of the late 1950s was one stimulant. 

The  hearings  were  to  consider  the  production  and  use  of  ratings  in  the  broad-
casters’  fulfillment  of  their  statutory  obligation  to  serve  the  public  interest.  If  rat-
ings  were  unreliable,  then  they  were  worthless  as  a  means  to  that  end.  Chairman 
Harris  felt  there  was  an  ‘‘intolerable  situation.’’  The  question  was:  is  the  service  of 
the public and is television commerce being conducted on funny money? 

A  year  earlier,  the  prospect  of  hearings  loomed.  Congressional  investigators  ap-
peared on Nielsen’s doorstep and that of many other companies. The actual hearings 
commenced  on  February  9,  1963  and  ended  19  months  later.  The  proceedings  are 
memorialized in a 1,932-page transcript. 

The  hearings  changed  audience  measurement  forever.  While  Nielsen  as  the  larg-
est audience research entity had some difficult days during the hearings, in the end 
Nielsen was a great benefactor from the process. Evidence of that is in their market 
position  in  the  ensuing  40  years.  The  Nielsen  Company  responded  well  by  working 
with the industry. 

Congress  tried  to  determine  whether  the  rating  companies  were  doing  what  they 
said  they  did.  They  investigated  how  rating  reports  were  used  and  the  effects  on 
both  programming  and  on  the  sale  and  purchase  of  broadcast  time.  In  brief,  they 
discovered  some  research  companies  were  apparently  making  up  the  numbers  from 
imaginary surveys. Nielsen and others were accused of misleading clients as to their 
procedures  and  of  not  accurately  describing  the  samples  on  which  ratings  were 
based.  Congress  was  exploring  Federal  regulation  and  considering  legislation.  The 
Bureau of Census was asked if it could undertake to provide certain broadcast data. 
The  Federal  Trade  Commission  became  involved.  Several  ratings  companies,  in-
cluding  Nielsen,  Pulse  and  the  parent  company  of  Arbitron,  were  ordered  ‘‘to  cease 
and desist from misrepresenting the accuracy and reliability of their measurements, 
data  and  reports.’’  The  FTC  issued  guidelines  to  the  media  for  use  of  ratings  and 
stated that audience claims must be ‘‘truthful and not deceptive’’ and that the media 
must avoid activities intended to ‘‘distort or inflate’’ audience data solely during sur-
vey periods. 

Those  activities  led  to  a  hyperactive  industry  response  led  primarily  by  the  NAB 
and  featured  broad  participation.  One  NAB  committee  included  24  corporate  rep-
resentatives, including delegates from the AAAA’s and the ANA. The three networks 
formed  a  Committee  on  Nationwide  Television  Audience  Measurement,  which  be-
came  known  by  the  acronym,  CONTAM.  The  purpose  was  to  improve  the  quality 
and understanding of audience ratings. That purpose would be fulfilled by three ac-
tions: 

• Require rating services to describe what they do; 
• Audit rating services to determine if they do what they say; and 
• Conduct continuing and effective research to improve rating methodology. 
Work began immediately. 
The hearings changed the way the industry operated. They were a force that im-
proved  the  audience  ratings  systems.  Arthur  Nielsen,  Jr.  pledged  to  the  Congres-
sional  Committee  the  Nielsen  Company’s  full  cooperation  in  achieving  the  ‘‘broad 
and  worthy’’  objectives  that  were  targeted.  Some  clients  publicly  defended  Nielsen 
throughout this period. In private, all clients were adamant in their conviction that 
they would not be blind-sided—not be surprised again by a ratings service. Full dis-
closure and auditing of procedures would proceed forthwith. 

Not  everyone  liked  the  congressional  hearings  process.  The  investigators  were 
zealous—and  at  times  over  the  top.  During  the  hearings,  it  had  been  asked  of 
Nielsen if the use of a permanent panel of sample respondents meant that members 
might  be  ferreted  out  and  influenced  to  distort  the  ratings.  After  the  hearings  con-
cluded,  there  was  an  incident  that  raised  eyebrows.  One  of  the  investigators  used 
information  obtained  during  the  hearings  to  aid  a  well-known  entertainer.  Some 
Nielsen  homes  were  contacted  to  encourage  their  viewing  of  an  upcoming  special 
featuring  the  entertainer.  The  efforts  were  discovered  by  Nielsen  and  the  culprits 
were  called  to  account.  The  episode  was  kept  under  wraps  but  those  who  needed 
to  know  were  informed  and  the  whole  event  served  to  take  some  of  the  pressure 
off of Nielsen with the client community. 
Media Rating Council 

As a result of the governmental threat, in less than 1 year, an entity to audit re-
search  procedures  was  created.  It  was  originally  called  the  Broadcast  Rating  Coun-
cil,  which  is  today’s  Media  Rating  Council.  It  was  to  assure  ratings  companies  said 
what  they  did  and  did  what  they  said.  Was  any  of  this  anti-competitive  in  restrict-

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00044 Fmt 6633 Sfmt 6621 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

41 

ing  innovations  or  options?  The  Justice  Department  okayed  the  actions.  The  audits 
were firmly grounded. The industry had spoken. 

To assure consistency in the mechanics, the industry cooperated in creating stand-
ard  definitions,  standards  for  reports  and  disclosures  and  standards  for  presenting 
sampling error estimates. 

The  research  companies  had  differing  reactions.  Nielsen  worked  with  Ernst  and 
Ernst’s  Operations  Research  group  to  create  an  effective  and  efficient  working 
model.  The  E&E  staff  was  highly  professional  and  the  early  workings  were  rel-
atively smooth. Over the years the attitude toward the Audit functions ranged from 
those  who  saw  it  as  an  asset—an  effective,  independent  quality  control  check—to 
those  who  sought  to  avoid  such  crosschecks  or  to  treat  it  as  an  unnecessary  nui-
sance to be challenged. 

The  audit  operations  have  benefited  from  top  quality  leadership  of  Executive  Di-
rectors  Ken  Baker,  Mal  Beville,  John  Dimling,  Mel  Goldberg,  Dick  Weinstein  and 
today, George Ivie—who you will hear from later this afternoon. All of these individ-
uals  with  their  respective  Boards  of  Directors  worked  effectively  to  sort  the  wheat 
from  chaff  and  generally  served  to  be  an  influence  for  full  and  accurate  disclosure 
and for improvement. 

The  MRC  today  is  an  important  and  vital  resource.  I  believe  the  MRC  would  be 
even  more  valuable  if  its  reports  were  open  to  the  industry.  The  audits  are  closed 
to all but MRC directors. The industry only knows pass or fail. That is insufficient. 
I believe that open information is a force for understanding and improvement. 

Research  companies  should  have  no  pretenses.  The  founder  of  Arbitron,  Jim 
Seiler,  had  a  favorite  saying.  ‘‘The  three  things  you  do  not  want  to  see  made  are 
sausage, legislation and ratings.’’ There is also the analogy between growing mush-
rooms  and  clients.  Both  should  be  kept  in  the  dark  and  covered  with  manure.  The 
humor  is  too  close  to  reality  to  be  funny.  Knowledge  is  power.  Knowing  strengths 
and weaknesses is key to using data intelligently. 
CONTAM 

Back  to  the  story—by  1964  the  industry  was  working  with  standards  and  defini-
tions,  disclosure  and  audits.  What  about  the  third  commitment,  to  improve  the 
state-of-the-art? A good share of the early work was dedicated to defining where we 
were. How good or bad were the ratings? What could be said on that subject? 

On January 15, 1964, three network executives testified before the Congressional 
Committee  on  the  newly  formed  CONTAM  and  its  early  work.  Through  extended 
studies  CONTAM  demonstrated  that  sampling  theory  does  apply  to  measurement 
of  television  viewing  behavior.  As  they  said  it,  ‘‘relatively  small  samples  give  good 
estimates  of  TV  audience  size.’’  They  also  committed  to  tackling  other  problem 
areas.  CONTAM  was  joined  in  this  work  by  a  parallel  local  committee,  COLTAM. 
That was the beginning of 35 years of methodological review and research on the 
quality  of  the  Nielsen  ratings.  Until  1999,  a  continuous  expenditure  of  funds  by  a 
limited  number  of  industry  leaders  provided  data  independent  of  Nielsen  or  other 
syndicated services to cross-check, evaluate and highlight strengths and weaknesses 
of the audience estimates used in the marketplace. 

In  1969,  a  Professor  of  Business  Statistics  from  New  York  University,  Gerald 
Glasser,  and  I  started  a  research  company,  Statistical  Research,  better  known  as 
SRI.  Gerry  had  been  a  consultant  to  the  networks  and  the  media  industry  during 
the prior tumultuous years. 

Among our first projects was a series of telephone coincidental studies to measure 
national audiences. The results were presented at the 1970 ARF Annual Conference 
and subsequently published in two booklets titled ‘‘How Good Are Television Ratings 
(continued).’’ The work examined the effects of methods on results. The best method 
yielded  results  remarkably  similar  to  Nielsen  on  TV  set  usage.  In  this  and  subse-
quent  research  we  found  consistent  differences  on  persons  ratings,  where  we  found 
more young viewers and fewer older viewers than Nielsen. 

In  the  1970s  and  1980s,  many  independent  studies  were  completed.  There  was  a 
continuous flow of work. Research on the effects of weighting and editing rules and 
of  data  gathered  along  with  audience  estimates  was  done.  When  a  new  measure-
ment  technique  was  introduced  in  Chicago,  the  resulting  disputes  were  addressed 
through  an  independent  study.  In  1981,  industry  sponsored  estimates  of  evolving 
technologies  were  begun.  It  was  a  top  quality  effort  to  track  TV  sets  and  related 
hardware  in  the  home.  Later  that  work  was  extended  to  cover  computer  and  tele-
phone devices. 

The efficacy of product ratings was explored in 1972. Arbitron had begun to meas-
ure the purchase of packaged goods in their TV diaries. They produced ratings with-
in product user categories. A widely sponsored industry study that was reviewed by 
an ARF Technical Committee demonstrated that program buying decisions based on 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00045 Fmt 6633 Sfmt 6621 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

42 

the  product  data  produced  inferior  results  to  those  based  solely  on  standard  demo-
graphic ratings. It was a classic study. It demonstrated that, in this case, more was 
less. The added data were not reliable and were harmful to media buying decisions. 
Arbitron ceased gathering and producing the data. 

In  the  1990s,  projects  around  how  people  use  media  were  added.  They  were  de-
signed  to  look  at  the  media  through  the  eyes  of  the  consumer.  Over  a  dozen  such 
studies were conducted following an agenda directed by an industry committee. 

There are two ways to assess any data stream. One is independent research such 
as the work I just described. The second method is to track the internal consistency 
of Nielsen information. For over two decades, SRI compiled and tracked Nielsen na-
tional  audiences  and  sample  statistics  for  CONTAM.  Television  usage  over  3 
dayparts  was  analyzed  on  five  bases.  The  purpose  was  to  detect  unexpected  vari-
ations  in  HUT  levels  based  on  statistical  principles.  The  data  were  deseasonalized 
and  compared  to  a  long-term  trend.  If  something  jumped  out  of  line,  it  was  clear 
to all. Rather than relying on anecdotal evidence, we had the full story. Discussions 
about unexplained variations were cast in a broad light. 

Sample  statistics  were  tracked  in  the  same  way.  Statistics  on  implementation  of 
the  Nielsen  sample  and  on  tabulation  were  inspected  on  12  different  parameters. 
For  example,  ‘‘normal  levels’’  were  defined  for  unidentified  tuning,  meter  overflow, 
and  set  disconnects.  The  abnormal  was  held  up  for  possible  action  and  resolution. 
Over  the  years,  this  standard  quality  control  warning  system  identified  extreme 
changes  in  usage  levels.  After  investigating,  sometimes  a  cause  was  identified  and 
corrective action taken. On other occasions, the tracking was used to correct a laxity 
in operations that contributed to extra variation. 

Another  major  industry  effort,  the  people  meter  review,  began  in  1987.  The  pro-
posed  introduction  of  people  meters  by  AGB  and  Nielsen  was  a  landmark  change 
in  the  measurement  of  TV  audiences.  There  were  many  questions.  Both  AGB  and 
Nielsen agreed to participate in a detailed analysis. However, before the actual work 
began, AGB withdrew its proposed service from the U.S. market. 

The purpose of the review was to understand and describe the issues and to iden-
tify  possible  improvements  in  the  system.  The  product  was  seven  reports  including 
a  data  review,  exit  interviews  with  former  panelists,  sampling  and  field  implemen-
tation,  household  contacts,  processing  and  editing,  an  engineering  review  of  the 
hardware and a final report. 

It asked that Nielsen act on three recommendations: 
• Defined procedures and quality control, 
• Ongoing methodological research; and 
• Client involvement. 
Reactions to the effort were enthusiastic. It was called exhaustive, a new standard 
of  excellence  and  a  blueprint  for  change.  Nielsen  called  the  work  ‘‘an  outstanding 
effort.’’ It was a unique chance for all of the industry to be on the same page. 

In  1990,  CONTAM  published  its  Principles  of  Nationwide  Television  Audience 
Measurement,  which  was  in  part  a  derivative  of  the  earlier  People  Meter  Review. 
To  this  point  CONTAM  and  the  industry  had  focused  on  checking  and  assessing 
methods  and  alternatives.  It  was  a  reactive  role  and  the  industry  was  frustrated 
that  promised  actions  from  the  people  meter  review  had  not  been  implemented. 
Therefore,  beginning  in  the  early  1990s,  the  posture  became  proactive  with  S-M-A- 
R-T.  S-M-A-R-T  was  an  acronym  for  Systems  for  Measuring  and  Reporting  Tele-
vision. 

The  S-M-A-R-T  story  is  long  and  involved.  By  mid-1999,  when  the  operation 
ceased, S-M-A-R-T had created a complete laboratory for future measurement in the 
digital  age.  New  measurement  hardware  was  designed  and  built.  The  Philadelphia 
market was the test bed. Clients were delivered 9 months of Philadelphia audience 
data  to  their  desktops  on  a  weekly  basis.  Software  enabled  instant  analyses  at  no 
marginal cost. In the end there were 30 telecaster, advertiser and agency sponsors. 
Since  1999,  independent  initiatives  to  understand  and  improve  the  Nielsen  sys-
tems  have  effectively  disappeared.  The  measurement  challenges  are  greater  than 
ever,  but  client  managements  are  unwilling  to  fund  such  work.  The  willingness  to 
attend  to  the  problems,  reactively  or  proactively,  has  disappeared.  That  brings  me 
to accountability. 
Accountability 

The 1963 Hearings and the associated fear of regulation was a powerful attention 
getting event. The industry and Nielsen became riveted on taking responsibility for 
what they did and what they sold. Consider the industry: 

Industry. In the 1950s and 1960s television was dominated by three players. Each 
recognized  a  public  responsibility  for  use  of  the  public  airwaves.  Stations  were  li-

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00046 Fmt 6633 Sfmt 6621 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

43 

censed  and  obligated  to  ascertain  and  serve  public  interests.  The  networks  studied 
the medium and its relation to society. 

Two  examples.  First,  Frank  Stanton—another  of  those  Founding  Fathers  in  the 
ARF  compendium—as  CEO  of  CBS,  gave  money  to  Paul  Lazerfeld  and  the  Bureau 
of  Applied  Research  at  Columbia  to  study  television  audiences.  In  1955,  Stanton 
said ‘‘we owe it to our audience as well as to ourselves to establish some systematic 
method of inviting the public to participate in shaping what we do.’’ From that 1955 
comment  came  successive  studies  published  in  1963  under  the  title  of,  The  People 
Look  at  Television,  by  Gary  Steiner  and  a  later  update  by  Robert  Bower  published 
in 1973. 

Second,  NBC  funded  a  huge  longitudinal  study  over  several  years  on  the  effects 
of  violence  on  television  for  children.  The  resulting  book,  Television  and  Aggression 
by Stipp, Rubens, Milovsky and Kessler was published in 1982. 

In the 1960s, the three network television research departments numbered about 
100  people  each.  Then,  the  research  departments  had  a  budget  to  do  research  on 
the  ratings.  From  the  1960s  through  the  1990s,  some  media  entities  spent  heavily 
to understand and improve ratings quality. The S-M-A-R-T initiative was supported 
largely by selected networks to the tune of $45,000,000. 

The CEO’s who approved the S-M-A-R-T expenditures knew that they were in for 
the  long  haul.  Payout  would  be  years  away.  It  was  okay  if  S-M-A-R-T  diluted  cur-
rent earnings. But CEO’s change and CEO’s also change their minds. The year 1999 
was  financially  crazed  and  some  of  the  then-current  CEO’s  saw  a  greater  bottom 
line by cutting costs and learning to live with ratings as they were. 

Today,  with  a  fragmented  industry  and  each  network  run  as  a  profit  center,  the 
corporate research department is likely to be ten people with no independent budg-
et. There is little focus on the long term. In the 1990s, some of the most successful 
players  sat  on  the  financial  sidelines  and  reaped  the  benefits  of  independent  re-
search without paying the price. Today, all seem to have adopted the sidelines pos-
ture.  Evidence  of  action  to  test  or  fulfill  a  public  responsibility  is  thin;  the  Wall 
Street  accountability  is  clear.  Research  on  research  does  not  add  to  today’s  sales; 
it dilutes earnings. That is the pox on our times. 

Nielsen. In the 1960s, 1970s and 1980s, Nielsen supported the industry initiatives 
to  improve  the  research  product.  They  rightly  saw  this  work  as  buttressing  the  in-
dustry’s  stock  of  knowledge  and  therefore  helping  their  cause.  A  network  research 
director used early CONTAM work to tell the ANA that Nielsen data were accurate 
and  reliable  and  should  be  used  with  confidence  in  the  television  marketplace. 
Nielsen  cooperated  with  independent  studies  by  supplying  corresponding  data  for 
comparisons  and  participated  in  analyses.  When  disputes  arose  about  methods  or 
measurement changes, those disputes were sometimes settled by a jointly sponsored 
study  where  Nielsen  paid  half  or  by  a  summit  meeting  where  data  were  presented 
and a resolution planned. 

Because of the scope and nature of the People Meter Review, Statistical Research 
sought and received legal protection from Nielsen against any claim arising from the 
conduct or reporting of the study. After that review was completed, Nielsen refused 
to extend that protection for proposed future work. That refusal and Nielsen’s resist-
ance  to  the  industries  more  in-depth  involvement  was  one  reason  S-M-A-R-T  was 
initiated. 

Another episode of inexplicable changes in television usage in 1990 and Nielsen’s 
resistance  to  investigating  and  correcting  the  cause  was  also  a  motivation  behind 
S-M-A-R-T’s launch. 

The network people will tell you that while S-M-A-R-T was there, Nielsen was its 
most  responsive  self.  When  S-M-A-R-T  happened,  a  whiff  of  competition  stirred  a 
reaction.  Innovations  were  talked  about  and  some  things  actually  changed.  Re-
sponse  rates  on  the  national  panel  improved.  Questions  were  answered  promptly. 
And  corporate  contracts  across  media  entities  that  Nielsen  had  refused  to  consider 
suddenly came to be. Nielsen reacted. 

Today’s  Wall  Street-thinking  also  influences  Nielsen.  Anything  Nielsen  does  over 
and  above  producing  rating  reports  reduces  their  earnings.  That  fact  is  a  powerful 
deterrent to investing in improvements. 
Current Status 

To  conclude,  I  offer  my  perspective  on  where  we  are  today.  I  grant  that  the 
Nielsen task of measuring television audiences is incredibly difficult. It is far tough-
er  than  what  was  done  with  S-M-A-R-T.  S-M-A-R-T  had  the  advantage  of  working 
in  a  laboratory,  of  a  fresh  start  and  of  ‘‘off-line’’  innovation.  Nielsen  needs  to  inno-
vate  and  introduce  new  systems  into  a  service  that  is  valuing  the  assets  of  others 
365 days per year. 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00047 Fmt 6633 Sfmt 6621 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

44 

The  scary  realities  are  these.  Everything  Nielsen  does  affects  the  ratings.  Every 
change  in  procedures,  every  change  in  operations  affects  the  ratings.  The  perceived 
changes  as  seen  through  Nielsen  data  are  additive  to  any  real  change  in  behavior 
that may occur. 

For  example,  when  Nielsen  passes  over  a  high  tech  home,  ratings  are  changed. 
When Nielsen alters weighting, or persons prompting sequences, or the meter itself, 
or  methodology  in  any  way,  the  ratings  are  changed.  Some  clients  are  helped  and 
some are hurt. 

The  methods  changes  may  be  planned  or  unplanned.  When  meter  fault  levels  in-
crease,  the  ratings  are  changed.  When  Nielsen  decides  to  install  LPM  markets  and 
changes  field  assignments  so  that  home  maintenance  calls  are  delayed,  the  ratings 
are changed. Does anyone doubt that the male teen and young adult audiences that 
were lost and reappeared a year later were due, not to real change in real viewing, 
but  to  changes  in  Nielsen  operations?  When  methods  are  changing  and  when  there 
are  layers  of  changes,  can  the  media  guarantee  audience  delivery  to  their  clients? 
On what set of numbers should the guarantees be based? 

The  first  and  most  important  recommendation  from  the  1987  People  Meter  Re-
view was that Nielsen institute a more careful approach to its methodology. It called 
for  defined  procedures  and  quality  control.  That  recommendation  was  framed  be-
cause changing methods change results and create aberrant data patterns. 

Nielsen  appears  to  have  been  almost  cavalier  about  making  changes.  There  has 
been too little attention and too few analyses to support changes that have occurred. 
That  fact  explains,  in  part,  the  extended  controversies.  Another  contributor  to  the 
controversies  is  that  Nielsen  has  never  picked  up  the  quality  control  monitoring  of 
its  own  data—or  if  Nielsen  has,  it  has  not  been  shared  with  clients.  With  today’s 
technology,  Nielsen  should  have  quality  control  charts  available  simultaneous  with 
the  release  of  rating  reports.  They  should  cover  the  levels  and  trends  by  daypart 
and  age  groups.  They  should  cover  all  aspects  of  the  sample.  Without  that  type  of 
data tracking, sellers or buyers cannot know how to interpret today’s ratings. They 
act on faith and hope that the emperor is clothed. 

The  state  of  Nielsen  metering  technology  is  troubling.  One  problem  is  that  there 
is  a  potpourri  of  meters  and  meter  installations.  It  is  a  collage  or  patchwork  quilt 
of  methods.  Nielsen  bragged  some  years  ago  that  it  had  several  hundred  different 
ways of metering a home. That says there are too many moving parts for the system 
to  work  effectively.  What  the  industry  needs  is  one  simple  and  effective  metering 
method;  one  meter  that  supports  reporting  of  what  is  tuned  to  the  10-second  level 
rather than the average minute. An average minute rating masks channel changes. 
The  AP  meter  was  around  the  corner  in  1995;  it  has  taken  10  years  to  get  here. 
It  seems  the  distance  between  TV  technology  today  and  meter  design  is  ever  grow-
ing. The hole gets deeper. 

We  know  that  many  predesignated  sample  homes  have  been  omitted  because  the 
meters do not work in complex homes. Reports of high fault rates means others are 
also  omitted  from  the  tabulated  sample.  Faults  occur  because  the  meters  are  not 
sufficiently robust to deal with the real world environment. Those homes that fault 
are a biased subset. Faulting homes are not randomly selected. 

I  am  omitting  discussion  of  Nielsen  reporting  systems.  A  key  value  element  with 
data  is  accessibility  in  a  friendly  and  affordable  manner.  Nielsen  clients  complain 
bitterly that they do not have such access. The ratings cannot be analyzed in a time-
ly and effective way. 

So  with  the  methods  changes,  with  the  meter  frailties  and  with  the  reporting  in-
eptitude,  how  much  confidence  should  clients  or  society  place  in  today’s  ratings? 
That question is left hanging. We don’t know. 

Another recommendation from the People Meter review was that there should be 
continuous  methodological  research.  Independent  crosschecks  are  needed.  Nielsen 
has supplied independent checks in the past. For 40 years, Nielsen had two separate 
systems. The sum of NSI local ratings were compared to independently derived NTI 
national  ratings.  There  was  a  distinct  and  consistent  pattern  to  the  differences. 
That reassured clients of both services. With the merging of local measurement into 
the national, that crosscheck disappears. 

In  the  early  1960s,  Nielsen  did  a  noncooperation  bias  study  to  check  independ-

ently the effects of nonresponse on NSI measurements. 

The fact of Nielsen taking responsibility to check its own systems needs to be re-
established.  Some  basis  for  assessing  the  degree  of  confidence  associated  with 
Nielsen ratings must exist. 
Conclusion 

Life  is  filled  with  uncertainties.  We  learn  to  live  with  uncertainty—we  can  curse 
the  darkness—or  we  can  become  proactive.  The  1963  hearings  gave  a  jolt  to  the 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00048 Fmt 6633 Sfmt 6621 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

45 

media  audience  measurement  world,  and  the  industry  was  energized  for  decades. 
That energy has been dissipated. 

Television  audience  measurements  today  are  shaky.  There  seems  little  point  to 
ranting  or  raving  at  Nielsen  or  engaging  in  public  warfare.  Such  actions  only  seem 
to  become  a  distraction.  The  first  step  to  solving  any  problem  is  to  face  reality.  My 
view is that the Nielsen ship has lost its anchor and is adrift, no land in sight. 

The  industry  posture  is  distressing.  The  work  done  pre  2000  was  not  for  charity. 
It was work done to protect the media business base. It was work to provide mean-
ing  and  context  to  the  audiences  being  sold.  Can  you  imagine  a  network  executive 
going  to  the  ANA  today  and  telling  them  to  use  the  Nielsen  data  with  confidence? 
Those who funded studies before, now say the industry should do it. What industry? 
There  is  no  media  industry  organization  that  brings  together  broadcast  and  cable 
to do this fundamental work. The ARF is a possibility, but finding the right commit-
ment will be harder than finding the right organization. 

Regaining  confidence  is  beyond  the  client  or  Nielsen  research  community.  We 
have the talent to do better. Art Nielsen’s 17 years and $15,000,000 investment re-
flects  thinking  from  a  different  planet.  We  lack  management  leadership.  We  lack 
management commitment to invest, to build and to maintain a modern state-of-the- 
art system. The clients and Nielsen both must be willing to dilute current earnings 
to assure future earnings. 

The last recommendation from the people meter review was for Nielsen to commit 
to  client  involvement.  That  meant  involving  clients  in  setting  priorities.  Not  every-
thing can be done at once. Clients need information to permit realistic assessments 
of  the  existing  data.  Legal  clearance  is  not  needed  to  involve  clients  in  a  proactive 
process.  We  simply  need  a  competent  and  confident  Nielsen  management  that  is 
willing to engage clients meaningfully and to be candid, warts and all. 

The  advertisers,  the  government,  someone  needs  to  bring  Nielsen  and  the  clients 
to a new awakening. Keep in mind the goals of the hearings and of the People Meter 
Review. Let’s all get on the same page. We work better when we work together. 

There  is  one  thing  I  feel  I  can  say  today  with  dead  certainty.  The  current  direc-
tion  of  audience  measurement  cannot  go  on  forever.  The  TV  currency  will  become 
weaker and weaker. It will be funny money. At some point the wheels come off the 
bus. 

Senator BURNS. Thank you, Mr. Metzger. 
And  I’ve  noticed  the  attendance  today  of  Representative  Maxine 

Waters, from California. 

And  we  welcome  you.  And  if  you  have  a  statement,  why,  I’d  be 
happy  to  welcome  you  to  the  dais.  I  know  you  called  earlier,  and 
you’re  sure  welcome  here  today  as  we  go  on  with  the  questioning. 
From the testimony we gathered at the table—there was a series 
of  questions  that  came  up  as  we  put  this  hearing  together.  There 
has  been  controversy  with  the  MRC.  What  role  does  it  play?  How 
does  it  play  that  role?  And  do  you  give  it  more  power,  or  teeth,  or 
do  you  take  away  some  of  its  powers?  To  us,  who  have  to  look  at 
problems in the industry, we have to have someplace to go in which 
to base decisions, policy decisions. MRC is the only one we have on 
this  particular  issue.  So,  I  would  ask  the  question  that  everyone, 
I guess, would ask today, If we have nowhere to go for our informa-
tion but to the MRC, then where do we go for accurate information 
and  the  information  that  we  need  in  order  to  bring  some  account-
ability  to  the  industry  that  depends  on  advertising  dollars  to  sur-
vive? 

Mr.  Mullen,  would  you  like  to  start  with  that?  And  then  I’ll  ask 

Ms. Whiting if she’d like to respond to that. 

Mr.  MULLEN.  Well,  I  think  the  question  hits  the  issue  dead  on. 
The  MRC  is  an  organization,  historically,  that  we’ve  been  able  to 
rely upon for independent verification of the processes that Nielsen 
uses to gather ratings data. The MRC’s charge is to make sure that 
the  measurement  services  are  valid,  reliable,  and  effective.  If 
Nielsen  had,  in  fact,  followed  these  processes  voluntarily,  we 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00049 Fmt 6633 Sfmt 6601 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

46 

wouldn’t  be  here  today  with  the  problem  that  we  have.  The  testi-
mony—written  testimony  that  I  have  submitted  shows  a  pattern 
and practice of activities on Nielsen’s part, largely ignoring the con-
cerns and requests of clients and the actions of the MRC, and roll-
ing  out  new  technology  without  accreditation,  despite  the  concerns 
that  we  have  clearly  pointed  out  and  they  have  yet  to  provide  any 
answers to. 

Senator BURNS. Ms. Whiting, would you like to respond? 
Ms. WHITING. Yes, Senator Burns, I would. 
[Laughter.] 
Senator BURNS. I thought you might. 
Ms. WHITING. I’m sure you’re not surprised. 
First  of  all,  we  are  committed—let’s  just  go  back  to  something 
that we were asked publicly to commit to—we are committed to the 
MRC process. I’ve made that statement hundreds of times. We are 
also  committed  to  adopting  the  voluntary  code  of  conduct,  as  long 
as other research companies, as well, have reviewed the issues. So, 
start there. 

Second, we’ve taken every major service we have and voluntarily 
applied for accreditation. The issue here, I think, is about the tim-
ing  of  the  accreditation  process.  And  we  have,  in  fact,  applied  for 
accreditation  in  each  of  the  people  meter  markets.  You  know  that 
some  of  them  are  accredited,  that  the  rest  is  an  ongoing  process. 
But  since  it  is  a  voluntary  process,  and  since  the  process  that  we 
participate in does require an audit, which we are doing, and have 
done, in each market, I feel we have, in fact, been cooperating with 
that process. 

And  as  to  the  point  of  plowing  ahead  without  time,  I  just  would 
remind  you,  we  have  many  clients.  We  have  thousands  of  clients. 
In  any  given  market,  we  have  buyers  and  sellers.  This  all  started 
because  advertisers  asked  us  to  take  the  same  technology  that  we 
had looked at nationally, in the National People Meter Service, and 
bring daily reporting of audience demographics to the top markets. 
And that process then began a conversation with many clients. 

This  didn’t  happen  overnight.  It  wasn’t  pushed  down  anyone’s 
throat. There are, as you’ve seen from a number of the letters that 
you’ve received, supporters on other sides of this issue. And I think, 
ultimately,  what  we  were  trying  to  do  is  balance  buyers’  and  sell-
ers’  requests  for  improved  information,  and  the  timing  sometimes 
isn’t to everyone’s liking. But, in fact, we delayed every major roll-
out  of  every  people  meter  market  based  on  conversations  with  cli-
ents. 

Senator  BURNS.  Mr.  Ivie,  would  you  like  to  respond  to  that, 

please? 

Mr. IVIE. Yes, sir, I would. Yes, Senator Burns. 
I want to try to—— 
Senator BURNS. Pull up the microphone. 
Mr. IVIE. Sorry. 
Senator BURNS. Thank you. 
Mr.  IVIE.  I  want  to  try  to  give  you  maybe  a  little  bit  more  back-
ground.  And  I  know  this  hearing  isn’t  about  LPM,  specifically,  but 
that has been a topic of why we’re here, kind of, what led us here. 
So, there are a couple of truths on both sides of this equation that 
I think you need to know about. 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00050 Fmt 6633 Sfmt 6601 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

47 

The  first  truth  is  that  the  LPM  system,  we  believe,  and  also 
across a broad spectrum of the industry it’s believed, that the LPM 
system  is,  indeed,  more  accurate  than  the  system  it  is  replacing. 
And  it  has  been  audited  and  verified  pretty  strongly  that  it  works 
pretty  well.  So,  when  we  audited  these  LPM  systems,  at  first,  we 
saw that there was a mix of performance in these new markets. We 
saw that Nielsen did certain things very well, and they did certain 
things not so well when they implemented this market. But yet our 
Television  Committee,  made  up  of  some  65  organizations  from 
across the industry, decided that we needed to really do something 
special  here.  We  needed  to  recognize  to  the  marketplace  that  this 
was a superior type of measurement, but we also needed to tell the 
marketplace  that  there  were  problems  with  the  LPM  system  that 
still  needed  to  be  addressed.  So,  we  have  this  status,  and  several 
of the markets continue in this status, called ‘‘conditional accredita-
tion,’’ where we said, ‘‘Nielsen, you can roll this product out, we be-
lieve  it’s  responsible  for  you  to  roll  this  product  out,  but  we  want 
to  recognize  that  this  product  isn’t  done  yet,  that  there  needed  to 
be  some  very  intense  efforts  to  correct  certain  things,’’  and,  for  in-
stance,  Mr.  Mullen’s  testimony  referenced  the  faulting,  which  is 
one area that we’ve been concentrating on with Nielsen. But there 
are others. 

Now, the other truth on the side of this LPM is that Nielsen has, 
in  fact,  rolled  these  markets  out  before  audits  have  taken  place. 
That  is  a  problem.  That’s  a  problem  that,  sitting  in  my  seat,  I 
would never like to see happen again. I don’t write bills, I don’t do 
legislation. I wouldn’t want to substitute my experience for your ex-
perience  in  that  regard,  but  what  I  can  tell  you  is,  we’ve  said  that 
several  things  need  to  be  addressed.  One  is  that  we  don’t  want  it 
to  happen  again  that  the  marketplace  is  uninformed  about  the 
quality of a product when it’s rolled out. Nielsen should commit to 
that, and we want that commitment to hold in the future. 

We  also  think  that  our  voluntary  code  of  conduct  will  help  more 
clearly define how we interact, make sure Nielsen and other rating 
services—because this isn’t just about Nielsen—react to audit find-
ings  promptly.  And  I  think  the  communication  linkage  that  we’re 
requesting  will  make  sure  that  if  there  are  issues  like  this  in  the 
future,  if  this  process  has  a  problem  2  years  from  now,  when  your 
attention is elsewhere, for example, we can come back to the Exec-
utive  Branch  or  Congress  and  say,  ‘‘Hey,  we  have  a  problem.  We 
have a rating service that’s not listening to what we’re saying.’’ 

So,  that’s  why  these  two  truths  need  to  be  considered,  that  not 
everyone  here—they’re  all  telling  you  the  truth,  probably,  but  the 
idea is that there are multi-sides to this equation. 

Senator BURNS. Would you like to respond to that, Ms. Whiting? 
This is the way I learn things—you put all the stakeholders at the 
table, and then we start this dialogue. And this is very good for me, 
to be real honest with you. OK? 

Ms. WHITING. Thank you, Senator Burns. 
I  think  I  said  earlier  prior  to—in  fact,  I  believe  it’s  true  that 
prior  to  the  introduction  of  people  meters  in  individual  markets, 
the  process  for  audits  and  accreditation  had  been  that  a  service 
would  be  up  and  operating—for  instance,  we  have  many  metered 
markets.  We  have  meters  and  diaries.  The  service  would  be 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00051 Fmt 6633 Sfmt 6601 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

48 

launched, an audit would then be performed on a live market. That 
was our procedure for those kind of markets. When we went to the 
people  meter  market,  as  Mr.  Ivie  has  described,  I  think  there  was 
a  much  heightened  sense  of  review  by  our  clients,  in  spite  of  the 
fact  that  we  had  operated  a  people  meter  service  for  many,  many 
years, about that service. And we did have people ask us to do au-
dits before the service, and we replied that the process would have 
to  be  an  audit  upon  a  live  service.  In  spite  of  that,  what  I’ve  just 
indicated earlier, the voluntary code of conduct would propose that 
we would do audits before a service was offered. And we’ve already 
committed to doing that to the MRC regardless of whether the vol-
untary  code  of  conduct  proceeds.  So,  I  think  this  issue  should  be 
one that we can say we agree upon. 

And the other point really is important, which is, we have many 
clients.  I  keep  saying  this,  but  the  other  side  of  the  house,  the  ad-
vertisers,  who  want  information  more  quickly,  have  been  talking 
about  this  for  years.  And  their  urgency  is  not  reflected  in  some  of 
these comments. 

Senator BURNS. Ms. Crawford? 
Ms. CRAWFORD. Thank you, Senator. 
I  would  like  to  say  that,  as  an  advertiser,  or  an  agency  rep-
resenting  advertisers,  we  almost  screamed  our  way  to  getting 
LPMs  in  a—faster  and  faster  and  faster,  because  the  service  had 
been available nationally, since 1987, I believe. I believe that’s the 
date. 

All that being said, I think that it bears reminding of everybody 
that the LPM, from a fault-rate standpoint—and if you can use the 
term ‘‘fault rate’’ as it relates to the meter diary, which is not quite 
the right terminology, but it’s close—the fault rates in the LPM are 
better,  if  there  is  such  a  way  to  say  that,  than  they  are  in  the 
meter  diary.  And  yet,  we  never  came  in  front  of  your  Committee 
when  the  meter/diary  markets  were  out  there.  And  I  would  have 
to  ask  if  that’s  because  the  ratings  are  higher  in  the  meter  diary; 
and  so,  they  were  acceptable.  Now  we’re  here,  and  the  ratings  are 
lower,  and  we’re  now  really  talking  about  the  diversity  of 
viewership  in  all  of  these  130  channels  that  the  American  public 
is  viewing  every  single  day  that  is  now  measurable  by  an  LPM 
technology that was not measurable in the meter diary technology, 
never  mind  the  diary-only,  both  of  which,  by  the  way,  are  accred-
ited by the MRC. 

Senator BURNS. Tell me about fault rates. Define ‘‘fault rates’’ for 

those of us who do not understand the term. 

Ms.  CRAWFORD.  Fault  rates,  in  the  world  of  the  LPM—I  don’t 

know why I’m the one who’s doing that, but—— 

[Laughter.] 
Ms.  CRAWFORD.  George  can  do  that.  I  actually—I  do  know  what 

they mean, but I’d be a lot happier if George did that. 

Senator BURNS. OK. Mr. Ivie? 
Mr.  IVIE.  Yes,  I’ll  try  to—I  want  to  do  two  things,  if  it’s  OK.  I 

want to—— 

Senator BURNS. OK. 
Mr.  IVIE.  I’ll  talk  about  ‘‘fault  rates,’’  and  define  those,  but  I 
also—Ms.  Crawford  raised  the  question  about  the  consistency  of 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00052 Fmt 6633 Sfmt 6601 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

49 

our  treatment  between  diary  markets  and  LPM,  so  I  wanted  to 
spend a minute on that. But let’s talk about fault rates first. 

Fault rate is really the situation where the household that’s par-
ticipating  in  Nielsen’s  panel  is  not  interacting  properly,  or  as  de-
signed,  with  the  Nielsen  meter  somehow.  So,  it  could  be  a  hard-
ware  thing.  The  household  could  have  unplugged  the  meter  or 
moved  the  meter  or  it’s  an  electric  problem  in  the  household,  or 
they  could—in  the  case  of  a  people-meter  household,  they  could  be 
not  interacting  properly  with  the  mechanism  by  which  they  record 
their presence in the room when the television is on. So, if the tele-
vision  is  on,  and  nobody  has  entered  themselves  as  a  viewer,  and 
they’ve  changed  a  channel  on  the  set  or  something  like  that,  that 
meter  is  smart  enough  to  recognize,  ‘‘Hey,  there’s  got  to  be  some-
body  there.  No  one  has  told  me  that  they’re  there.’’  So,  that  data 
is of suspect quality. 

And  Nielsen  has  controls  that  say,  ‘‘If  we  have  enough  of  these 
conditions,  where  there’s  suspect  quality,  we  should  remove  that 
house  from  the  ratings  for  the  day.’’  And  for  most  of  these  faults, 
it’s  just  removed  for  a  day.  It  has  the  ability  to  be  in  the  sample 
the  next  day,  and  that  condition  would  have  to  reoccur  the  next 
day  for  the  household  to  be  removed.  So,  when  Mr.  Mullen  said— 
and I don’t have those statistics in my head, but he said in his tes-
timony  that  a  third  of  the  African  American—or  almost  a  third  of 
the  African  American  and  Hispanic  households  were  not  reporting 
on the average day, that means that they faulted or didn’t interact 
properly. Actually, our more recent experience is less than that, be-
cause these fault rates have been getting better as initiatives have 
been taking place. But that faulting is a difficult problem, because 
you have to coach the households on how to interact with the meter 
and  not  unplug  it.  But  that’s  what  ‘‘faulting’’  is,  when  they’re  not 
interacting properly. 

One thing that I want to say, to talk about equality of treatment, 
is,  when  people  fault,  they’re  almost  certainly  interacting  with  the 
television  set.  It  could  be  that  they’re  just  moving  the  set,  but  a 
lot  of  times,  most  times,  it’s  that  they’re  watching  television  and 
they’re doing something to the television that creates the fault. So, 
we  know  that  people  that  fault  a  lot  tend  to  be  watching  during 
that  time  period.  So  the—and  you  can  tell.  If  you  look  at  house-
holds  that  fault  a  lot,  they  use  television  more  than  households 
that  don’t  fault  a  lot.  And  I  don’t  think  anybody  would  dispute 
that. We’ve seen that hundreds, thousands of times. 

That’s  why  there’s  a  difference  in  treatment  from  the  MRC.  We 
know that in an LPM household, and in these people meter house-
holds, faulting is directly correlated with when people are using the 
television.  In  the  diary  service,  which  I’m  not  going  to  sit  in  front 
of  you  and  say  is  perfect—we  have  initiatives  to  try  to  work  with 
Nielsen  to  correct  that—we  know  that  that  is  not  directly  linked 
to viewing, necessarily. It’s linked to other things. ‘‘I’m too busy to 
complete  a  diary.  Maybe  I  can’t  read  or  write.’’  It’s  linked  to  a  lot 
of  other  things—literacy,  maybe  I’m  used  to  working  on  the  Inter-
net, I’m not used to writing a diary, et cetera. 

So,  there  are  a  lot  of  things  that  come  into  play,  but  not  nec-
essarily  as  direct  of  a  tie  to  television  viewing,  as  we  see  in  this 
LPM.  And  this  stuff  needs  to  be  studied.  But  there  is  a  difference 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00053 Fmt 6633 Sfmt 6601 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

50 

in  treatment,  because  there  is  a  difference  in  the  problem.  Every 
problem  needs  a  custom  solution,  and  that’s  why  we’re  focusing  in 
two different ways on these services. 

Senator  BURNS.  I’m  going  to  go  to—I’m  going  to  go  to  Mr. 

Metzger, then Mr. Mullen, and—— 

Mr. METZGER. Let me describe ‘‘faults’’ for you in a simpler way. 
It’s  going  to—some  households,  it’s  not  processed,  something’s 
wrong.  That’s  a  fault.  Nielsen  designates  a  sample,  that  should  be 
measured,  to  count  everyone.  Some  of  those  homes  cannot  be  in-
stalled because the meters will not accommodate modern digital de-
livery  systems  and  recording  systems.  So,  you  miss  those  homes. 
Then  you  have  homes  that  fault,  so  you  miss  those  homes.  Now, 
both  of  those  homes  are  not  randomly  selected,  they’re  particular 
kinds  of  homes.  In  the  case  of  the  faults,  we  know  those  occur 
much  more  where  there  are  more  sets  or  more  people.  Interest-
ingly, in White households, 11 percent of White households have 5 
or more people. Twenty percent of Black households have 5 or more 
people.  And  almost  30  percent  of  Hispanic  households  have  5  or 
more  people.  So,  that’s  the  reason  minorities  should  be  very  con-
cerned about these systems, whether it’s the meter diary or the A/ 
P meter. They both have the same problem. And part of the reason 
those  faults  are  so  high  and  why  we’re  skipping  homes  is  that  the 
metering  technology  is  still  based  in  the  past,  it  is  not  up  to  snuff 
with  modern  technology.  You  can’t  expect  people—up  to  a  certain 
limit—you  can  put  a  certain  task  on  people—you  have  to  make  it 
easy  for  them.  And  the  task  for  them  now  is  too  difficult.  That’s 
the problem. 

Senator  BURNS.  Let  me  offer  an  opinion  here,  because  I  don’t 
want  to  get  too  far  astray  on  people  meters  and  this  type  thing. 
That’s  a  technology  that  we  can  take  up  in  the  MRC,  and  to  say 
why we can’t make accreditation here, or recommend accreditation, 
or  whatever,  I  think  that’s  for  the  industry  and  the  MRC  to  work 
out. And if they find some problems with it, then I think it’s incum-
bent,  or  should  be  incumbent,  on  the  sampling  company,  such  as 
Nielsen,  to  try  to  work  on  those  fault  rates  and  to  make  them 
whole.  That’s  the  real  purpose  of  this  hearing,  to  be  right  honest 
with  you.  I  can’t  judge,  here,  which  is  best.  That’s  not  what  this 
is about. This is about getting a fairness with the—and doing busi-
ness  with  the  only  game  in  town,  and  how  we  get  these  people  to-
gether. 

Mr. Mullen, you want to respond? 
Mr. MULLEN. Yes, thank you, Mr. Chairman. 
The point of fault rates, in bringing that up, is not—we could de-
bate that all day long. As I say, you can do anything with numbers, 
and  that’s  not  our  purpose.  In  fact,  that’s  why  the  MRC  exists,  so 
that we can all share and analyze that data to determine if Nielsen 
is,  in  fact,  delivering  the  product  that  they  have  sold  to  us  in  the 
marketplace. 

The  point  that  Mr.  Metzger  makes  is  absolutely  right.  It’s  the 
key  audiences  of  homes  with  five  or  more  people  which  tend  to 
over-index—and  in  African-American  homes  and  in  Hispanic 
homes—that are also our key audiences, skew into the younger de-
mographics, and young homes, that tend to fault on a more regular 
basis.  When  I  referenced  one-third  of  African-American  men  and 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00054 Fmt 6633 Sfmt 6601 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

51 

Hispanic  men  in  New  York  in  a  given  week,  that  is  a  year  after 
they’ve  rolled  out  the  service.  They’ve  shown  no  ability,  on  a  con-
sistent  basis,  to  improve  that.  That’s  what  the  MRC  is  looking  at. 
That’s why the MRC has not given full accreditation to the service 
in  New  York.  And  that’s  our  only  concern,  is,  don’t  commercialize 
this  product  in  additional  markets  like  Washington,  D.C.,  and 
Philadelphia,  until  you’ve  demonstrated  to  us  that  you  have  the 
ability to measure these audiences properly in the Nation’s largest 
markets. 

Senator BURNS. Ms. Whiting? 
Ms. WHITING. Yes, please. 
I  think,  because  we  are  talking  about  broad  quality  here,  one  of 
the measures of quality is fault rates. But it’s not the only one. It’s 
the  sample  size.  It’s  the  population  that  you’re  measuring.  It’s  the 
characteristics and the quality. It’s the—it is the technology, which 
allows  you  to  look  at  the  breadth  of  channels,  24  hours  a  day,  365 
days  a  year.  It’s  the  cooperation  rate.  And  we  are  lucky,  actually, 
with  people  meters,  to  be  able  to  have  the  technology  that  allows 
us  to  know  when  someone’s  not  doing  what  we  would  like  them  to 
be  doing,  or  when  a  TV  set  is  moved  or  unplugged.  And  that  has 
to be looked at in a relative way. On every broad measure, our peo-
ple  meter  service  is  better  than  the  service  it  has  replaced.  And 
there  are  always  going  to  be  issues  with  individual  days  and  indi-
vidual  segments.  And  that’s  true  of  polls,  and  that’s  true  of  any 
measure and any statistical sample you take. 

But  I  think,  to  Ms.  Crawford’s  point,  we  do  need  to  look  at  the 
fact that we have diary services in some markets, meter diary serv-
ice  in  others,  and  then  people  meter  service.  And  this  is  an  im-
provement  over  the  current  system,  and  one  of  many  things  we 
have  to  continue  to  improve,  and  we  do  that  in  every  one  of  our 
services.  They  have  to  have  a  commitment  to  improvement.  So,  I 
think it’s one of many measures, and it’s really somewhat disingen-
uous  to  point  out  one  aspect  of  what  is  a  greatly  improved  system 
that allows us to report many, many channels every day with more 
people of color, with higher cooperation rates, and with better tech-
nology. 

And I’d like to add that we do not, anymore, with our A/P meter, 
and with the recent addition of our ability to measure digital video 
recorders, bypass homes for technology reasons, which is something 
Mr. Metzger said. 

Senator  BURNS.  Well,  I  want  to—I’m  going  to  throw  out  another 
question here. When you go out and you have to locate your, what-
ever  it  is,  a  diary  or  the  people  meter,  you  knock  on  the  door,  and 
you said, ‘‘Would you like to be, or could we ask you to be, a person 
that  would  do  this  sampling  for  us?’’  how  many  times  are  you 
turned  down?  I  mean,  do  you  have  a  turn-down  factor  that  peo-
ple—I  mean,  I’d  like  to  know,  when  you  knock  on  the  door,  who 
says  yes  and  who  says  no  and—because  I  know  it  has  to  be  a  vol-
untary program, and there has to be consent. I’d like to know, have 
you got any kind of a rate on that? 

Ms.  WHITING.  Of  course  we  do.  One  of  the  things  we  have  to  re-
port  in  our  different  reports,  whether  they  be  a  diary  report  or  a 
meter  diary  or  the  people  meter,  are  cooperation  rates.  And  that’s 
what I think you’re asking. 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00055 Fmt 6633 Sfmt 6601 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

52 

Senator BURNS. Yes, I think that’s what I’m getting at. 
Ms.  WHITING.  And  they’re  different  for  different  markets,  and 
they’re  different  for  different  services,  and  they’re  reported,  if  it’s 
a  daily  service,  every  day,  if  it’s  weekly,  every  week.  In  that  local 
people meter service, the average cooperation rate is about 40 per-
cent,  which  means  60  percent  of  the  people  turn  you  down.  But  if 
you  think  about  polling  and  marketing  research,  that’s  actually 
very high. 

Ms. SHAGRIN. And one of the problems is that the people that it’s 
hardest  to  get  to  say,  ‘‘Yes,  I’ll  be  in  your  sample,’’  are  the  same 
people  that  it’s  hardest  to  keep  giving  you  reliable  data.  So,  the 
point  is,  40  percent  is  good.  Ninety  percent  giving  you  usable  data 
is good. But if you’re totally excluding, or almost excluding, certain 
types  of  households,  then  the  resulting  audience  information  is 
flawed.  And  I  think  the  focus  on  the  MRC—at  the  MRC  has  been, 
is the audience—are the audience estimates biased? Is there a flaw 
there? And is it fixable? And I think the pressure has been to say, 
we  think  it’s  fixable.  We  think  it  impacts  the  quality  of  the  data 
and  the  reliability  of  the  data  and  causes  some  differences  from 
day  to  day.  Because  if  20  young  men  in  New  York  are  providing 
usable data on Monday, and 20 fewer on Tuesday, your ratings for 
adults 18 to 24, or males 18 to 34, change those 2 days, it has noth-
ing  to  do  with  real  change.  So,  we’ve  been  focusing,  at  the  MRC 
level,  on,  what  are  the  things  that  we  see  in  these  new  markets 
that  may  be  causing  a  bias?  What  are  we  pointing  out  to  Nielsen? 
And this is why I believe the MRC drives consistent improvement. 
What needs to be fixed? And then constantly reviewing that to say, 
‘‘OK,  now  it  is  a  level  that  we  are  very  comfortable  with.’’  And,  as 
George  said  earlier,  the  conditional  accreditation  was  a  very  new 
thing for the MRC, but the MRC membership agreed to it, because 
they wanted to send a clear message that there were a lot of things 
that  were  better,  but  there  were  also  a  lot  of  things  that  weren’t 
better and needed to be addressed. 

Senator  BURNS.  OK.  Mr.  Mullen,  you’ve  shown  some  interest  in 

this statement? Do you want to respond to that? 

Mr.  MULLEN.  No,  I  certainly  agree  that  the  process  of  accredita-
tion  has  been  slowed  for  the  LPM,  but  I  think  it’s  largely  because 
MRC is not yet comfortable that Nielsen is delivering on the prod-
uct that it has designed. 

Senator BURNS. Mr. Ivie? 
Mr.  IVIE.  Yes,  I  just  want  to  add  two  points  of  clarification.  Ms. 
Whiting  quoted  a  response-rate  average  of  40  percent.  That  varies 
widely sometimes between markets. It could be higher than 40 per-
cent, or it could be lower. For example, one of the markets in play 
that  tends  to  be  lower  is  New  York.  That  rate  is  in,  sort  of,  the 
mid-1920s,  is  my  recollection,  in  terms  of  response  rate.  So,  those 
response  rates  vary  a  lot.  If  you  go  to  smaller  markets  or  more 
rural markets, for example, those response rates tend to be higher. 
More  urban  markets,  where  it  might  be  harder  to  get  mail  deliv-
ered, et cetera, those response rates can be much more difficult and 
lower. 

I just want to spend a second on—the focus of the MRC is not— 
is—when  we  conduct  audits,  we  look  at  literally  hundreds  of  per-
formance  areas  and  standards  areas  when  we  look  at  a  product. 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00056 Fmt 6633 Sfmt 6601 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

53 

Faulting  has  been  discussed  here  today,  but  we  look  at  response 
rates, sample distribution, you know, the procedures in the field to 
install  households.  And,  a  lot  of  times,  when  we  don’t  comment  on 
things, it’s because they’re working good. And we saw, when we au-
dited these LPMs, that there was a lot working good. And faulting 
is one thorn that remains. And faulting has improved somewhat in 
some of the markets, but it’s—I mean, those markets remain condi-
tional, because we still don’t believe that faulting performance area 
meets our expectations. 

Senator BURNS. OK. I’ve got a new question. Let’s talk about the 
legislation  just  for  a  second.  Some  have  said  that  this  bill  would 
raise barriers to entry. And I know it can cost a lot of money, $100 
million or more in development costs, and several years to roll out 
new measurement services. But MRC audits can cost $100,000 and 
take a few months. That’s 1 or 2 percent, in money terms, and not 
much  more  in  the  terms  of  time.  I  don’t  see  that  as  a  barrier.  Tell 
me if I’m wrong. 

Ms. WHITING. Senator Burns, may—— 
Senator BURNS. Yes. 
Ms. WHITING.—I reply? 
I  think  the  cost  is  not  so  much  the  issue;  it’s  the  time.  And  it’s 
that there is no clear knowledge, the way the bill is drafted, of the 
amount of time that it would take to accredit a service. And so, as 
I  understand  the  bill  to  be  written,  if  you  have  to  have  every 
change  to  an  accredit  service  accredited—and  I  think  that  is  the 
way  it’s  written  today—before  you  can  actually  offer  it,  then  I  do 
believe,  if  you  are  creating  a  rating  service  or  putting  together  in-
novation  or  testing  a  new  technology  you  want  to  deploy,  you  do 
not  know  when  that  service  will  be  accredited.  You  have  clients 
who  are  asking  for  it,  you  have  contracts,  you  have  a  process,  but 
you  could  easily  spend  a  year.  And  we  have  had  cases  where  the 
accreditation  process  has  taken  a  year,  or  more.  And  if  that’s  the 
case,  this  would  not  allow  any  business  that  I  know  of  to  put  that 
process in place, and I think it would also give pause to anyone en-
tering  the  business,  if  you  did  not  know  when  you  could  actually 
commercialize your service. 
Senator BURNS. Mr. Ivie? 
Mr. IVIE. I just—— 
Senator BURNS. Everybody should have opinion on this one. 
Mr. IVIE. Yes, I—— 
Senator BURNS. But I might—— 
Mr. IVIE. Just one point of clarification. The audit process, itself, 
never—I mean, in my history with the MRC, the audit process has 
never  taken  a  year.  What  takes  a  year  is  if  you  conduct  an  audit 
and  you  find  some  issues  within  the  audit,  and  ultimately  those 
have to be corrected by the measurement service. They have to in-
stall  new  initiatives,  make  changes,  change  their  sampling,  what-
ever  it  may  be.  Those  procedures  can  take  a  long  time.  Then  you 
have to verify that they’ve been done. And then, ultimately, you get 
the decision that it completely meets the standards, and it becomes 
accredited. So, it is valid that we’ve done audits that have extended 
long  periods  of  time,  but  it’s  not  because  of  the  MRC  executing  an 
audit for a year. Audits don’t take a year. Audits take a month, or 
they might take something like that. But correcting issues that are 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00057 Fmt 6633 Sfmt 6601 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

54 

found  in  audits—and  this  is  the  real  critical  component—MRC’s 
about  process  improvement.  Improving  those  processes  can  take  a 
long  period  of  time.  We  have  a  rating  service  that  we  audit  that 
has been in the audit process, without full accreditation, for almost 
a  decade,  because  they’re  trying—and  this  isn’t  Nielsen;  I  should 
clarify  that—because  they  have  certain  aspects  of  their  product 
that  do  not  meet  our  standards,  and  they’re  figuring  out,  as  they 
go  along,  you  know,  how  to  correct  that  product.  And  that  has 
taken  a  decade,  because  these  things  aren’t  easy.  The  cooperation 
rates and things, trying to get people to cooperate with data-inten-
sive research—you’re trying to gather all sorts of information about 
what  soap  they  use  or  it  could  be  anything.  This  stuff  is  hard  to 
gather, and these process improvements are very difficult to make. 
But  that  is  how  the  industry  is  benefited.  That  product  doesn’t 
have  accreditation.  And  what  happens  is,  they  don’t  bear  our  logo, 
the users know that there are issues. And that—— 

Senator BURNS. Ms. Shagrin? 
Ms.  SHAGRIN.  If  the  MRC  and  the  audit  process  finds  a  signifi-
cant problem, and they go back to the ratings company, whichever 
ratings company it is, and says, ‘‘We cannot take a vote, we cannot 
give  you  accreditation  because  we  found  this  problem,’’  that’s  how 
it’s  protecting  the  industry.  That’s  how  it’s  constantly  improving 
the ratings, themselves—and I’m not limiting it just to television— 
and getting the best-possible estimates for this industry to continue 
to make good decisions and to grow. 

Senator  BURNS.  Now  let’s  hear  from  Mr.  Mullen  first,  and  then, 
Ms.  Whiting,  we’ll  have  all  of  this  accumulated,  and  you  can  take 
your shot. Yes? And then I’ll go to Mr. Metzger. 

Mr. MULLEN. Yes, Mr. Chairman. 
We, first, as a company—and I cannot speak for the entire broad-
cast  industry,  though  I  think  many  would  feel  exactly  the  same 
way—accept accreditation. If a market is accredited, we accept the 
ratings,  without  question,  and  we  compete  with  those  ratings.  The 
New  York  market,  as  an  example,  has  been  audited.  There  have 
been  problems  that  have  been  shown  there,  significant  problems 
pointed out to Nielsen by the MRC. Nielsen has—I give them cred-
it—tried  to  fix  those  existing  problems.  But,  month  after  month, 
they  have  not  shown  significant  improvement,  and,  with  that,  the 
MRC  board,  upon  evaluating  what  they’ve  been  doing,  has  not  ac-
credited  the  market.  They’ve  shown  the  same  problem  in  other 
markets.  Our  largest  objection  was,  with  that  type  of  a  track  his-
tory, they are still rolling out additional markets without audit and 
without  accreditation.  We  have  no  confidence  in  the  quality  of  the 
service and the ratings that they’re providing us. And that does in-
fluence  the  type  of  programming  that  we  run  and  the  type  of  pro-
gramming that we will run in the future. 

Senator BURNS. Ms. Whiting? 
Ms. WHITING. Well, I think this discussion actually is a very good 
example of the different points of view on why accreditation should 
be  mandatory  or  voluntary,  and  when  it  should  occur,  because  we 
have  many  clients—and  I  keep  going  back  to  this—who  would  say 
that they’re disadvantaged unless they have the better system that 
a  people  meter  offers,  or  a  meter/diary  system,  or  something  else. 
And  their  point  of  view  would  be  that  they  want  this  in  the  com-

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00058 Fmt 6633 Sfmt 6601 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

55 

mercial  world  faster.  And  that’s  one  reason  I  believe  that  we  have 
to  look  at  the  voluntary  code  of  conduct,  we  have  to  look  at  the 
ability to have a faster way to market for big changes, and we have 
to use the MRC process and not make it mandatory, because if ac-
creditation—not  an  audit—can  take  a  year  or  two,  or  who  knows 
how long, what happens to all of the clients who are disadvantaged 
in that system? 

Senator BURNS. Well, let me say, I agree with you in some parts 

of your statement, but if voluntary doesn’t work—— 

Ms.  WHITING.  Well,  I  think  we  may  disagree  over  whether  it 

doesn’t work. 

Senator  BURNS.  Well,  but  I’m  saying—in  some  areas,  I  think  it 
does, and that’s my—I come out of the industry. I like the idea of— 
that we put up some sort of a situation where we can solve our own 
problems between the broadcaster and the samplers. But if the vol-
untary system breaks down, then where do we go when there’s only 
one  company  out  there?  I  guess  that’s  what  we  look  at.  We  really 
weren’t  elected  by  a  constituency  to  oversee  a  monopoly,  an  un-
regulated  monopoly.  That’s  what,  kind  of,  causes  us  concern,  be-
cause that red flag goes up, and sometimes we do things that have 
unintended  consequences,  and  we  don’t  want  to  do  that  in  this 
case, because I love this industry. And so, once there’s a breakdown 
or  somebody  gets  up  on  the  wrong  side  of  the  breakfast  table  one 
morning and decides not to cooperate—— 

I want to hear from Mr. Metzger, please. And then I’ll come back 

to you. You’ll get your say. I’ll not leave you out. 

Mr.  METZGER.  I  said  in  my  testimony  that  I  thought  the  MRC 
aided innovation and competition. The reason I say that is from my 
own experience. First, in the context of our RADAR service, for ex-
ample, I mean, the MRC helps all of us track where the fault lines 
are—not  just  faults,  but  any  issues  we  have—and,  because  of  that 
industry  inspection,  it  brings  a  pressure  to  do  things  better.  And 
with  our  RADAR  service—I  think  it  was  in  1999,  we  were  look-
ing—our response rates were dropping, also, but other services—we 
had  experimented  on  how  to  get  a  better  response,  and  we  struc-
tured  an  experiment  and  went  to  the  MRC  to  discuss  that  experi-
ment  before  we  did  it,  and  got  their—to  buy  into  the  process  and 
the  sample  sizes  and  so  forth.  Matter  of  fact,  at  that  time,  there 
was a minority network that was not a part of the MRC, and I in-
sisted they be invited to those meetings to discuss that. We did the 
experiment,  got  it  fully  accepted  and  implemented  in  a  very  fast 
time—in  part,  because  we  had  the  industry  exposure  through  the 
MRC to help the communications process. 

And  with  regard  to  competition,  Michael  Porter,  of  Harvard,  is 
famous  for  saying,  ‘‘The  way  to  get  a  good  product  is  to  create 
value  and  signal  value.’’  With  our  SMART  Laboratory,  we  created, 
I  think,  a  better  product,  clearly.  Now,  how  do  you  signal  that? 
Had we got funding, I would have been breaking the door down of 
the MRC to get in there and have them work with us, just like we 
did with that experiment on improving response rates, as we rolled 
out  the  service.  Rolling  out  the  service  was  going  to  take  1  to  2 
years.  And  then,  parallel  with  that,  you  can  bring  the  MRC  in— 
I mean, how can I compete with—Nielsen has 200 salespeople, I’ve 
got  three  or  four  people  out  there.  I  can  go  to  that  one  place  that 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00059 Fmt 6633 Sfmt 6601 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

56 

the  industry  is  looking  at,  work  with  them  in  a  positive  way,  and 
it would help me break into the market faster, rather than impede 
me. 

Ms. CRAWFORD. So—— 
Senator BURNS. Ms. Crawford? 
Ms.  CRAWFORD.—what  we  have  here  is  the  fact  that  the  indus-
try, itself, made the decision not to support a second rating service. 
It  was  the  industry  that  did  this.  It  was  not  Nielsen  or  anybody 
else  that  made  that  decision.  It  was  the  broadcasters,  the  adver-
tisers, the agencies, and so forth. So, the bottom line is, is that it’s 
the industry that made that decision. That’s number one. 

Number two, I would like to remind everybody that we have the 
advertiser,  who  is  paying  the  ultimate  price  here.  It  is  paying  for 
Nielsen’s service, or anybody else’s, no matter what the medium is, 
in  the  cost-per-spot,  as  you  very  well  know.  As  a  result,  these  ad-
vertisers  have  been  waiting  15  years  in  the  local  marketplaces  to 
have a service that told them the next day how well their spot that 
ran  performed  the  night  before.  This  has  been  a  long  time  in  com-
ing.  The  fault  rates  are  better  in  the  LPM  than  they  are  in  the 
meter/diary  markets.  And  yet,  we’re  sitting  at  this  table  over  the 
LPM. And I’m very concerned that we are talking about this when 
we  have  accreditation  on  the  meter/diary  side  and  we  don’t  have 
accreditation on the LPM side. 
Senator BURNS. Mr. Mullen? 
Mr.  MULLEN.  Mr.  Chairman,  I  would  say  that  when  you  talk 
about  paying  the  ultimate  price,  ultimately,  I  think  that  is  the 
weight borne by the stations. Not only do we pay the vast majority 
of  the  fees  for  Nielsen’s  local  services—and  Susan  could  tell, 
maybe, better than I, what that percent is, but certainly a vast ma-
jority  of  it—how  our  ratings  are  reported,  based  upon  that  ratings 
system, ultimately determines our rates. And if it’s not an accurate 
system, we pay the ultimate price. 

And to the point of accreditation, I know right now that Arbitron 
is working with the MRC for accreditation. They are submitting to 
the audits and seeking accreditation for a new service in the Hous-
ton market. So, I do not believe that the ability to go through MRC 
for  accreditation  would  be  a  hindrance  for  entry  into  this  business 
at all. 

Senator BURNS. Ms. Whiting? 
Ms. WHITING. Yes, Senator Burns. 
Senator BURNS. Then I’ll turn to Mr. Ivie. 
Ms.  WHITING.  I  think  stepping  back  a  bit—you  asked,  what  do 
we do when we’re here at this place, and what could you expect us 
to  do?  And  over  the  last  year  and  a  half,  starting  with  every  piece 
of recommendation that our independent task force made in a won-
derful group of people who worked 9 months voluntarily, to put to-
gether  a  review  of  our  procedures,  made  a  set  of  recommendations 
that we actually have implemented, are in the process of doing. In 
the  written  testimony  I  submitted,  there  are  pages  of  quality  im-
provements that we’ve made in the Local People Meter service vol-
untarily.  And  they  range—everything  from  staffing  additions,  like 
50 people in significant markets, to incentives, to different coaching 
procedures.  There  have  been  many,  many  focused  voluntary  im-
provements  in  the  last  year  and  a  half.  And  you  might  say,  well, 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00060 Fmt 6633 Sfmt 6601 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

57 

that’s  because  there  has  been  so  much  attention  on  this  issue.  Of 
course that’s part of it. But it’s not all of it. And I think if you look 
back at the last 5 years, particularly, of investment, we have inde-
pendently, voluntarily invested a lot of money to improve our serv-
ice.  And  I  think  that  speaks  to  why  we  believe  that  a  voluntary 
code  of  conduct  would  allow  us  the  flexibility  to  move  improve-
ments  in  the  service  forward  as  long  as  the  rating  services—and 
we are—commit to that fact, that there have to be audits before the 
service is commercial. 

And  I  agree  with  Mr.  Mullen  that  Arbitron  is,  in  fact,  working 
with  the  MRC.  So  are  we  on  many  of  the  things  we  do  before  we 
do  them.  But  that  does  not  guarantee  accreditation.  You  can  have 
a  review  of  the  process,  and  if  the  accreditation  is  mandatory,  it’s 
a different issue. 

Senator BURNS. Mr. Ivie? 
Mr.  IVIE.  I  just  want  to  address  two  things.  Ms.  Whiting  men-
tioned our voluntary code of conduct again. Something I didn’t com-
municate to you is, we are working on that with some urgency. We 
expect to have sign-off on that voluntary code by October 15. That’s 
a goal that we’ve set for ourselves to work with rating services and 
our  members  to  have  that  code  completed  and  prepared  for  adop-
tion by the rating services. 

The  other  thing  I  would  say  is,  all  this  testimony  sounds  nice. 
I  come  back  to  one  fact.  There  were  at  least  three  LPM  markets 
implemented,  commercialized,  without  having  an  audit.  And  Ms. 
Whiting has agreed to that in front of you, that that won’t happen 
again.  The  voluntary  code  of  conduct  requires—you  know,  states  a 
clear preference, as a voluntary code does, that that shouldn’t hap-
pen.  Nielsen  has  a  number  of  products  that  are  not  audited  that 
we believe should be audited, and there needs to be dialogue about 
that. But that is really where our focus is, because that’s where we 
provide  value  and  provide  our  service  to  the  marketplace—doing 
these  audits,  making  sure  Nielsen,  with  all  of  the  marketplace 
power that has been discussed here today, complies with the MRC 
audit process. That’s where my focus is. 

Senator  BURNS.  Mr.  Ivie,  I’ve  got  a  question,  and  I  think  this  is 
key  to  what  this  hearing  is  about  today,  too,  also.  There’s  little  or 
no competition in the field with Nielsen. I want to start an organi-
zation, a research organization. I come to you, and I present to you 
a methodology on how we’re going to do it, my technology that I’m 
using.  You  look  at  it,  you’d  say,  ‘‘I’d  like  to  see  a  pilot  program.’’ 
I facilitate that. Can I get accreditation from the MRC with a vote 
after  they’ve  all  looked  at  it,  and  can  I  compete  in  a  market  with 
the Nielsen folks? 

Mr. IVIE. Well, you just described a very interactive scenario. You 
come  to  the  MRC  when  you  are,  sort  of,  ‘‘baking’’  the  product. 
You’re  designing  your  product,  you  come  to  us,  and  you  bounce  it 
off of us. 

Senator BURNS. No, I’ve got—— 
Mr. IVIE. We do that. 
Senator BURNS. Yes. 
Mr.  IVIE.  You  then  develop  a  prototype  of  your  meter,  you  bring 
it  to  us,  we  can  test  that  in  a  laboratory.  We  can  go  very  far  in 
an  audit  to  conduct  that  audit  and  get  a  lot  of  assurance  for  our 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00061 Fmt 6633 Sfmt 6601 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

58 

members prior to implementation of the first respondent. But, ulti-
mately, it is a fact that we don’t accredit any research—this is one 
hallmark of the MRC—until we see that in operation. So—— 

Senator  BURNS.  Well,  I  say  I  will  pay  the  bill,  I’ll  give  you—you 

tell me what kind of a pilot program you want me to run—— 

Mr. IVIE. Right. 
Senator BURNS.—and I do that, and I submit it to you. 
Mr.  IVIE.  We  have  no  barriers  that  would  stop  you  from  coming 
to us to accredit. We audit all comers. We’ve never turned down an 
audit.  If  somebody  came  to  us—I  mean,  one  of  the  things—I  have 
a  stack  of  legal  opinions  about  two  things.  One  is,  the  MRC  never 
discusses  anything  financial  in  any  of  our  meetings;  otherwise, 
we’re colluding against the rating service, financially. That’s strict-
ly prohibited. The other thing I have a stack of legal opinions about 
historically  is,  we  cannot  turn  down  audits.  We’re  an  equal-access 
organization.  We  don’t  turn  down  an  audit.  You  could  come  to  us, 
we  would  execute  that  audit.  And,  guess  what?  The  audit  timing 
has  nothing  to  do  with  the  membership.  So,  no  member  can  delay 
an  audit.  That’s  done  by  the  staff,  the  independent  staff  of  the 
MRC, who doesn’t work for any broadcaster, cable-caster, or adver-
tising  agency.  We  work  with  the  rating  service.  We  establish  the 
audit  schedule  and  timing  and  when  the  audit  will  be  conducted. 
So,  that—the  audit  process  really—there  is  no  issue  of  whether 
that could be delayed, because the audit process, itself, is controlled 
by  the  staff.  Now,  ultimately,  when  that  audit  is  done,  we  do  con-
vene our members to review that audit, read the audit, go through 
the  pain  of  meeting  with  the  independent  CPAs  that  conduct  the 
audit in getting all the findings. That’s when the accreditation deci-
sion  comes  into  play.  It  either  makes  it  or  it  doesn’t.  And  if  it 
doesn’t,  there’s  a  reason,  and  that  has  to  be  improved.  But  that’s 
how the process works. We don’t turn any organizations—— 

Senator BURNS. Mr. Metzger? 
Mr. METZGER. I think it should be understood that the accredita-
tion  process  is  not  any  kind  of  mystery.  Again,  I  was  audited  for 
30  years  and  accredited  for  30  years.  And  if  you  do  things  up  to 
snuff, there’s no ambiguity about this, it’s accredited. 

Ms. SHAGRIN. Could I add that the—your scenario, if you had the 
pilot  audited,  your  data-collection  system  and  tool  could  be  accred-
ited,  your  methodology  could  be  accredited.  But  until  you  rolled  it 
out  into  a  real  sample,  your  sample  could  not  be  accredited,  and, 
therefore,  the  service  would  not  be  accredited.  But  going  into  roll-
out,  you  would  know  that,  assuming  you’ve  got  a  representative 
sample,  that  you  would  be  accredited,  because  pieces  of  it  would 
have  already  passed  the  test.  But  without  the  sample,  without 
being  able  to  audit  and  accredit  the  sample,  the  service  could  not 
be accredited. 

Senator BURNS. OK. Mr. Mullen? 
Mr. MULLEN. Senator, in Ms. Whiting’s written testimony and in 
her statements today, she talked about Nielsen’s willingness to talk 
further about the voluntary code of conduct, but in her written tes-
timony  she  stated  it  was  applicable  to  future  commercial  ratings, 
said nothing about existing, and also said that that would be done 
with  some  give-and-take,  which  we  read  to  say  there  are  things 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00062 Fmt 6633 Sfmt 6601 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

59 

Nielsen needs to see changed in the MRC’s proposed voluntary code 
of conduct. That certainly concerns me. 

And then, to take it a step further, again, this is not a discussion 
about  lower  ratings.  We  have  tried  for  years  to  work  with  Nielsen 
behind  the  scenes,  professionally,  in  meetings  face-to-face.  Susan 
and  I  have  been  meeting  face  to  face  on  the  LPM  issue  now  for 
probably  more  than  3  years.  But  we  are  dealing  with  a  monopoly 
that,  in  my  opinion,  is  acting  as  one.  Either  we  allow  Nielsen  that 
monopoly  to  determine  the  specifications  for  their  own  service,  or 
we  depend  upon  the  MRC  for  those  specifications  and  oversight. 
And I think the bill that you have introduced, S. 1372, helps us ac-
complish that. 

Senator BURNS. Well, I’m just going to make a comment now. I’m 
going  to  have  to  get  some  more  information  from  the  MRC.  We’re 
going  to  have  to  sit  down  and  visit  about  it.  Because  if  I  go  out  of 
here  and  I  invest  in  the  technology,  and  then—and  give  them  a 
pilot  program  any  place  in  the  country  they  want  to  take  it  and 
test it before I go into the field, before I make the big investment— 
because I’d hate to go out here and say, ‘‘OK, now I’m going to sam-
ple  one  area,  one  ADI,’’  and  all  at  once—and  not  get  accreditation 
on it. That’s a big chance that I’ve taken. In other words, there has 
to  be  some  way  that  I  know  that  I’m  on  solid  ground,  that  I’ve 
crossed  all  the  ‘‘t’s’’  and  dotted  all  the  ‘‘i’s’’  and  done  everything  in 
methodology and technology that would merit your accreditation. 

Mr.  IVIE.  One  thing  that  I  just  should  mention.  There  is  some-
thing  called  a  ‘‘pre-audit.’’  A  pre-audit  is—first  of  all,  it’s  kind  of 
a  misnomer,  it’s  not  an  audit,  but  what  it  is,  is  a  brief  review  of 
a rating service, where we engage—we and a measurement service 
that  approaches  us  engages  the  CPA  firm  to  go  out  and  walk 
through  the  methodology.  They  don’t  conduct  an  audit,  but  how 
does  the  sampling  work,  how  does  the  equipment  work,  how  does 
the  reporting  work,  all  the  different  aspects  that  we  generally 
study.  This  is  very,  very  cost  effective.  It  takes  about  2  weeks  to 
actually  execute  a  pre-audit.  But  that  is  a  service  that  we  offer. 
And  the  end  product  of  that  service  is  a  letter  that  the  CPAs 
produce.  Now,  these  are  the  same  CPAs  that  conduct  the  audit, 
eventually, in the future. 

Senator BURNS. OK. 
Mr. IVIE. That letter is sent to me, the Director of the MRC, and 
the  rating  service.  And  that  letter  says  something  like,  ‘‘We  didn’t 
conduct  an  audit.  All  we  did  was  do  a  walk-through,  but  had  we 
been  auditing  you,  these  are  the  things  that  we  noticed  in  your 
process,  in  your  technology,  that  are  accreditation  problems.’’  And 
they  communicate  that  in  advance  to  the  rating  service.  So,  if— 
you’ve  not  spent  a  penny  on  a  regular  audit  yet,  you’ve  just  had 
this walk-through, and you have a list, and I have a list, of the sig-
nificant deficiencies that you have. This process is designed just for 
the  exact  thing  you  were  asking  a  question  about.  That  pre-audit 
exists, and it’s there. 

Senator BURNS. OK. Yes, ma’am? 
Ms.  WHITING.  I’d  just  like  to  reply  to  Mr.  Mullen.  We  have  com-
mitted  publicly  to  an  audit  before  commercialization  of  the  next 
three  people-meter  markets,  and  that  is  outside  of  the  voluntary 
code of conduct, for Dallas, Detroit, and Atlanta. And so, I do think 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00063 Fmt 6633 Sfmt 6601 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

60 

I  understand  that  it’s  important,  and  we  have  committed  to  doing 
that. But, back to the point we were just discussing, this conversa-
tion is why I am concerned about a mandatory accreditation versus 
a very strong voluntary code of conduct, because I think you—here, 
you  could  do  all  the  right  steps,  and  I  hope  everybody  would,  in  a 
new service being offered ahead of time, but you actually, until the 
final  service  or  a  real  sample  is  up  and  operating,  cannot  get  full 
accreditation.  And  I  think  that  is  an  issue  for  people  starting  new 
services or improving services. 

Senator  BURNS.  Mr.  Metzger,  please.  I’ll  come  back  to  Mr. 

Mullen. 

Mr.  METZGER.  Let  me  first  comment,  I  think  it’s  clear  to  me 
today  that  your  introduction  of  this  legislation  has  aided  the  proc-
ess of the voluntary code of conduct a great deal. 

[Laughter.] 
Mr.  METZGER.  I  doubt  we’d  be  this  far  along  at  this  point.  But, 
to your specific question about investing and creating a new meter 
and taking the jeopardy of doing that, again, the MRC is not some 
arbitrary thing sitting out on some other planet. 

Senator BURNS. Yes. 
Mr. METZGER. It is an industry organization. The industry wants 
competition.  And,  in  1997—late  1997,  early  1998—we  had  our 
meter  up  and  operating,  and  Nielsen  announced  the  A/P  meter. 
And,  at  that  time,  the  ARF  put  forth  an  initiative  to  do  a  parallel 
audit  of  those  two  meters,  hiring  an  independent  engineering  lab-
oratory  such  as—our  firm  had  done  that  by  auditing  Arbitron  and 
Nielsen meters, and hired the Illinois Institute of Technology to go 
through  those  meters  and  see  how  robust  they  were,  where  the 
fault lines were, and so forth. 

So,  where  there’s  a  real  option  for  competition  that  has  credi-
bility,  the  industry  will  respond.  I  mean,  if  you  handle  this  thing 
right, I think you can get through—I don’t think the issue of man-
datory—or  voluntary  MRC  accreditation  has  any  influence  on— 
frankly,  I  think—and  I  said  I  think  it  expedites  it,  because  it 
brings the power together in one place. You can go and get a read-
ing and keep people informed. 
Senator BURNS. Mr. Mullen? 
Mr.  MULLEN.  Yes,  I  agree  with  Mr.  Metzger,  in  that  this  whole 
process  has  helped  the  voluntary  code  of  conduct  move  along,  but 
I  would  want  to  point  out  that  that  voluntary  code  of  conduct  was 
out and proposed by the MRC well in advance of Nielsen’s decision 
to  roll  out  both  Philadelphia  and  Washington,  D.C.  And  the  re-
sponse  from  Nielsen  to  audit  all  future  markets  was  announced,  I 
believe, the day after they commercialized the service in those two 
markets. 

Senator BURNS. Well, this has been very helpful today. 
Mr. Ivie? 
Mr. IVIE. I just wanted—can I—— 
Senator BURNS. Yes, sir. 
Mr. IVIE.—just address one point? It’s different, though. 
Senator  BURNS.  I’ve  got  to  shift  gears  and  go  talk  about  BSE 

here in—— 

Mr. IVIE. All right. 
Senator BURNS.—a little bit. 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00064 Fmt 6633 Sfmt 6601 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

61 

Mr. IVIE. Can I just—— 
Senator BURNS. This is a bad venue to bring that up. 
Mr.  IVIE.  All  right.  I  just  wanted  to  make  one  quick  point.  The 
idea of the membership of the MRC—who is a member and is that 
a  forum  dominated  by  broadcasters—has  been  discussed  here,  and 
I didn’t get an opportunity to really respond to that. And I wanted 
to just put something in the record on that. 

The MRC has 95 members today. In 1964, when we were formed, 
we  had  15.  This  was  at  the  full  knowledge  of  the  Congress  when 
we  were  formed.  At  that  time,  there  were  11  broadcast  members, 
out  of  15.  There  were  two—these  are  television  broadcast  mem-
bers—there were two radio broadcasters, and there were two seats 
held  by  the  American  Association  of  Advertising  Agencies.  Today, 
we  have  95  members,  there  are  27  broadcast  seats.  So,  that’s—if 
you  look  at  that  in  terms  of  diluting  the  influence  of  broadcasters 
within  the  MRC,  the  MRC  is  a  much  more  diverse  organization 
today  than  we  ever  were  in  1964,  and  that’s  reflective  of,  just  as 
people have said here, the diversity of the business. 

Interestingly  enough,  we  had  five  seats  to  one  organization  in 
1964.  That  was  the  NAB.  They  held  5  of  those  11  broadcaster 
votes. We’ve maintained that rule. In other words, no organization 
in  the  MRC  can  hold  more  than  5  seats,  and  they  can  only  have 
a seat for a different media identity. So, if you think about Viacom, 
they  have  a  radio  seat  for  Infinity,  they  have  a  broadcasting  seat, 
they also have cable—— 

Senator BURNS. Sounds like Rotary. 
Mr.  IVIE.  So,  we  have  a  very  diverse  organization.  No  one  sector 
controls  it.  But  it  is  true  that  we  have  issues  that  come  up  that 
certain sectors are very, very interested in. So, you’ll see sometimes 
very contentious, hotly-debated issues among, you know, certain of 
the things we review. People do this with passion. So—— 

Senator  BURNS.  Well,  it’s  like  I  said,  I’ve  got  another  commit-
ment  here,  but  I  want  to  thank  this  panel,  the  information  and 
how you’ve been candid with me and this Committee—and this will 
be reviewed by other Senators; we’re just scattered all over the Hill 
today—and  the  way  you  presented  your  information.  And  I  appre-
ciate  that  very  much,  being  very  honest  with  the  Committee.  And 
we’ll have to make some decisions as we go along. Maybe this legis-
lation  might  have  to  be  like  my  idea  of  going  into  the  sampling 
business, maybe. 

[Laughter.] 
Senator  BURNS.  We  might  have  to  change—but  we’re  amenable 
to  change.  I  think  Congress  can  sometimes  get  into  areas  where 
there  are  unintended  consequences,  and  I  don’t  want  to  do  that. 
And  the  only  way  we  have,  bringing  this  out—I  appreciate  Mr. 
Metzger today a lot because of his experience and what he has said 
here today. There’s a lot of wisdom there. And I appreciate it. And 
I know all of us have different interests. And I appreciate that. 

So,  I  look  forward  to  working  with  all  of  you  to  solve  this  prob-
lem. This is an industry that—the broadcast industry—that I love. 
I  came  out  of  it.  I  sort  of  backed  into  it  in  the  first  place.  But  it 
is  dear  to  my  heart.  And  I  don’t  want  to  do  anything  that  would 
damage  it,  because  I  think  we  have  a  great  responsibility  to  the 
American  people,  to  our  advertisers,  and  to  each  other  to  make 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00065 Fmt 6633 Sfmt 6601 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

62 

sure that the industry continues to grow, and grow in all segments 
of our society. 

I appreciate that. And if you want to extend some—and you’ll get 
some questions from other Senators. I would ask you to respond to 
those  Senators  and  to  the  Committee.  Your  full  statement  today 
will  be  made  part  of  the  record.  And  if  you  have  more  that  you 
would  like  to  add,  we  would  more  than  welcome  those  comments. 

Thank you for coming today. This Committee is closed. 
[Whereupon, at 4:20 p.m., the hearing was adjourned.] 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00066 Fmt 6633 Sfmt 6601 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

A P P E N D I X 

PREPARED STATEMENT OF HON. DANIEL K. INOUYE, U.S. SENATOR FROM HAWAII 
Today,  the  Committee  returns  to  the  subject  of  television  ratings.  Previously,  in 
the  108th  Congress,  we  heard  from  parties  concerned  about  the  decision  of  Nielsen 
Media  Research  to  roll  out  new  television  ratings  technology  in  local  markets.  This 
technology—often  referred  to  as  ‘‘Local  People  Meters’’—is  designed  to  replace  the 
old,  and  admittedly  flawed  system,  which  relied  on  viewers  to  write  down  their 
viewing choices in paper diaries. 

The  need  to  ensure  appropriate  levels  of  accuracy  and  transparency  have  long 
been  of  interest  to  members  of  this  committee  and  date  back  to  inquires  pursued 
in the early 1960s. Given that the market for television ratings data currently sup-
ports  only  one  television  ratings  service—Nielsen—that  interest  is  particularly 
acute. Moreover, our interest in this issue is shared by a number of parties who rely 
on  ratings  information.  Buyers  of  television  advertising  have  a  clear  interest  in 
knowing  the  audience  make  up  of  the  particular  shows  to  bid  on.  Similarly,  pro-
gramming  distributors—and  particularly,  free,  over-the-air  broadcasters  that  rely 
solely on ad-supported revenues—have an interest in ensuring that ratings data ac-
curately reflects the number of people watching their programs. 

Given  these  interests,  our  review  of  current  practices  is  entirely  appropriate.  If 
there are problems with the current system, we are well within our right to explore 
possible improvements. Some of these improvements may be pursued in the market-
place;  others  may  require  government  action.  I  look  forward  to  reviewing  these 
issues, but hope that as we go forward, we will be wary of solutions that would give 
parties  with  an  economic  interest  in  the  outcome,  the  right  to  prevent  the  roll  out 
of new ratings technologies. In the end, our interests should focus on promoting ac-
curacy,  and  should  not  get  sidetracked  with  the  mediation  of  commercial  disputes. 
Accordingly,  Mr.  Chairman,  thank  you  again  for  calling  for  today’s  hearing  and 

I look forward to hearing from the witnesses assembled hear today. 

PREPARED STATEMENT OF HON. FRANK R. LAUTENBERG, 

U.S. SENATOR FROM NEW JERSEY 

Mr. Chairman: 
Thank  you  for  calling  this  hearing  to  give  us  an  opportunity  to  learn  more  about 

this issue. 

are accurate. 

Over  the  last  few  decades,  television  has  grown  from  a  couple  of  broadcast  net-
work  affiliate  stations  in  each  market  to  cable  systems  with  hundreds  of  channels 
from which to choose. Keeping track of who is watching what is obviously extremely 
complicated. 

The Nielsen Corporation has been tracking viewership for decades. 
Although  it  is  a  private  company,  its  work  has  enormous  implications  for  the 
American people—because viewer-ship not only determines advertising rates, it ulti-
mately decides what program choices are available to the American people. 

So there is a clear public interest in ensuring that the ratings of television shows 

We  know  that  Nielsen  has  begun  using  a  new  system  to  measure  ratings.  It  ac-
knowledges  that  the  system  isn’t  perfect,  but  claims  that  the  technology  is  superior 
and that problems are being corrected. 

Some broadcasters have said that the new system isn’t getting a true measure of 
some  viewers—especially  minorities.  This  is  a  serious  concern  to  me,  and  I  am  dis-
appointed  that  a  year  after  a  Senate  hearing  on  this  same  issue,  we  are  learning 
that the problem has not been fixed. 

Mr. Chairman, as I see it, there are two questions we must explore today: 
First,  is  Nielsen  taking  immediate  steps  to  correct  any  problems  with  their  sys-

tem? 

(63) 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00067 Fmt 6601 Sfmt 6621 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

64 

And  second,  is  the  FAIR  Act,  which  is  before  us  today,  the  appropriate  Federal 
legislation  to  deal  with  the  issue?  I  believe  we  should  think  long  and  hard  before 
mandating  that  a  group  made  up  of  Nielsen’s  clients  should  have  power  to  decide 
what technologies Nielsen can and cannot utilize. 

I look forward to hearing from our witnesses. I’m sure they’ll do a good job of ex-

plaining both sides of this issue. 

New York, NY, September 29, 2005 

MINDSHARE 

Hon. TED STEVENS, 
Chairman, 
Senate Committee on Commerce, Science, and Transportation, 
Washington, DC. 
Dear Senator Stevens: 

I would like to thank the Senate Committee on Commerce, Science, and Transpor-
tation,  particularly  Senator  Conrad  Burns,  for  inviting  me  to  testify  at  the  hearing 
on the FAIR Ratings Act. I appreciated Senator Burns’ courtesy during the hearing, 
as  well  as  the  chance  to  express  the  views  held  by  many  of  my  colleagues  in  the 
advertising  community.  As  you  know,  advertisers,  advertising  agencies  and  adver-
tising buying companies have all demonstrated concern about any legislation affect-
ing television ratings and I believe it was important that their voice be heard. 

I  would  like  to  take  this  opportunity  to  comment  for  the  record  on  some  of  the 

remarks made by other witnesses. 
George Ivie 

My  observations  below  are  not  meant  to  criticize  the  Media  Rating  Council  for 
what  it  is  today—a  voluntary  industry  organization  operating  within  the  private 
sector.  Instead,  I  am  concerned  that  the  MRC  as  currently  constituted  cannot  take 
on the responsibility for regulating television audience measurement on the govern-
ment’s behalf. If the MRC is to be given the authority envisaged by the Fair Rating 
Bill, I believe the organization must be completely overhauled so that research deci-
sions are not determined by special interest voting. 

In  its  new  governing  role,  the  MRC  must  be  independent  of  the  business  sur-
rounding  the  data  being  regulated.  We,  in  the  industry,  can  accept  a  certain  level 
of potential bias today under the MRC’s current advisory role. 

Statement:  Mr.  Ivie  said  that  one  of  the  MRC’s  stated  policies  is  to  ‘‘limit  the  in-

fluence of any one Industry sector within our organization.’’ 

Response:  If  this  is  an  MRC  policy,  it  is  a  policy  that  has  not  been  implemented. 
The  broadcast  industry  continues  to  dominate  the  MRC  today,  as  it  has  from  the 
time  of  its  formation.  By  Mr.  Ivie’s  own  count,  27  of  the  65  votes—or  almost  half 
of the votes—on the Television Committee are controlled by broadcasters. 

But  this  does  not  tell  the  full  story.  Large  media  organizations  can  have  up  to 
five  votes  for  each  of  their  business  segments,  so  NBC  Universal,  for  example,  has 
five  separate  votes:  for  the  NBC  Network,  the  NBC  TV  station  group,  MSNBC, 
Telemundo  and  Universal  Television.  I  also  note  that  Infinity  Broadcasting, 
Viacom’s radio network, is one of five Viacom votes on the Television Committee de-
spite not even being a consumer of Nielsen ratings. 

By  contrast,  my  company,  Mindshare,  has  only  one  vote.  This  gives  a  handful  of 
companies  disproportionate  power  within  the  organization—power  that  they  have 
used  to  block  accreditation  of  LPMs  in  many  markets  over  the  opposition  of  voters 
from  the  advertising  and  cable  industries.  If  the  broadcast,  advertiser  and  cable 
companies all had one vote each, it is possible that the outcome of the accreditation 
votes would have been much different. 

Statement:  Mr.  Ivie  said  that  ‘‘Accreditation  is  granted  by  the  MRC  Board  of  Di-
rectors  if  a  rating  service  complies  with  the  MRC’s  Minimum  Standards  for  Media 
Rating  Research  and  makes  materially  complete  methodological  and  survey-per-
formance disclosures to their customers.’’ 

Response: The accreditation process is not as simple as this sentence implies. This 
process  has  become  a  lengthy  and  cumbersome  struggle.  The  MRC’s  ‘‘Minimum 
Standards’’  are  vague  and  open  to  wide  interpretation.  Fault  rates  remain  a  case 
in point, demonstrating that these Minimum Standards are a moving target. A fault 
rate  that  was  historically  acceptable  in  a  Meter/Diary  sample  has  suddenly  become 
unacceptable in an LPM sample. 

Because  of  this,  delay  in  accreditation  has  occurred  even  though  the  collection 
technique is far superior to the diary, and the sample is larger and more representa-

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00068 Fmt 6601 Sfmt 6621 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

65 

tive of the market. If the FAIR Ratings Act were in effect, advertisers and program-
mers  would  have  been  denied  the  use  of  this  more  accurate  information  for  more 
than a year. 

Statement:  Mr.  Ivie  says,  ‘‘Special  circumstances  occur  when  an  MRC  member 
whose company has a vested interest in the matter being considered. When this oc-
curs,  that  member  may  participate  in  the  review  meeting  but  will  not  be  allowed 
to vote.’’ 

Response:  I  believe  that  all  MRC  members  have  a  vested  interest  in  the  issues 
before the MRC. Every member stands to profit or lose through the implementation 
of new ratings systems. Again, if the FAIR Ratings bill becomes law, I strongly be-
lieve  that  the  MRC  membership  would  have  to  be  changed  so  that  members  would 
not be in a position to vote their self-interest and use their power to deny more ac-
curate ratings systems. 
Pat Mullen 

Statement: Mr. Mullen says that Nielsen ‘‘does not have the trust of our company 

or that of more than a dozen responsible broadcasters.’’ 

Response: Mr. Mullen provides no names to back up this statement; and although 
everyone  has  had  their  issues  with  Nielsen  over  the  years,  it  is  unlikely  that  he 
could provide a list of a dozen companies who would support that statement. Indeed, 
only  a  handful  of  companies  have  voiced  their  public  support  for  the  FAIR  Ratings 
bill, compared to dozens who are opposed, including the Association of National Ad-
vertisers, the American Association of Advertising Agencies, Asian American Adver-
tising  Federation,  BET,  Azteca  American  Affiliate  Group,  the  Latin  Business  Asso-
ciation, the Urban League and the Rainbow/PUSH Coalition. 

Statement:  Mr.  Mullen  complains  several  times  that  Nielsen  is  a  monopoly,  in-
cluding his statement that ‘‘the keys to our success—our ratings—are held by a mo-
nopoly.’’ 

Response: Nielsen is the only company offering ratings data because the TV indus-
try  itself,  led  primarily  by  the  broadcasters,  decided  it  didn’t  want  to  pay  for  more 
than  one  service.  Indeed,  when  Gale  Metzger  tried  to  launch  SMART  as  a  compet-
itor to Nielsen in the late 1990s the major broadcast networks made a conscious de-
cision not to fund it. Nielsen may currently be the only company offering television 
ratings,  but  that  does  not  mean  there  cannot  or  will  not  be  competitors  in  the  fu-
ture,  especially  with  recent  innovations  in  set  top  boxes  and  other  television  tech-
nology.  Moreover,  it  is  worth  noting  that  the  Federal  Trade  Commission  recently 
wrote  that  Nielsen  has  not  engaged  in  ‘‘exclusionary  monopoly  practices,  collusion 
[or] anticompetitive mergers.’’ 

Additionally, the FAIR Ratings Act will preclude potential competitors to Nielsen. 
What company could afford, what venture capitalist would fund, and who in the in-
dustry would support, a service that could take years to complete the MRC accredi-
tation  process  with  a  high  potential  for  failure  due  to  previously  stated  conflict  of 
interest issues? 

Statement:  In  an  apparent  reference  to  fault  rates,  Mr.  Mullen  says,  ‘‘It  is  worth 
noting that in New York, on the average day for the week ending July 10, the view-
ing  choices  for  nearly  one-third  of  the  black  and  Hispanic  men  ages  18–34  in  the 
Nielsen LPM sample were not reflected in the ratings.’’ 

Response: Obviously it is always possible to find one demographic in one week in 
one  market  that  appears  to  show  high  fault  rates,  but  looking  at  the  broader  pic-
ture,  it  is  very  clear  that  fault  rates  are  lower  for  all  groups  in  the  LPM  samples 
than  in  the  Meter  Diary  sample.  Mr.  Mullen’s  credibility  on  this  issue  would  be 
stronger if he had also objected to fault rates in Meter/Diary markets. 

More  to  the  point,  though,  it  is  not  true  that  faulting  causes  undercounting.  All 
demographic  groups  are  weighted  to  make  sure  they  are  represented  in  ratings  to 
the same extent they are represented in the overall population. 

Statement:  Mr.  Mullen  said  that  broadcasters  ‘‘pay  the  vast  majority  of  the  fees 
for Nielsen’s local services,’’ seeming to imply that broadcasters should have a great-
er say in ratings decisions. 

Response:  I  strongly  object  to  Mr.  Mullen’s  assertion  that  local  broadcasters  pay 
most of the freight for local TV ratings. The money to support free over-the-air pro-
gramming  at  the  local  level  comes  almost  exclusively  from  advertising,  so  all  of  a 
station’s  operating  expenses—including  ratings  fees—are  ultimately  borne  by  the 
advertiser.  I  might  also  add  that  television  stations,  which  operate  under  a  license 
granted  by  the  Federal  Government,  are  some  of  the  most  profitable  businesses  in 
our  economy.  Since  those  high  profit  margins  are  also  borne  by  the  advertiser,  I 
think  the  advertising  community  has  a  right  to  know  that  the  rates  it  pays  local 
stations accurately reflect the number of people watching their programming. 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00069 Fmt 6601 Sfmt 6621 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

66 

Again, Senator Stevens, it was a great privilege for me to testify before the Com-
merce Committee on this important issue, and I truly appreciate the equitable man-
ner  in  which  Senator  Burns’  handled  proceedings.  I  hope  Committee  Members  will 
keep  in  mind  that  the  American  Association  of  Advertising  Agencies  (AAAA),  the 
American  Advertising  Federation  (AAF),  the  Association  of  National  Advertisers 
(ANA),  the  Asian  American  Advertising  Federation  (3AF)  and  the  Association  of 
Hispanic  Advertising  Agencies  (AHAA),  in  addition  to  more  than  a  dozen  leading 
advertising agencies and buying companies, have all registered their objection to the 
FAIR  Ratings  bill.  In  light  of  these  concerns,  I  hope  that  Senator  Burns  and  the 
co-sponsors of the bill will reconsider their support for this legislation. 

Sincerely, 

KATHY CRAWFORD. 

Fault Rate Trends—Chicago 

Set Meter vs. LPM Set 

Week-ending 

Fault Rate 
(Set Meter) 

Week-ending 

Fault Rate 
(LPM Set) 

Total Fault Rate Trend 

3/28/2004 
4/4/2004 
4/11/2004 
4/18/2004 
4/25/2004 
5/2/2004 
5/9/2004 
5/16/2004 
5/23/2004 
5/30/2004 
6/6/2004 
6/13/2004 
6/20/2004 
6/27/2004 
7/4/2004 
7/11/2004 
7/18/2004 

3/28/2004 
4/4/2004 
4/11/2004 
4/18/2004 
4/25/2004 
5/2/2004 
5/9/2004 
5/16/2004 
5/23/2004 
5/30/2004 
6/6/2004 
6/13/2004 
6/20/2004 
6/27/2004 
7/4/2004 
7/11/2004 
7/18/2004 

3/28/2004 
4/4/2004 
4/11/2004 
4/18/2004 
4/25/2004 
5/2/2004 
5/9/2004 

13.8 
12.6 
12.7 
11.8 
12.9 
11.5 
11.5 
11.9 
11.8 
11.5 
11.5 
12.7 
12.7 
11.7 
10.6 
11.3 
11.1 

3/27/2005 
4/3/2005 
4/10/2005 
4/17/2005 
4/24/2005 
5/1/2005 
5/8/2005 
5/15/2005 
5/22/2005 
5/29/2005 
6/5/2005 
6/12/2005 
6/19/2005 
6/26/2005 
7/3/2005 
7/10/2005 
7/17/2005 

African-American Fault Rate Trend 

19.8 
18.3 
15.1 
14.9 
18.9 
15.2 
12.1 
14.1 
17.6 
18.9 
20.2 
23.3 
20.9 
19.1 
19.3 
20.5 
18.2 

Hispanic Fault Rate Trend 

21.2 
15.6 
23.1 
18.8 
15.9 
17.2 
15.2 

3/27/2005 
4/3/2005 
4/10/2005 
4/17/2005 
4/24/2005 
5/1/2005 
5/8/2005 
5/15/2005 
5/22/2005 
5/29/2005 
6/5/2005 
6/12/2005 
6/19/2005 
6/26/2005 
7/3/2005 
7/10/2005 
7/17/2005 

3/27/2005 
4/3/2005 
4/10/2005 
4/17/2005 
4/24/2005 
5/1/2005 
5/8/2005 

8.8 
9.4 
9.9 
8.0 
6.8 
7.2 
6.4 
8.2 
8.5 
7.9 
9.5 
10.5 
11.0 
9.9 
10.3 
11.9 
10.9 

13.0 
15.0 
15.2 
12.3 
7.7 
12.2 
10.3 
12.6 
15.7 
15.7 
14.6 
15.7 
17.0 
17.3 
17.1 
17.8 
16.0 

12.1 
12.7 
14.2 
10.6 
11.6 
9.1 
9.2 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00070 Fmt 6601 Sfmt 6621 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

67 

Fault Rate Trends—Chicago—Continued 

Set Meter vs. LPM Set 

Week-ending 

Fault Rate 
(Set Meter) 

Week-ending 

Fault Rate 
(LPM Set) 

5/16/2004 
5/23/2004 
5/30/2004 
6/6/2004 
6/13/2004 
6/20/2004 
6/27/2004 
7/4/2004 
7/11/2004 
7/18/2004 

15.4 
15.4 
16.9 
16.7 
18.2 
18.5 
17.2 
18.5 
18.8 
20.6 

5/15/2005 
5/22/2005 
5/29/2005 
6/5/2005 
6/12/2005 
6/19/2005 
6/26/2005 
7/3/2005 
7/10/2005 
7/17/2005 

11.8 
9.9 
8.8 
11.7 
12.7 
15.5 
10.9 
9.8 
13.4 
13.9 

Fault Rate Trends—New York 

Set Meter vs. LPM Set 

Week-ending 

Fault Rate 
(Set Meter) 

Week-ending 

Fault Rate 
(LPM Set) 

Total Fault Rate Trend 

3/28/2004 
4/4/2004 
4/11/2004 
4/18/2004 
4/25/2004 
5/2/2004 
5/9/2004 
5/16/2004 
5/23/2004 
5/30/2004 
6/6/2004 
6/13/2004 
6/20/2004 
6/27/2004 
7/4/2004 
7/11/2004 
7/18/2004 

3/28/2004 
4/4/2004 
4/11/2004 
4/18/2004 
4/25/2004 
5/2/2004 
5/9/2004 
5/16/2004 
5/23/2004 
5/30/2004 
6/6/2004 
6/13/2004 
6/20/2004 
6/27/2004 
7/4/2004 
7/11/2004 
7/18/2004 

3/28/2004 
4/4/2004 

11.3 
9.8 
10.5 
11.1 
10.9 
12.1 
12.7 
13.2 
12.7 
14.2 
13.4 
11.3 
11.2 
11.2 
9.7 
8.7 
8.3 

3/27/2005 
4/3/2005 
4/10/2005 
4/17/2005 
4/24/2005 
5/1/2005 
5/8/2005 
5/15/2005 
5/22/2005 
5/29/2005 
6/5/2005 
6/12/2005 
6/19/2005 
6/26/2005 
7/3/2005 
7/10/2005 
7/17/2005 

African-American Fault Rate Trend 

20.2 
19.8 
18.0 
17.2 
21.2 
23.2 
21.6 
22.1 
23.7 
22.8 
21.1 
19.1 
18.2 
18.2 
16.9 
16.9 
16.1 

Hispanic Fault Rate Trend 

17.4 
12.2 

3/27/2005 
4/3/2005 
4/10/2005 
4/17/2005 
4/24/2005 
5/1/2005 
5/8/2005 
5/15/2005 
5/22/2005 
5/29/2005 
6/5/2005 
6/12/2005 
6/19/2005 
6/26/2005 
7/3/2005 
7/10/2005 
7/17/2005 

3/27/2005 
4/3/2005 

9.7 
10.3 
9.9 
9.7 
9.5 
10.9 
9.4 
7.9 
7.9 
7.5 
9.5 
9.8 
9.4 
8.4 
8.9 
9.8 
9.0 

15.3 
17.2 
15.0 
14.5 
14.1 
17.4 
14.8 
11.6 
10.8 
8.2 
11.5 
14.7 
13.4 
12.3 
11.5 
13.8 
10.6 

12.3 
14.2 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00071 Fmt 6601 Sfmt 6621 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

68 

Fault Rate Trends—New York—Continued 

Set Meter vs. LPM Set 

Week-ending 

Fault Rate 
(Set Meter) 

Week-ending 

Fault Rate 
(LPM Set) 

4/11/2004 
4/18/2004 
4/25/2004 
5/2/2004 
5/9/2004 
5/16/2004 
5/23/2004 
5/30/2004 
6/6/2004 
6/13/2004 
6/20/2004 
6/27/2004 
7/4/2004 
7/11/2004 
7/18/2004 

14.6 
18.3 
17.1 
19.3 
19.8 
18.8 
17.9 
27.5 
26.6 
22.1 
20.8 
20.8 
10.3 
12.8 
14.3 

4/10/2005 
4/17/2005 
4/24/2005 
5/1/2005 
5/8/2005 
5/15/2005 
5/22/2005 
5/29/2005 
6/5/2005 
6/12/2005 
6/19/2005 
6/26/2005 
7/3/2005 
7/10/2005 
7/17/2005 

11.6 
14.2 
12.9 
16.4 
13.2 
10.1 
10.8 
11.0 
13.1 
10.6 
9.3 
11.8 
13.7 
14.9 
14.4 

SUPPLEMENTARY INFORMATION SUBMITTED BY GALE METZGER 

I  appreciated  the  opportunity  to  testify  before  the  Senate  Committee  on  Com-
merce,  Science,  and  Transportation  regarding  the  FAIR  Ratings  Act  on  July  27. 
Thank you for allowing me to do so and for inviting these additional remarks. 

As  I  said  at  the  time,  the  introduction  of  legislation  has  itself  had  an  apparently 
positive effect. It seemed to have expedited the acceptance of the proposed voluntary 
code of conduct. However, that prospect does not diminish the need for a mandatory 
process to assure that audience measurement services are always committed to the 
vetting of their services through the Media Rating Council (MRC). 

As explained in my testimony, I comment as one who (A) has no stake in the out-
come,  (B)  is  concerned  about  core  weaknesses  in  Nielsen  services  and  (C)  believes 
that  the  quality  of  Nielsen  research  is  important  to  society  and  to  the  industry  it 
serves.  We  now  read  that  Nielsen  has  spent  ‘‘more  than  $4,000,000’’  for  lobbyists 
and  PR  people  to  shape  the  debate  on  this  bill. 1 They  have  cast  the  issues  as  gov-
ernment  regulation  and  minority  representation.  Both  characterizations  are  mis-
leading. 

First,  what  is  proposed  is  not  government  regulation  but  a  government  require-
ment. The requirement mandates a monopoly to work with the industry and to play 
by long-standing and long-accepted rules. 

To  call  this  bill  ‘‘government  regulation’’  is  a  smokescreen,  created  purposefully 
to raise a frightening hydra and to conjure a burden that stifles innovation. Working 
with the MRC is not working with the FTC—or any governmental bureaucracy. The 
MRC  is  a  creation  of  the  industry  itself.  Accreditation  is  held  up  only  if  problems 
arise—if  a  ratings  service  is  not  doing  things  right.  The  MRC  system  has  worked 
well for decades and is respected and accepted by all, buyers and sellers, who have 
to  use  audience  research  numbers.  This  confidence  is  a  necessary  prerequisite  for 
a media industry that exchanges billions of dollars on information. That information 
must be reliable. 

In 1963, the industry and Nielsen agreed to work collaboratively to build and en-
sure confidence in ratings. The MRC was set-up to avoid government regulation and 
now, this legislative proposal only requires that they live up to that earlier commit-
ment—which in recent times seems to be deemed as optional by Nielsen. The legis-
lation is appropriate and will benefit everyone. 

Second,  this  bill  does  not  stifle  innovation;  monopolies  stifle  innovation.  As  I  ex-
plained at the hearing, the MRC would expedite gaining acceptance of new and bet-
ter  approaches  to  measurement.  Had  the  SMART  initiative  been  funded,  I  would 
have asked the MRC to audit the rollout in order to signal efficiently the value and 
accuracy of our approach. 

Nielsen has little or no incentive to do better. During the discussion section of the 
hearing,  I  noted  that  Nielsen  skipped  homes  with  new  digital  recording  devices, 

1 Nielsen,  Long  a  Gauge  of  Popularity,  Fights  to  Preserve  Its  Own,  New  York  Times,  August 

8, 2005, Lorne Manly and Raymond Hernandez, p. C1 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00072 Fmt 6601 Sfmt 6621 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

69 

such  as  TiVo.  Ms.  Whiting  stated  that  Nielsen  could  now  meter  such  homes.  Only 
recently have they announced that capability, many years after the digital recording 
devices entered the marketplace. This lag time between measurement of time-shift-
ing viewers and actual use exemplifies the ill effect of a monopolized industry. Fur-
ther, the industry will have to wait an additional year, or years, for Nielsen to bring 
their  total  national  sample  up-to-date  and  to  have  the  proper  share  of  new  high- 
tech homes in their sample for complete measurement. 

Third,  Nielsen  says  that  it  is  ‘‘in  the  truth  business’’  and  casts  the  dispute  as  a 
battle  between  the  buyers  and  the  sellers  of  the  data.  In  effect,  Nielsen  maintains 
they  are  above  the  fray  and  they  can’t  satisfy  everyone.  If  Nielsen  were  to  focus  on 
research quality, they and the television marketplace would be the richer for it. 

Instead,  the  appearance  is  that  they  are  focused  on  short-term  profits  at  the  ex-
pense  of  long-term  investing  to  produce  a  better  and  more  accurate  measurement. 
The  appearance  is  of  doing  only  what  they  have  to  do  to  get  by.  Their  history  of 
anomalous  and  inconsistent  numbers  are  caused,  I  believe,  by  business  decisions 
animated  most  by  the  bottom  line.  The  lack  of  adequate  support  staff  and  the  fail-
ure  to  institute  effective  quality  control  procedures  over  their  operations  are  illus-
trations. 

The roll-out of an improved meter provides an example of their slowness to invest 
for  improvement.  I  noted  in  my  testimony  that  Nielsen  responds  only  when  a  com-
petitor  challenges  them.  In  1998,  when  the  A/P  meter 2 was  being  developed  and 
SMART  was  a  real  possible  alternative  to  their  services,  Nielsen  published  a  well- 
designed  research  plan  to  create  a  scientifically-based  approach  to  new  A/P  oper-
ating  rules.  Seven  years  later  and  much  delayed,  Nielsen  is  ready  to  roll  out  this 
‘‘A/P meter’’ and integrate the technology into the measurement system. In addition 
to  the  inexplicable  wait,  only  on  the  eve  of  the  installations  of  the  new  meter  did 
Nielsen  propose  efforts  to  fill  in  the  operating-rules  gap.  The  planned  research  of 
1998 had never been completed and still hasn’t. Effectively, Nielsen’s new A/P rules 
will be set arbitrarily and be modified as experience dictates. 

A  champion  of  truth  would  have  introduced  the  new  meters  years  ago  and  com-
pleted  the  original  research  plan.  Nielsen’s  slowness  to  innovate  and  to  improve 
damages themselves and the industry. 

Fourth,  Nielsen’s  posture  as  the  protector  of  minority  interests  camouflages  the 
true  problem.  Minority  groups  are  right  to  be  concerned  about  the  accuracy  of 
Nielsen ratings. As I testified, black and Hispanic homes have more people in them. 
That  means  it  is  more  difficult  to  obtain  good  data  from  those  homes.  This  is  true 
for every measurement technique, be it the LPM 3 or the meter-diary approach. The 
MRC  is  the  best  assurance  minorities  have  of  a  measurement  service  in  which  all 
population segments are appropriately counted. 
Media Rating Council 

In  my  July  27  testimony,  I  advocated  that  the  MRC  audit  be  an  open  process. 
That  is,  the  audit  reports,  which  are  the  basis  for  the  accreditation  process,  should 
be  available  to  the  entire  community.  Transparency  would  benefit  the  marketplace 
by  putting  all  users  on  an  equal  footing.  It  would  bring  pressure  to  improve  oper-
ations more quickly when problems are identified. 

Effectively,  the  Statistical  Research,  Inc.  People  Meter  Review  of  1987–88  was  a 
full  and  complete  open  audit.  The  Advertising  Research  Foundation  has  performed 
audits  of  media  rating  services  and,  as  a  matter  of  policy,  their  audit  results  are 
open  to  everyone.  Open-audit  precedents  exist  and  have  served  the  industry  well. 
In addition, distribution of the full audit findings takes the onus off of the current 
process of accrediting or not accrediting. A pass or fail grade is too rudimentary for 
the  sophisticated  evaluation  required.  The  market  needs  to  know  and  understand 
the accreditation process. Further, concern articulated about the politicization of ac-
creditation voting (to the extent it is real) would be ameliorated by open audits. Ev-
erybody  could  monitor  the  process  and  providers  would  be  accountable  from  begin-
ning to end. 
Conclusion 

It  would  be  truly  regrettable  if  this  bill  did  not  pass  because  some  lawmakers 
don’t  like  government  regulation  and  others  fear  the  disenfranchisement  of  minori-
ties—when  neither  issue  is  the  real  problem.  Decoys  and  diversions  created  by 
Nielsen should not triumph. 

2 A/P  Meter  stands  for  Active/Passive  Meter  and  was  designed  to  enable  identification  of  pro-

grams tuned on metered sets without relying on station calibration. 

3 LPM stands for Local People Meter. 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00073 Fmt 6601 Sfmt 6621 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

70 

The  real  story  is  that  the  proposed  legislation  would  reinforce  industry  self-regu-
lation and provide better protection that all people, including minorities, are count-
ed more accurately. 

I  remain  hopeful  that  Congress  will  intervene  to  ensure  that  the  1963  standards 
for  audience  measurement  review  will  persevere  and  transcend  the  political  aisles. 

Æ 

VerDate Nov 24 2008  08:17 Mar 21, 2011 Jkt 065216 PO 00000 Frm 00074 Fmt 6601 Sfmt 6611 S:\GPO\DOCS\65216.TXT SCOM1 PsN: JACKIE

